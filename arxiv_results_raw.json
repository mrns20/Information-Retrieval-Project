[
    {
        "title": "Title:Transduce: learning transduction grammars for string transformation",
        "authors": [
            "",
            "Authors:",
            "",
            "Francis Frydman",
            ",",
            "Philippe Mangion",
            ""
        ],
        "abstract": "The synthesis of string transformation programs from input-output examples\nutilizes various techniques, all based on an inductive bias that comprises a\nrestricted set of basic operators to be combined. A new algorithm, Transduce,\nis proposed, which is founded on the construction of abstract transduction\ngrammars and their generalization. We experimentally demonstrate that Transduce\ncan learn positional transformations efficiently from one or two positive\nexamples without inductive bias, achieving a success rate higher than the\ncurrent state of the art.",
        "date": "Not Found"
    },
    {
        "title": "Title:RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language  Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Meiling Tao",
            ",",
            "Xuechen Liang",
            ",",
            "Tianyu Shi",
            ",",
            "Lei Yu",
            ",",
            "Yiting Xie",
            ""
        ],
        "abstract": "This study presents RoleCraft-GLM, an innovative framework aimed at enhancing\npersonalized role-playing with Large Language Models (LLMs). RoleCraft-GLM\naddresses the key issue of lacking personalized interactions in conversational\nAI, and offers a solution with detailed and emotionally nuanced character\nportrayals. We contribute a unique conversational dataset that shifts from\nconventional celebrity-centric characters to diverse, non-celebrity personas,\nthus enhancing the realism and complexity of language modeling interactions.\nAdditionally, our approach includes meticulous character development, ensuring\ndialogues are both realistic and emotionally resonant. The effectiveness of\nRoleCraft-GLM is validated through various case studies, highlighting its\nversatility and skill in different scenarios. Our framework excels in\ngenerating dialogues that accurately reflect characters' personality traits and\nemotions, thereby boosting user engagement. In conclusion, RoleCraft-GLM marks\na significant leap in personalized AI interactions, and paves the way for more\nauthentic and immersive AI-assisted role-playing experiences by enabling more\nnuanced and emotionally rich dialogues",
        "date": "Not Found"
    },
    {
        "title": "Title:Modeling, Simulation, and Maneuvering Control of a Generic Submarine",
        "authors": [
            "",
            "Authors:",
            "",
            "Gage MacLin",
            ",",
            "Maxwell Hammond",
            ",",
            "Venanzio Cichella",
            ",",
            "J. Ezequiel Martin",
            ""
        ],
        "abstract": "This work introduces two multi-level control strategies to address the\nproblem of guidance and control of underwater vehicles. An outer-loop\npath-following algorithm and an outer-loop trajectory tracking algorithm are\npresented. Both outer-loop algorithms provide reference commands that enable\nthe generic submarine to adhere to a three-dimensional path, and both use an\ninner-loop adaptive controller to determine the required actuation commands.\nFurther, a reduced order model of a generic submarine is presented.\nComputational fluid dynamics (CFD) results are used to create and validate a\nmodel that includes depth dependence and the effect of waves on the craft. %The\nmodel and the procedure to obtain its coefficients are discussed, and examples\nof the data used to obtain the model coefficients are presented. An example of\noperation following a complex path is presented and Results from the reduced\norder model for each control strategy are compared.",
        "date": "Not Found"
    },
    {
        "title": "Title:Voxceleb-ESP: preliminary experiments detecting Spanish celebrities from  their voices",
        "authors": [
            "",
            "Authors:",
            "",
            "Beltr\u00e1n Labrador",
            ",",
            "Manuel Otero-Gonzalez",
            ",",
            "Alicia Lozano-Diez",
            ",",
            "Daniel Ramos",
            ",",
            "Doroteo T. Toledano",
            ",",
            "Joaquin Gonzalez-Rodriguez",
            ""
        ],
        "abstract": "This paper presents VoxCeleb-ESP, a collection of pointers and timestamps to\nYouTube videos facilitating the creation of a novel speaker recognition\ndataset. VoxCeleb-ESP captures real-world scenarios, incorporating diverse\nspeaking styles, noises, and channel distortions. It includes 160 Spanish\ncelebrities spanning various categories, ensuring a representative distribution\nacross age groups and geographic regions in Spain. We provide two speaker trial\nlists for speaker identification tasks, each of them with same-video or\ndifferent-video target trials respectively, accompanied by a cross-lingual\nevaluation of ResNet pretrained models. Preliminary speaker identification\nresults suggest that the complexity of the detection task in VoxCeleb-ESP is\nequivalent to that of the original and much larger VoxCeleb in English.\nVoxCeleb-ESP contributes to the expansion of speaker recognition benchmarks\nwith a comprehensive and diverse dataset for the Spanish language.",
        "date": "Not Found"
    },
    {
        "title": "Title:Object Attribute Matters in Visual Question Answering",
        "authors": [
            "",
            "Authors:",
            "",
            "Peize Li",
            ",",
            "Qingyi Si",
            ",",
            "Peng Fu",
            ",",
            "Zheng Lin",
            ",",
            "Yan Wang",
            ""
        ],
        "abstract": "Visual question answering is a multimodal task that requires the joint\ncomprehension of visual and textual information. However, integrating visual\nand textual semantics solely through attention layers is insufficient to\ncomprehensively understand and align information from both modalities.\nIntuitively, object attributes can naturally serve as a bridge to unify them,\nwhich has been overlooked in previous research. In this paper, we propose a\nnovel VQA approach from the perspective of utilizing object attribute, aiming\nto achieve better object-level visual-language alignment and multimodal scene\nunderstanding. Specifically, we design an attribute fusion module and a\ncontrastive knowledge distillation module. The attribute fusion module\nconstructs a multimodal graph neural network to fuse attributes and visual\nfeatures through message passing. The enhanced object-level visual features\ncontribute to solving fine-grained problem like counting-question. The better\nobject-level visual-language alignment aids in understanding multimodal scenes,\nthereby improving the model's robustness. Furthermore, to augment scene\nunderstanding and the out-of-distribution performance, the contrastive\nknowledge distillation module introduces a series of implicit knowledge. We\ndistill knowledge into attributes through contrastive loss, which further\nstrengthens the representation learning of attribute features and facilitates\nvisual-linguistic alignment. Intensive experiments on six datasets, COCO-QA,\nVQAv2, VQA-CPv2, VQA-CPv1, VQAvs and TDIUC, show the superiority of the\nproposed method.",
        "date": "Not Found"
    },
    {
        "title": "Title:CRD: Collaborative Representation Distance for Practical Anomaly  Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Chao Han",
            ",",
            "Yudong Yan",
            ""
        ],
        "abstract": "Visual defect detection plays an important role in intelligent industry.\nPatch based methods consider visual images as a collection of image patches\naccording to positions, which have stronger discriminative ability for small\ndefects in products, e.g. scratches on pills. However, the nearest neighbor\nsearch for the query image and the stored patches will occupy $O(n)$ complexity\nin terms of time and space requirements, posing strict challenges for\ndeployment in edge environments. In this paper, we propose an alternative\napproach to the distance calculation of image patches via collaborative\nrepresentation models. Starting from the nearest neighbor distance with $L_0$\nconstraint, we relax the constraint to $L_2$ constraint and solve the distance\nquickly in close-formed without actually accessing the original stored\ncollection of image patches. Furthermore, we point out that the main\ncomputational burden of this close-formed solution can be pre-computed by\nhigh-performance server before deployment. Consequently, the distance\ncalculation on edge devices only requires a simple matrix multiplication, which\nis extremely lightweight and GPU-friendly. Performance on real industrial\nscenarios demonstrates that compared to the existing state-of-the-art methods,\nthis distance achieves several hundred times improvement in computational\nefficiency with slight performance drop, while greatly reducing memory\noverhead.",
        "date": "Not Found"
    },
    {
        "title": "Title:Online Handbook of Argumentation for AI: Volume 4",
        "authors": [
            "",
            "Authors:",
            "",
            "Lars Bengel",
            ",",
            "Lydia Bl\u00fcmel",
            ",",
            "Elfia Bezou-Vrakatseli",
            ",",
            "Federico Castagna",
            ",",
            "Giulia D'Agostino",
            ",",
            "Isabelle Kuhlmann",
            ",",
            "Jack Mumford",
            ",",
            "Daphne Odekerken",
            ",",
            "Fabrizio Russo",
            ",",
            "Stefan Sarkadi",
            ",",
            "Madeleine Waller",
            ",",
            "Andreas Xydis",
            ""
        ],
        "abstract": "This volume contains revised versions of the papers selected for the fourth\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.",
        "date": "Not Found"
    },
    {
        "title": "Title:Quadratic neural networks for solving inverse problems",
        "authors": [
            "",
            "Authors:",
            "",
            "Leon Frischauf",
            ",",
            "Otmar Scherzer",
            ",",
            "Cong Shi",
            ""
        ],
        "abstract": "In this paper we investigate the solution of inverse problems with neural\nnetwork ansatz functions with generalized decision functions. The relevant\nobservation for this work is that such functions can approximate typical test\ncases, such as the Shepp-Logan phantom, better, than standard neural networks.\nMoreover, we show that the convergence analysis of numerical methods for\nsolving inverse problems with shallow generalized neural network functions\nleads to more intuitive convergence conditions, than for deep affine linear\nneural networks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Explainable Multimodal Sentiment Analysis on Bengali Memes",
        "authors": [
            "",
            "Authors:",
            "",
            "Kazi Toufique Elahi",
            ",",
            "Tasnuva Binte Rahman",
            ",",
            "Shakil Shahriar",
            ",",
            "Samir Sarker",
            ",",
            "Sajib Kumar Saha Joy",
            ",",
            "Faisal Muhammad Shah",
            ""
        ],
        "abstract": "Memes have become a distinctive and effective form of communication in the\ndigital era, attracting online communities and cutting across cultural\nbarriers. Even though memes are frequently linked with humor, they have an\namazing capacity to convey a wide range of emotions, including happiness,\nsarcasm, frustration, and more. Understanding and interpreting the sentiment\nunderlying memes has become crucial in the age of information. Previous\nresearch has explored text-based, image-based, and multimodal approaches,\nleading to the development of models like CAPSAN and PromptHate for detecting\nvarious meme categories. However, the study of low-resource languages like\nBengali memes remains scarce, with limited availability of publicly accessible\ndatasets. A recent contribution includes the introduction of the MemoSen\ndataset. However, the achieved accuracy is notably low, and the dataset suffers\nfrom imbalanced distribution. In this study, we employed a multimodal approach\nusing ResNet50 and BanglishBERT and achieved a satisfactory result of 0.71\nweighted F1-score, performed comparison with unimodal approaches, and\ninterpreted behaviors of the models using explainable artificial intelligence\n(XAI) techniques.",
        "date": "Not Found"
    },
    {
        "title": "Title:Experimental Investigation of 5G Base Station functionalities in  Reverberation Chamber at Millimeter-Wave",
        "authors": [
            "",
            "Authors:",
            "",
            "Michele Colombo",
            ",",
            "Riccardo Diamanti",
            ",",
            "Luca Bastianelli",
            ",",
            "Gabriele Gradoni",
            ",",
            "Emanuel Colella",
            ",",
            "Valter Mariani Primiani",
            ",",
            "Franco Moglie",
            ",",
            "Davide Micheli",
            ""
        ],
        "abstract": "The performance and functionalities of a commercial fifth generation base\nstation are evaluated inside the reverberation chamber at the mmWave frequency\nrange. The base station capability to operates in different propagation\nenvironment conditions reproduced by the reverberation chamber is investigated.\nThroughput, modulation code scheme and beamforming are analyzed for different\nreal life scenarios both in uplink and downlink. Experimental results inform\nnetwork operators in their evaluation of the base station operation: i) in many\nscenarios within a laboratory; ii) in the assessment of whether expected\nbenefit justifies the additional costs in an operating actual network.",
        "date": "Not Found"
    },
    {
        "title": "Title:Tumbug: A pictorial, universal knowledge representation method",
        "authors": [
            "",
            "Authors:",
            "",
            "Mark A. Atkins",
            ""
        ],
        "abstract": "Since the key to artificial general intelligence (AGI) is commonly believed\nto be commonsense reasoning (CSR) or, roughly equivalently, discovery of a\nknowledge representation method (KRM) that is particularly suitable for CSR,\nthe author developed a custom KRM for CSR. This novel KRM called Tumbug was\ndesigned to be pictorial in nature because there exists increasing evidence\nthat the human brain uses some pictorial type of KRM, and no well-known prior\nresearch in AGI has researched this KRM possibility. Tumbug is somewhat similar\nto Roger Schank's Conceptual Dependency (CD) theory, but Tumbug is pictorial\nand uses about 30 components based on fundamental concepts from the sciences\nand human life, in contrast to CD theory, which is textual and uses about 17\ncomponents (= 6 Primitive Conceptual Categories + 11 Primitive Acts) based\nmainly on human-oriented activities. All the Building Blocks of Tumbug were\nfound to generalize to only five Basic Building Blocks that exactly correspond\nto the three components {O, A, V} of traditional Object-Attribute-Value\nrepresentation plus two new components {C, S}, which are Change and System.\nCollectively this set of five components, called \"SCOVA,\" seems to be a\nuniversal foundation for all knowledge representation.",
        "date": "Not Found"
    },
    {
        "title": "Title:Optimal games in Room 25 solo and coop modes",
        "authors": [
            "",
            "Authors:",
            "",
            "Pierre Lafourcade",
            "(UB)"
        ],
        "abstract": "We study the problem of optimal games for the solo and coop modes of the\nboard game Room 25 (season 1). We show that the game cannot be won in a single\nturn for any starting configuration, but that it can be done in two for some\nconfigurations. We introduce an opening that wins in two turns with enough\nluck, while having a low probability of losing immediately. We then show that\nthe game can be won in a single turn if the game's rules are slightly modified,\nalthough the probability of winning then becomes substantially lower than in\nthe two-turn strategy. At last, we show that if the players are maximally\nunlucky, they will lose regardless of their strategy.",
        "date": "Not Found"
    },
    {
        "title": "Title:Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA  Initiative",
        "authors": [
            "",
            "Authors:",
            "",
            "Norman Zerbe",
            ",",
            "Lars Ole Schwen",
            ",",
            "Christian Gei\u00dfler",
            ",",
            "Katja Wiesemann",
            ",",
            "Tom Bisson",
            ",",
            "Peter Boor",
            ",",
            "Rita Carvalho",
            ",",
            "Michael Franz",
            ",",
            "Christoph Jansen",
            ",",
            "Tim-Rasmus Kiehl",
            ",",
            "Bj\u00f6rn Lindequist",
            ",",
            "Nora Charlotte Pohlan",
            ",",
            "Sarah Schmell",
            ",",
            "Klaus Strohmenger",
            ",",
            "Falk Zakrzewski",
            ",",
            "Markus Plass",
            ",",
            "Michael Takla",
            ",",
            "Tobias K\u00fcster",
            ",",
            "Andr\u00e9 Homeyer",
            ",",
            "Peter Hufnagl",
            ""
        ],
        "abstract": "Over the past decade, artificial intelligence (AI) methods in pathology have\nadvanced substantially. However, integration into routine clinical practice has\nbeen slow due to numerous challenges, including technical and regulatory\nhurdles in translating research results into clinical diagnostic products and\nthe lack of standardized interfaces. The open and vendor-neutral EMPAIA\ninitiative addresses these challenges. Here, we provide an overview of EMPAIA's\nachievements and lessons learned. EMPAIA integrates various stakeholders of the\npathology AI ecosystem, i.e., pathologists, computer scientists, and industry.\nIn close collaboration, we developed technical interoperability standards,\nrecommendations for AI testing and product development, and explainability\nmethods. We implemented the modular and open-source EMPAIA platform and\nsuccessfully integrated 11 AI-based image analysis apps from 6 different\nvendors, demonstrating how different apps can use a single standardized\ninterface. We prioritized requirements and evaluated the use of AI in real\nclinical settings with 14 different pathology laboratories in Europe and Asia.\nIn addition to technical developments, we created a forum for all stakeholders\nto share information and experiences on digital pathology and AI. Commercial,\nclinical, and academic stakeholders can now adopt EMPAIA's common open-source\ninterfaces, providing a unique opportunity for large-scale standardization and\nstreamlining of processes. Further efforts are needed to effectively and\nbroadly establish AI assistance in routine laboratory use. To this end, a\nsustainable infrastructure, the non-profit association EMPAIA International,\nhas been established to continue standardization and support broad\nimplementation and advocacy for an AI-assisted digital pathology future.",
        "date": "Not Found"
    },
    {
        "title": "Title:Incorporating Riemannian Geometric Features for Learning Coefficient of  Pressure Distributions on Airplane Wings",
        "authors": [
            "",
            "Authors:",
            "",
            "Liwei Hu",
            ",",
            "Wenyong Wang",
            ",",
            "Yu Xiang",
            ",",
            "Stefan Sommer",
            ""
        ],
        "abstract": "The aerodynamic coefficients of aircrafts are significantly impacted by its\ngeometry, especially when the angle of attack (AoA) is large. In the field of\naerodynamics, traditional polynomial-based parameterization uses as few\nparameters as possible to describe the geometry of an airfoil. However, because\nthe 3D geometry of a wing is more complicated than the 2D airfoil,\npolynomial-based parameterizations have difficulty in accurately representing\nthe entire shape of a wing in 3D space. Existing deep learning-based methods\ncan extract massive latent neural representations for the shape of 2D airfoils\nor 2D slices of wings. Recent studies highlight that directly taking geometric\nfeatures as inputs to the neural networks can improve the accuracy of predicted\naerodynamic coefficients. Motivated by geometry theory, we propose to\nincorporate Riemannian geometric features for learning Coefficient of Pressure\n(CP) distributions on wing surfaces. Our method calculates geometric features\n(Riemannian metric, connection, and curvature) and further inputs the geometric\nfeatures, coordinates and flight conditions into a deep learning model to\npredict the CP distribution. Experimental results show that our method,\ncompared to state-of-the-art Deep Attention Network (DAN), reduces the\npredicted mean square error (MSE) of CP by an average of 8.41% for the DLR-F11\naircraft test set.",
        "date": "Not Found"
    },
    {
        "title": "Title:Voila-A: Aligning Vision-Language Models with User's Gaze Attention",
        "authors": [
            "",
            "Authors:",
            "",
            "Kun Yan",
            ",",
            "Lei Ji",
            ",",
            "Zeyu Wang",
            ",",
            "Yuntao Wang",
            ",",
            "Nan Duan",
            ",",
            "Shuai Ma",
            ""
        ],
        "abstract": "In recent years, the integration of vision and language understanding has led\nto significant advancements in artificial intelligence, particularly through\nVision-Language Models (VLMs). However, existing VLMs face challenges in\nhandling real-world applications with complex scenes and multiple objects, as\nwell as aligning their focus with the diverse attention patterns of human\nusers. In this paper, we introduce gaze information, feasibly collected by AR\nor VR devices, as a proxy for human attention to guide VLMs and propose a novel\napproach, Voila-A, for gaze alignment to enhance the interpretability and\neffectiveness of these models in real-world applications. First, we collect\nhundreds of minutes of gaze data to demonstrate that we can mimic human gaze\nmodalities using localized narratives. We then design an automatic data\nannotation pipeline utilizing GPT-4 to generate the VOILA-COCO dataset.\nAdditionally, we innovate the Voila Perceiver modules to integrate gaze\ninformation into VLMs while preserving their pretrained knowledge. We evaluate\nVoila-A using a hold-out validation set and a newly collected VOILA-GAZE\nTestset, which features real-life scenarios captured with a gaze-tracking\ndevice. Our experimental results demonstrate that Voila-A significantly\noutperforms several baseline models. By aligning model attention with human\ngaze patterns, Voila-A paves the way for more intuitive, user-centric VLMs and\nfosters engaging human-AI interaction across a wide range of applications.",
        "date": "Not Found"
    },
    {
        "title": "Title:Dynamic Routing for Integrated Satellite-Terrestrial Networks: A  Constrained Multi-Agent Reinforcement Learning Approach",
        "authors": [
            "",
            "Authors:",
            "",
            "Yifeng Lyu",
            ",",
            "Han Hu",
            ",",
            "Rongfei Fan",
            ",",
            "Zhi Liu",
            ",",
            "Jianping An",
            ",",
            "Shiwen Mao",
            ""
        ],
        "abstract": "The integrated satellite-terrestrial network (ISTN) system has experienced\nsignificant growth, offering seamless communication services in remote areas\nwith limited terrestrial infrastructure. However, designing a routing scheme\nfor ISTN is exceedingly difficult, primarily due to the heightened complexity\nresulting from the inclusion of additional ground stations, along with the\nrequirement to satisfy various constraints related to satellite service\nquality. To address these challenges, we study packet routing with ground\nstations and satellites working jointly to transmit packets, while prioritizing\nfast communication and meeting energy efficiency and packet loss requirements.\nSpecifically, we formulate the problem of packet routing with constraints as a\nmax-min problem using the Lagrange method. Then we propose a novel constrained\nMulti-Agent reinforcement learning (MARL) dynamic routing algorithm named\nCMADR, which efficiently balances objective improvement and constraint\nsatisfaction during the updating of policy and Lagrange multipliers. Finally,\nwe conduct extensive experiments and an ablation study using the OneWeb and\nTelesat mega-constellations. Results demonstrate that CMADR reduces the packet\ndelay by a minimum of 21% and 15%, while meeting stringent energy consumption\nand packet loss rate constraints, outperforming several baseline algorithms.",
        "date": "Not Found"
    },
    {
        "title": "Title:Parametric Constraints for Bayesian Knowledge Tracing from First  Principles",
        "authors": [
            "",
            "Authors:",
            "",
            "Denis Shchepakin",
            ",",
            "Sreecharan Sankaranarayanan",
            ",",
            "Dawn Zimmaro",
            ""
        ],
        "abstract": "Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's\nstate of mastery corresponding to a knowledge component. It considers the\nlearner's state of mastery as a \"hidden\" or latent binary variable and updates\nthis state based on the observed correctness of the learner's response using\nparameters that represent transition probabilities between states. BKT is often\nrepresented as a Hidden Markov Model and the Expectation-Maximization (EM)\nalgorithm is used to infer these parameters. However, this algorithm can suffer\nfrom several issues including producing multiple viable sets of parameters,\nsettling into a local minima, producing degenerate parameter values, and a high\ncomputational cost during fitting. This paper takes a \"from first principles\"\napproach to deriving constraints that can be imposed on the BKT parameter\nspace. Starting from the basic mathematical truths of probability and building\nup to the behaviors expected of the BKT parameters in real systems, this paper\npresents a mathematical derivation that results in succinct constraints that\ncan be imposed on the BKT parameter space. Since these constraints are\nnecessary conditions, they can be applied prior to fitting in order to reduce\ncomputational cost and the likelihood of issues that can emerge from the EM\nprocedure. In order to see that promise through, the paper further introduces a\nnovel algorithm for estimating BKT parameters subject to the newly defined\nconstraints. While the issue of degenerate parameter values has been reported\npreviously, this paper is the first, to our best knowledge, to derive the\nconstrains from first principles while also presenting an algorithm that\nrespects those constraints.",
        "date": "Not Found"
    },
    {
        "title": "Title:Empowering Africa: An In-depth Exploration of the Adoption of Artificial  Intelligence Across the Continent",
        "authors": [
            "",
            "Authors:",
            "",
            "Kinyua Gikunda",
            ""
        ],
        "abstract": "This paper explores the dynamic landscape of Artificial Intelligence (AI)\nadoption in Africa, analysing its varied applications in addressing\nsocio-economic challenges and fostering development. Examining the African AI\necosystem, the study considers regional nuances, cultural factors, and\ninfrastructural constraints shaping the deployment of AI solutions. Case\nstudies in healthcare, agriculture, finance, and education highlight AI's\ntransformative potential for efficiency, accessibility, and inclusivity. The\npaper emphasizes indigenous AI innovations and international collaborations\ncontributing to a distinct African AI ecosystem. Ethical considerations,\nincluding data privacy and algorithmic bias, are addressed alongside policy\nframeworks supporting responsible AI implementation. The role of governmental\nbodies, regulations, and private sector partnerships is explored in creating a\nconducive AI development environment. Challenges such as digital literacy gaps\nand job displacement are discussed, with proposed strategies for mitigation. In\nconclusion, the paper provides a nuanced understanding of AI in Africa,\ncontributing to sustainable development discussions and advocating for an\ninclusive and ethical AI ecosystem on the continent.",
        "date": "Not Found"
    },
    {
        "title": "Title:What's my role? Modelling responsibility for AI-based safety-critical  systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Philippa Ryan",
            ",",
            "Zoe Porter",
            ",",
            "Joanna Al-Qaddoumi",
            ",",
            "John McDermid",
            ",",
            "Ibrahim Habli",
            ""
        ],
        "abstract": "AI-Based Safety-Critical Systems (AI-SCS) are being increasingly deployed in\nthe real world. These can pose a risk of harm to people and the environment.\nReducing that risk is an overarching priority during development and operation.\nAs more AI-SCS become autonomous, a layer of risk management via human\nintervention has been removed. Following an accident it will be important to\nidentify causal contributions and the different responsible actors behind those\nto learn from mistakes and prevent similar future events. Many authors have\ncommented on the \"responsibility gap\" where it is difficult for developers and\nmanufacturers to be held responsible for harmful behaviour of an AI-SCS. This\nis due to the complex development cycle for AI, uncertainty in AI performance,\nand dynamic operating environment. A human operator can become a \"liability\nsink\" absorbing blame for the consequences of AI-SCS outputs they weren't\nresponsible for creating, and may not have understanding of.\nThis cross-disciplinary paper considers different senses of responsibility\n(role, moral, legal and causal), and how they apply in the context of AI-SCS\nsafety. We use a core concept (Actor(A) is responsible for Occurrence(O)) to\ncreate role responsibility models, producing a practical method to capture\nresponsibility relationships and provide clarity on the previously identified\nresponsibility issues. Our paper demonstrates the approach with two examples: a\nretrospective analysis of the Tempe Arizona fatal collision involving an\nautonomous vehicle, and a safety focused predictive role-responsibility\nanalysis for an AI-based diabetes co-morbidity predictor. In both examples our\nprimary focus is on safety, aiming to reduce unfair or disproportionate blame\nbeing placed on operators or developers. We present a discussion and avenues\nfor future research.",
        "date": "Not Found"
    },
    {
        "title": "Title:Floating Point HUB Adder for RISC-V Sargantana Processor",
        "authors": [
            "",
            "Authors:",
            "",
            "Gerardo Bandera",
            ",",
            "Javier Salamero",
            ",",
            "Miquel Moreto",
            ",",
            "Julio Villalba",
            ""
        ],
        "abstract": "HUB format is an emerging technique to improve the hardware and time\nrequirement when round to nearest is needed. On the other hand, RISC-V is an\nopen-source ISA that many companies currently use in their designs. This paper\npresents a tailored floating point HUB adder implemented in the Sargantana\nRISC-V processor.",
        "date": "Not Found"
    },
    {
        "title": "Title:Offline Handwriting Signature Verification: A Transfer Learning and  Feature Selection Approach",
        "authors": [
            "",
            "Authors:",
            "",
            "Fatih Ozyurt",
            ",",
            "Jafar Majidpour",
            ",",
            "Tarik A. Rashid",
            ",",
            "Canan Koc",
            ""
        ],
        "abstract": "Handwritten signature verification poses a formidable challenge in biometrics\nand document authenticity. The objective is to ascertain the authenticity of a\nprovided handwritten signature, distinguishing between genuine and forged ones.\nThis issue has many applications in sectors such as finance, legal\ndocumentation, and security. Currently, the field of computer vision and\nmachine learning has made significant progress in the domain of handwritten\nsignature verification. The outcomes, however, may be enhanced depending on the\nacquired findings, the structure of the datasets, and the used models. Four\nstages make up our suggested strategy. First, we collected a large dataset of\n12600 images from 420 distinct individuals, and each individual has 30\nsignatures of a certain kind (All authors signatures are genuine). In the\nsubsequent stage, the best features from each image were extracted using a deep\nlearning model named MobileNetV2. During the feature selection step, three\nselectors neighborhood component analysis (NCA), Chi2, and mutual info (MI)\nwere used to pull out 200, 300, 400, and 500 features, giving a total of 12\nfeature vectors. Finally, 12 results have been obtained by applying machine\nlearning techniques such as SVM with kernels (rbf, poly, and linear), KNN, DT,\nLinear Discriminant Analysis, and Naive Bayes. Without employing feature\nselection techniques, our suggested offline signature verification achieved a\nclassification accuracy of 91.3%, whereas using the NCA feature selection\napproach with just 300 features it achieved a classification accuracy of 97.7%.\nHigh classification accuracy was achieved using the designed and suggested\nmodel, which also has the benefit of being a self-organized framework.\nConsequently, using the optimum minimally chosen features, the proposed method\ncould identify the best model performance and result validation prediction\nvectors.",
        "date": "Not Found"
    },
    {
        "title": "Title:Plug-in for visualizing 3D tool tracking from videos of Minimally  Invasive Surgeries",
        "authors": [
            "",
            "Authors:",
            "",
            "Shubhangi Nema",
            ",",
            "Abhishek Mathur",
            ",",
            "Leena Vachhani",
            ""
        ],
        "abstract": "This paper tackles instrument tracking and 3D visualization challenges in\nminimally invasive surgery (MIS), crucial for computer-assisted interventions.\nConventional and robot-assisted MIS encounter issues with limited 2D camera\nprojections and minimal hardware integration. The objective is to track and\nvisualize the entire surgical instrument, including shaft and metallic clasper,\nenabling safe navigation within the surgical environment. The proposed method\ninvolves 2D tracking based on segmentation maps, facilitating creation of\nlabeled dataset without extensive ground-truth knowledge. Geometric changes in\n2D intervals express motion, and kinematics based algorithms process results\ninto 3D tracking information. Synthesized and experimental results in 2D and 3D\nmotion estimates demonstrate negligible errors, validating the method for\nlabeling and motion tracking of instruments in MIS videos. The conclusion\nunderscores the proposed 2D segmentation technique's simplicity and\ncomputational efficiency, emphasizing its potential as direct plug-in for 3D\nvisualization in instrument tracking and MIS practices.",
        "date": "Not Found"
    },
    {
        "title": "Title:Business and ethical concerns in domestic Conversational Generative  AI-empowered multi-robot systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Rebekah Rousi",
            ",",
            "Hooman Samani",
            ",",
            "Niko M\u00e4kitalo",
            ",",
            "Ville Vakkuri",
            ",",
            "Simo Linkola",
            ",",
            "Kai-Kristian Kemell",
            ",",
            "Paulius Daubaris",
            ",",
            "Ilenia Fronza",
            ",",
            "Tommi Mikkonen",
            ",",
            "Pekka Abrahamsson",
            ""
        ],
        "abstract": "Business and technology are intricately connected through logic and design.\nThey are equally sensitive to societal changes and may be devastated by\nscandal. Cooperative multi-robot systems (MRSs) are on the rise, allowing\nrobots of different types and brands to work together in diverse contexts.\nGenerative artificial intelligence has been a dominant topic in recent\nartificial intelligence (AI) discussions due to its capacity to mimic humans\nthrough the use of natural language and the production of media, including deep\nfakes. In this article, we focus specifically on the conversational aspects of\ngenerative AI, and hence use the term Conversational Generative artificial\nintelligence (CGI). Like MRSs, CGIs have enormous potential for revolutionizing\nprocesses across sectors and transforming the way humans conduct business. From\na business perspective, cooperative MRSs alone, with potential conflicts of\ninterest, privacy practices, and safety concerns, require ethical examination.\nMRSs empowered by CGIs demand multi-dimensional and sophisticated methods to\nuncover imminent ethical pitfalls. This study focuses on ethics in\nCGI-empowered MRSs while reporting the stages of developing the MORUL model.",
        "date": "Not Found"
    },
    {
        "title": "Title:Weak Memory Demands Model-based Compiler Testing",
        "authors": [
            "",
            "Authors:",
            "",
            "Luke Geeson",
            ""
        ],
        "abstract": "A compiler bug arises if the behaviour of a compiled concurrent program, as\nallowed by its architecture memory model, is not a behaviour permitted by the\nsource program under its source model. One might reasonably think that most\ncompiler bugs have been found in the decade since the introduction of the C/C++\nmemory model. We observe that processor implementations are increasingly\nexploiting the behaviour of relaxed architecture models. As such, compiled\nprograms may exhibit bugs not seen on older hardware. To account for this we\nrequire model-based compiler testing.\nWhile this observation is not surprising, its implications are broad.\nCompilers and their testing tools will need to be updated to follow hardware\nrelaxations, concurrent test generators will need to be improved, and\nassumptions of prior work will need revisiting. We explore these ideas using a\ncompiler toolchain bug we reported in LLVM.",
        "date": "Not Found"
    },
    {
        "title": "Title:Triamese-ViT: A 3D-Aware Method for Robust Brain Age Estimation from  MRIs",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhaonian Zhang",
            ",",
            "Richard Jiang",
            ""
        ],
        "abstract": "The integration of machine learning in medicine has significantly improved\ndiagnostic precision, particularly in the interpretation of complex structures\nlike the human brain. Diagnosing challenging conditions such as Alzheimer's\ndisease has prompted the development of brain age estimation techniques. These\nmethods often leverage three-dimensional Magnetic Resonance Imaging (MRI)\nscans, with recent studies emphasizing the efficacy of 3D convolutional neural\nnetworks (CNNs) like 3D ResNet. However, the untapped potential of Vision\nTransformers (ViTs), known for their accuracy and interpretability, persists in\nthis domain due to limitations in their 3D versions. This paper introduces\nTriamese-ViT, an innovative adaptation of the ViT model for brain age\nestimation. Our model uniquely combines ViTs from three different orientations\nto capture 3D information, significantly enhancing accuracy and\ninterpretability. Tested on a dataset of 1351 MRI scans, Triamese-ViT achieves\na Mean Absolute Error (MAE) of 3.84, a 0.9 Spearman correlation coefficient\nwith chronological age, and a -0.29 Spearman correlation coefficient between\nthe brain age gap (BAG) and chronological age, significantly better than\nprevious methods for brian age estimation. A key innovation of Triamese-ViT is\nits capacity to generate a comprehensive 3D-like attention map, synthesized\nfrom 2D attention maps of each orientation-specific ViT. This feature is\nparticularly beneficial for in-depth brain age analysis and disease diagnosis,\noffering deeper insights into brain health and the mechanisms of age-related\nneural changes.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Framework for Agricultural Food Supply Chain using Blockchain",
        "authors": [
            "",
            "Authors:",
            "",
            "Sudarssan N",
            ""
        ],
        "abstract": "The main aim of the paper is to create a trust and transparency in the food\nsupply chain system, ensuring food safety for everyone with the help of\nBlockchain Technology. Food supply chain is the process of tracing a crop from\nthe farmer or producer to the buyer. With the advent of blockchain, providing a\nsafe and fraud-free environment for the provision of numerous agricultural\nnecessities has become much easier. Because of the globalization of trade, the\npresent supply chain market today includes various companies involving\nintegration of data, complex transactions and distribution. Information tamper\nresistance, supply-demand relationships, and traceable oversight are all\ndifficulties that arise as a result of this. Blockchain is a distributed ledger\ntechnology that can provide information that is resistant to tampering. This\nstrategy can eliminate the need for a centralized trusted authority,\nintermediaries, and business histories, allowing for increased production and\nsecurity while maintaining the highest levels of integrity, liability, and\nsafety. In order to have an integrity and transparency in food supply chain in\nthe agricultural sector, a framework is proposed here based on block chain and\nIoT.",
        "date": "Not Found"
    },
    {
        "title": "Title:Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep  Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Rahul Vishwakarma",
            ",",
            "Amin Rezaei",
            ""
        ],
        "abstract": "The risk of hardware Trojans being inserted at various stages of chip\nproduction has increased in a zero-trust fabless era. To counter this, various\nmachine learning solutions have been developed for the detection of hardware\nTrojans. While most of the focus has been on either a statistical or deep\nlearning approach, the limited number of Trojan-infected benchmarks affects the\ndetection accuracy and restricts the possibility of detecting zero-day Trojans.\nTo close the gap, we first employ generative adversarial networks to amplify\nour data in two alternative representation modalities, a graph and a tabular,\nensuring that the dataset is distributed in a representative manner. Further,\nwe propose a multimodal deep learning approach to detect hardware Trojans and\nevaluate the results from both early fusion and late fusion strategies. We also\nestimate the uncertainty quantification metrics of each prediction for\nrisk-aware decision-making. The outcomes not only confirms the efficacy of our\nproposed hardware Trojan detection method but also opens a new door for future\nstudies employing multimodality and uncertainty quantification to address other\nhardware security challenges.",
        "date": "Not Found"
    },
    {
        "title": "Title:LoMA: Lossless Compressed Memory Attention",
        "authors": [
            "",
            "Authors:",
            "",
            "Yumeng Wang",
            ",",
            "Zhenyang Xiao",
            ""
        ],
        "abstract": "The ability to handle long texts is one of the most important capabilities of\nLarge Language Models (LLMs), but as the text length increases, the consumption\nof resources also increases dramatically. At present, reducing resource\nconsumption by compressing the KV cache is a common approach. Although there\nare many existing compression methods, they share a common drawback: the\ncompression is not lossless. That is, information is inevitably lost during the\ncompression process. If the compression rate is high, the probability of losing\nimportant information increases dramatically. We propose a new method, Lossless\nCompressed Memory Attention (LoMA), which allows for lossless compression of\ninformation into special memory token KV pairs according to a set compression\nratio. Our experiments have achieved remarkable results, demonstrating that\nLoMA can be efficiently trained and has very effective performance.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Universal System for OpenID Connect Sign-ins with Verifiable  Credentials and Cross-Device Flow",
        "authors": [
            "",
            "Authors:",
            "",
            "Felix Hoops",
            ",",
            "Florian Matthes",
            ""
        ],
        "abstract": "Self-Sovereign Identity (SSI), as a new and promising identity management\nparadigm, needs mechanisms that can ease a gradual transition of existing\nservices and developers towards it. Systems that bridge the gap between SSI and\nestablished identity and access management have been proposed but still lack\nadoption. We argue that they are all some combination of too complex, locked\ninto specific ecosystems, have no source code available, or are not\nsufficiently documented. We propose a comparatively simple system that enables\nSSI-based sign-ins for services that support the widespread OpenID Connect or\nOAuth 2.0 protocols. Its handling of claims is highly configurable through a\nsingle policy and designed for cross-device authentication flows involving a\nsmartphone identity wallet. For external interfaces, we solely rely on open\nstandards, such as the recent OpenID for Verifiable Credentials standards. We\nprovide our implementation as open-source software intended for prototyping and\nas a reference. Also, we contribute a detailed technical discussion of our\nparticular sign-in flow. To prove its feasibility, we have successfully tested\nit with existing software and realistic hardware.",
        "date": "Not Found"
    },
    {
        "title": "Title:PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies",
        "authors": [
            "",
            "Authors:",
            "",
            "Audrey Der",
            ",",
            "Chin-Chia Michael Yeh",
            ",",
            "Yan Zheng",
            ",",
            "Junpeng Wang",
            ",",
            "Zhongfang Zhuang",
            ",",
            "Liang Wang",
            ",",
            "Wei Zhang",
            ",",
            "Eamonn J. Keogh",
            ""
        ],
        "abstract": "In recent years there has been significant progress in time series anomaly\ndetection. However, after detecting an (perhaps tentative) anomaly, can we\nexplain it? Such explanations would be useful to triage anomalies. For example,\nin an oil refinery, should we respond to an anomaly by dispatching a hydraulic\nengineer, or an intern to replace the battery on a sensor? There have been some\nparallel efforts to explain anomalies, however many proposed techniques produce\nexplanations that are indirect, and often seem more complex than the anomaly\nthey seek to explain. Our review of the literature/checklists/user-manuals used\nby frontline practitioners in various domains reveals an interesting\nnear-universal commonality. Most practitioners discuss, explain and report\nanomalies in the following format: The anomaly would be like normal data A, if\nnot for the corruption B. The reader will appreciate that is a type of\ncounterfactual explanation. In this work we introduce a domain agnostic\ncounterfactual explanation technique to produce explanations for time series\nanomalies. As we will show, our method can produce both visual and text-based\nexplanations that are objectively correct, intuitive and in many circumstances,\ndirectly actionable.",
        "date": "Not Found"
    },
    {
        "title": "Title:Memory, Space, and Planning: Multiscale Predictive Representations",
        "authors": [
            "",
            "Authors:",
            "",
            "Ida Momennejad",
            ""
        ],
        "abstract": "Memory is inherently entangled with prediction and planning. Flexible\nbehavior in biological and artificial agents depends on the interplay of\nlearning from the past and predicting the future in ever-changing environments.\nThis chapter reviews computational, behavioral, and neural evidence suggesting\nthese processes rely on learning the relational structure of experiences, known\nas cognitive maps, and draws two key takeaways. First, that these memory\nstructures are organized as multiscale, compact predictive representations in\nhippocampal and prefrontal cortex, or PFC, hierarchies. Second, we argue that\nsuch predictive memory structures are crucial to the complementary functions of\nthe hippocampus and PFC, both for enabling a recall of detailed and coherent\npast episodes as well as generalizing experiences at varying scales for\nefficient prediction and planning. These insights advance our understanding of\nmemory and planning mechanisms in the brain and hold significant implications\nfor advancing artificial intelligence systems.",
        "date": "Not Found"
    },
    {
        "title": "Title:Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian  Process Regression",
        "authors": [
            "",
            "Authors:",
            "",
            "Rub\u00e9n Antonio Garc\u00eda-Ruiz",
            ",",
            "Jos\u00e9 Luis Blanco-Claraco",
            ",",
            "Javier L\u00f3pez-Mart\u00ednez",
            ",",
            "\u00c1ngel Jes\u00fas Callej\u00f3n-Ferre",
            ""
        ],
        "abstract": "Expensive ultrasonic anemometers are usually required to measure wind speed\naccurately. The aim of this work is to overcome the loss of accuracy of a low\ncost hot-wire anemometer caused by the changes of air temperature, by means of\na probabilistic calibration using Gaussian Process Regression. Gaussian Process\nRegression is a non-parametric, Bayesian, and supervised learning method\ndesigned to make predictions of an unknown target variable as a function of one\nor more known input variables. Our approach is validated against real datasets,\nobtaining a good performance in inferring the actual wind speed values. By\nperforming, before its real use in the field, a calibration of the hot-wire\nanemometer taking into account air temperature, permits that the wind speed can\nbe estimated for the typical range of ambient temperatures, including a\ngrounded uncertainty estimation for each speed measure.",
        "date": "Not Found"
    },
    {
        "title": "Title:VeriBug: An Attention-based Framework for Bug-Localization in Hardware  Designs",
        "authors": [
            "",
            "Authors:",
            "",
            "Giuseppe Stracquadanio",
            ",",
            "Sourav Medya",
            ",",
            "Stefano Quer",
            ",",
            "Debjit Pal",
            ""
        ],
        "abstract": "In recent years, there has been an exponential growth in the size and\ncomplexity of System-on-Chip designs targeting different specialized\napplications. The cost of an undetected bug in these systems is much higher\nthan in traditional processor systems as it may imply the loss of property or\nlife. The problem is further exacerbated by the ever-shrinking time-to-market\nand ever-increasing demand to churn out billions of devices. Despite decades of\nresearch in simulation and formal methods for debugging and verification, it is\nstill one of the most time-consuming and resource intensive processes in\ncontemporary hardware design cycle. In this work, we propose VeriBug, which\nleverages recent advances in deep learning to accelerate debugging at the\nRegister-Transfer Level and generates explanations of likely root causes.\nFirst, VeriBug uses control-data flow graph of a hardware design and learns to\nexecute design statements by analyzing the context of operands and their\nassignments. Then, it assigns an importance score to each operand in a design\nstatement and uses that score for generating explanations for failures.\nFinally, VeriBug produces a heatmap highlighting potential buggy source code\nportions. Our experiments show that VeriBug can achieve an average bug\nlocalization coverage of 82.5% on open-source designs and different types of\ninjected bugs.",
        "date": "Not Found"
    },
    {
        "title": "Title:IPR-NeRF: Ownership Verification meets Neural Radiance Field",
        "authors": [
            "",
            "Authors:",
            "",
            "Win Kent Ong",
            ",",
            "Kam Woh Ng",
            ",",
            "Chee Seng Chan",
            ",",
            "Yi Zhe Song",
            ",",
            "Tao Xiang",
            ""
        ],
        "abstract": "Neural Radiance Field (NeRF) models have gained significant attention in the\ncomputer vision community in the recent past with state-of-the-art visual\nquality and produced impressive demonstrations. Since then, technopreneurs have\nsought to leverage NeRF models into a profitable business. Therefore, NeRF\nmodels make it worth the risk of plagiarizers illegally copying,\nre-distributing, or misusing those models. This paper proposes a comprehensive\nintellectual property (IP) protection framework for the NeRF model in both\nblack-box and white-box settings, namely IPR-NeRF. In the black-box setting, a\ndiffusion-based solution is introduced to embed and extract the watermark via a\ntwo-stage optimization process. In the white-box setting, a designated digital\nsignature is embedded into the weights of the NeRF model by adopting the sign\nloss objective. Our extensive experiments demonstrate that not only does our\napproach maintain the fidelity (\\ie, the rendering quality) of IPR-NeRF models,\nbut it is also robust against both ambiguity and removal attacks compared to\nprior arts.",
        "date": "Not Found"
    },
    {
        "title": "Title:Learning to Generalize over Subpartitions for Heterogeneity-aware Domain  Adaptive Nuclei Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Jianan Fan",
            ",",
            "Dongnan Liu",
            ",",
            "Hang Chang",
            ",",
            "Weidong Cai",
            ""
        ],
        "abstract": "Annotation scarcity and cross-modality/stain data distribution shifts are two\nmajor obstacles hindering the application of deep learning models for nuclei\nanalysis, which holds a broad spectrum of potential applications in digital\npathology. Recently, unsupervised domain adaptation (UDA) methods have been\nproposed to mitigate the distributional gap between different imaging\nmodalities for unsupervised nuclei segmentation in histopathology images.\nHowever, existing UDA methods are built upon the assumption that data\ndistributions within each domain should be uniform. Based on the\nover-simplified supposition, they propose to align the histopathology target\ndomain with the source domain integrally, neglecting severe intra-domain\ndiscrepancy over subpartitions incurred by mixed cancer types and sampling\norgans. In this paper, for the first time, we propose to explicitly consider\nthe heterogeneity within the histopathology domain and introduce open compound\ndomain adaptation (OCDA) to resolve the crux. In specific, a two-stage\ndisentanglement framework is proposed to acquire domain-invariant feature\nrepresentations at both image and instance levels. The holistic design\naddresses the limitations of existing OCDA approaches which struggle to capture\ninstance-wise variations. Two regularization strategies are specifically\ndevised herein to leverage the rich subpartition-specific characteristics in\nhistopathology images and facilitate subdomain decomposition. Moreover, we\npropose a dual-branch nucleus shape and structure preserving module to prevent\nnucleus over-generation and deformation in the synthesized images. Experimental\nresults on both cross-modality and cross-stain scenarios over a broad range of\ndiverse datasets demonstrate the superiority of our method compared with\nstate-of-the-art UDA and OCDA methods.",
        "date": "Not Found"
    },
    {
        "title": "Title:Technical Report: On the Convergence of Gossip Learning in the Presence  of Node Inaccessibility",
        "authors": [
            "",
            "Authors:",
            "",
            "Tian Liu",
            ",",
            "Yue Cui",
            ",",
            "Xueyang Hu",
            ",",
            "Yecheng Xu",
            ",",
            "Bo Liu",
            ""
        ],
        "abstract": "Gossip learning (GL), as a decentralized alternative to federated learning\n(FL), is more suitable for resource-constrained wireless networks, such as\nFANETs that are formed by unmanned aerial vehicles (UAVs). GL can significantly\nenhance the efficiency and extend the battery life of UAV networks. Despite the\nadvantages, the performance of GL is strongly affected by data distribution,\ncommunication speed, and network connectivity. However, how these factors\ninfluence the GL convergence is still unclear. Existing work studied the\nconvergence of GL based on a virtual quantity for the sake of convenience,\nwhich fail to reflect the real state of the network when some nodes are\ninaccessible. In this paper, we formulate and investigate the impact of\ninaccessible nodes to GL under a dynamic network topology. We first decompose\nthe weight divergence by whether the node is accessible or not. Then, we\ninvestigate the GL convergence under the dynamic of node accessibility and\ntheoretically provide how the number of inaccessible nodes, data\nnon-i.i.d.-ness, and duration of inaccessibility affect the convergence.\nExtensive experiments are carried out in practical settings to comprehensively\nverify the correctness of our theoretical findings.",
        "date": "Not Found"
    },
    {
        "title": "Title:Functional Autoencoder for Smoothing and Representation Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Sidi Wu",
            ",",
            "C\u00e9dric Beaulac",
            ",",
            "Jiguo Cao",
            ""
        ],
        "abstract": "A common pipeline in functional data analysis is to first convert the\ndiscretely observed data to smooth functions, and then represent the functions\nby a finite-dimensional vector of coefficients summarizing the information.\nExisting methods for data smoothing and dimensional reduction mainly focus on\nlearning the linear mappings from the data space to the representation space,\nhowever, learning only the linear representations may not be sufficient. In\nthis study, we propose to learn the nonlinear representations of functional\ndata using neural network autoencoders designed to process data in the form it\nis usually collected without the need of preprocessing. We design the encoder\nto employ a projection layer computing the weighted inner product of the\nfunctional data and functional weights over the observed timestamp, and the\ndecoder to apply a recovery layer that maps the finite-dimensional vector\nextracted from the functional data back to functional space using a set of\npredetermined basis functions. The developed architecture can accommodate both\nregularly and irregularly spaced data. Our experiments demonstrate that the\nproposed method outperforms functional principal component analysis in terms of\nprediction and classification, and maintains superior smoothing ability and\nbetter computational efficiency in comparison to the conventional autoencoders\nunder both linear and nonlinear settings.",
        "date": "Not Found"
    },
    {
        "title": "Title:Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in  Online Advertising",
        "authors": [
            "",
            "Authors:",
            "",
            "Shuai Yang",
            ",",
            "Hao Yang",
            ",",
            "Zhuang Zou",
            ",",
            "Linhe Xu",
            ",",
            "Shuo Yuan",
            ",",
            "Yifan Zeng",
            ""
        ],
        "abstract": "In the e-commerce advertising scenario, estimating the true probabilities\n(known as a calibrated estimate) on CTR and CVR is critical and can directly\naffect the benefits of the buyer, seller and platform. Previous research has\nintroduced numerous solutions for addressing the calibration problem. These\nmethods typically involve the training of calibrators using a validation set\nand subsequently applying these calibrators to correct the original estimated\nvalues during online inference. However, what sets e-commerce advertising\nscenarios is the challenge of multi-field calibration. Multi-field calibration\ncan be subdivided into two distinct sub-problems: value calibration and shape\ncalibration. Value calibration is defined as no over- or under-estimation for\neach value under concerned fields. Shape calibration is defined as no over- or\nunder-estimation for each subset of the pCTR within the specified range under\ncondition of concerned fields. In order to achieve shape calibration and value\ncalibration, it is necessary to have a strong data utilization ability.Because\nthe quantity of pCTR specified range for single field-value sample is relative\nsmall, which makes the calibrator more difficult to train. However the existing\nmethods cannot simultaneously fulfill both value calibration and shape\ncalibration. To solve these problems, we propose a new method named Deep\nEnsemble Shape Calibration (DESC). We introduce innovative basis calibration\nfunctions, which enhance both function expression capabilities and data\nutilization by combining these basis calibration functions. A significant\nadvancement lies in the development of an allocator capable of allocating the\nmost suitable shape calibrators to different estimation error distributions\nwithin diverse fields and values.",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploration of Activation Fault Reliability in Quantized Systolic  Array-Based DNN Accelerators",
        "authors": [
            "",
            "Authors:",
            "",
            "Mahdi Taheri",
            ",",
            "Natalia Cherezova",
            ",",
            "Mohammad Saeed Ansari",
            ",",
            "Maksim Jenihhin",
            ",",
            "Ali Mahani",
            ",",
            "Masoud Daneshtalab",
            ",",
            "Jaan Raik",
            ""
        ],
        "abstract": "The stringent requirements for the Deep Neural Networks (DNNs) accelerator's\nreliability stand along with the need for reducing the computational burden on\nthe hardware platforms, i.e. reducing the energy consumption and execution time\nas well as increasing the efficiency of DNN accelerators. Moreover, the growing\ndemand for specialized DNN accelerators with tailored requirements,\nparticularly for safety-critical applications, necessitates a comprehensive\ndesign space exploration to enable the development of efficient and robust\naccelerators that meet those requirements. Therefore, the trade-off between\nhardware performance, i.e. area and delay, and the reliability of the DNN\naccelerator implementation becomes critical and requires tools for analysis.\nThis paper presents a comprehensive methodology for exploring and enabling a\nholistic assessment of the trilateral impact of quantization on model accuracy,\nactivation fault reliability, and hardware efficiency. A fully automated\nframework is introduced that is capable of applying various quantization-aware\ntechniques, fault injection, and hardware implementation, thus enabling the\nmeasurement of hardware parameters. Moreover, this paper proposes a novel\nlightweight protection technique integrated within the framework to ensure the\ndependable deployment of the final systolic-array-based FPGA implementation.\nThe experiments on established benchmarks demonstrate the analysis flow and the\nprofound implications of quantization on reliability, hardware performance, and\nnetwork accuracy, particularly concerning the transient faults in the network's\nactivations.",
        "date": "Not Found"
    },
    {
        "title": "Title:Community Detection in the Multi-View Stochastic Block Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Yexin Zhang",
            ",",
            "Zhongtian Ma",
            ",",
            "Qiaosheng Zhang",
            ",",
            "Zhen Wang",
            ",",
            "Xuelong Li",
            ""
        ],
        "abstract": "This paper considers the problem of community detection on multiple\npotentially correlated graphs from an information-theoretical perspective. We\nfirst put forth a random graph model, called the multi-view stochastic block\nmodel (MVSBM), designed to generate correlated graphs on the same set of nodes\n(with cardinality $n$). The $n$ nodes are partitioned into two disjoint\ncommunities of equal size. The presence or absence of edges in the graphs for\neach pair of nodes depends on whether the two nodes belong to the same\ncommunity or not. The objective for the learner is to recover the hidden\ncommunities with observed graphs. Our technical contributions are two-fold: (i)\nWe establish an information-theoretic upper bound (Theorem~1) showing that\nexact recovery of community is achievable when the model parameters of MVSBM\nexceed a certain threshold. (ii) Conversely, we derive an information-theoretic\nlower bound (Theorem~2) showing that when the model parameters of MVSBM fall\nbelow the aforementioned threshold, then for any estimator, the expected number\nof misclassified nodes will always be greater than one. Our results for the\nMVSBM recover several prior results for community detection in the standard SBM\nas well as in multiple independent SBMs as special cases.",
        "date": "Not Found"
    },
    {
        "title": "Title:MLAAD: The Multi-Language Audio Anti-Spoofing Dataset",
        "authors": [
            "",
            "Authors:",
            "",
            "Nicolas M. M\u00fcller",
            ",",
            "Piotr Kawa",
            ",",
            "Wei Herng Choong",
            ",",
            "Edresson Casanova",
            ",",
            "Eren G\u00f6lge",
            ",",
            "Thorsten M\u00fcller",
            ",",
            "Piotr Syga",
            ",",
            "Philip Sperl",
            ",",
            "Konstantin B\u00f6ttinger",
            ""
        ],
        "abstract": "Text-to-Speech (TTS) technology brings significant advantages, such as giving\na voice to those with speech impairments, but also enables audio deepfakes and\nspoofs. The former mislead individuals and may propagate misinformation, while\nthe latter undermine voice biometric security systems. AI-based detection can\nhelp to address these challenges by automatically differentiating between\ngenuine and fabricated voice recordings. However, these models are only as good\nas their training data, which currently is severely limited due to an\noverwhelming concentration on English and Chinese audio in anti-spoofing\ndatabases, thus restricting its worldwide effectiveness. In response, this\npaper presents the Multi-Language Audio Anti-Spoof Dataset (MLAAD), created\nusing 52 TTS models, comprising 19 different architectures, to generate 160.1\nhours of synthetic voice in 23 different languages. We train and evaluate three\nstate-of-the-art deepfake detection models with MLAAD, and observe that MLAAD\ndemonstrates superior performance over comparable datasets like InTheWild or\nFakeOrReal when used as a training resource. Furthermore, in comparison with\nthe renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary\nresource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately\noutperformed each other, both excelling on four datasets. By publishing MLAAD\nand making trained models accessible via an interactive webserver , we aim to\ndemocratize antispoofing technology, making it accessible beyond the realm of\nspecialists, thus contributing to global efforts against audio spoofing and\ndeepfakes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhancing Surveillance Camera FOV Quality via Semantic Line Detection  and Classification with Deep Hough Transform",
        "authors": [
            "",
            "Authors:",
            "",
            "Andrew C. Freeman",
            ",",
            "Wenjing Shi",
            ",",
            "Bin Hwang",
            ""
        ],
        "abstract": "The quality of recorded videos and images is significantly influenced by the\ncamera's field of view (FOV). In critical applications like surveillance\nsystems and self-driving cars, an inadequate FOV can give rise to severe safety\nand security concerns, including car accidents and thefts due to the failure to\ndetect individuals and objects. The conventional methods for establishing the\ncorrect FOV heavily rely on human judgment and lack automated mechanisms to\nassess video and image quality based on FOV. In this paper, we introduce an\ninnovative approach that harnesses semantic line detection and classification\nalongside deep Hough transform to identify semantic lines, thus ensuring a\nsuitable FOV by understanding 3D view through parallel lines. Our approach\nyields an effective F1 score of 0.729 on the public EgoCart dataset, coupled\nwith a notably high median score in the line placement metric. We illustrate\nthat our method offers a straightforward means of assessing the quality of the\ncamera's field of view, achieving a classification accuracy of 83.8\\%. This\nmetric can serve as a proxy for evaluating the potential performance of video\nand image quality applications.",
        "date": "Not Found"
    },
    {
        "title": "Title:Accelerating Data Generation for Neural Operators via Krylov Subspace  Recycling",
        "authors": [
            "",
            "Authors:",
            "",
            "Hong Wang",
            ",",
            "Zhongkai Hao",
            ",",
            "Jie Wang",
            ",",
            "Zijie Geng",
            ",",
            "Zhen Wang",
            ",",
            "Bin Li",
            ",",
            "Feng Wu",
            ""
        ],
        "abstract": "Learning neural operators for solving partial differential equations (PDEs)\nhas attracted great attention due to its high inference efficiency. However,\ntraining such operators requires generating a substantial amount of labeled\ndata, i.e., PDE problems together with their solutions. The data generation\nprocess is exceptionally time-consuming, as it involves solving numerous\nsystems of linear equations to obtain numerical solutions to the PDEs. Many\nexisting methods solve these systems independently without considering their\ninherent similarities, resulting in extremely redundant computations. To tackle\nthis problem, we propose a novel method, namely Sorting Krylov Recycling (SKR),\nto boost the efficiency of solving these systems, thus significantly\naccelerating data generation for neural operators training. To the best of our\nknowledge, SKR is the first attempt to address the time-consuming nature of\ndata generation for learning neural operators. The working horse of SKR is\nKrylov subspace recycling, a powerful technique for solving a series of\ninterrelated systems by leveraging their inherent similarities. Specifically,\nSKR employs a sorting algorithm to arrange these systems in a sequence, where\nadjacent systems exhibit high similarities. Then it equips a solver with Krylov\nsubspace recycling to solve the systems sequentially instead of independently,\nthus effectively enhancing the solving efficiency. Both theoretical analysis\nand extensive experiments demonstrate that SKR can significantly accelerate\nneural operator data generation, achieving a remarkable speedup of up to 13.9\ntimes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Dimensional Neuroimaging Endophenotypes: Neurobiological Representations  of Disease Heterogeneity Through Machine Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Junhao Wen",
            ",",
            "Mathilde Antoniades",
            ",",
            "Zhijian Yang",
            ",",
            "Gyujoon Hwang",
            ",",
            "Ioanna Skampardoni",
            ",",
            "Rongguang Wang",
            ",",
            "Christos Davatzikos",
            ""
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized\nneuroimaging signatures for disease diagnosis, prognosis, and response to\ntreatment in neuropsychiatric and neurodegenerative disorders. Therefore, it\nhas contributed to a better understanding of disease heterogeneity by\nidentifying disease subtypes that present significant differences in various\nbrain phenotypic measures. In this review, we first present a systematic\nliterature overview of studies using machine learning and multimodal MRI to\nunravel disease heterogeneity in various neuropsychiatric and neurodegenerative\ndisorders, including Alzheimer disease, schizophrenia, major depressive\ndisorder, autism spectrum disorder, multiple sclerosis, as well as their\npotential in transdiagnostic settings. Subsequently, we summarize relevant\nmachine learning methodologies and discuss an emerging paradigm which we call\ndimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological\nheterogeneity of neuropsychiatric and neurodegenerative disorders into a low\ndimensional yet informative, quantitative brain phenotypic representation,\nserving as a robust intermediate phenotype (i.e., endophenotype) largely\nreflecting underlying genetics and etiology. Finally, we discuss the potential\nclinical implications of the current findings and envision future research\navenues.",
        "date": "Not Found"
    },
    {
        "title": "Title:On-Off Pattern Encoding and Path-Count Encoding as Deep Neural Network  Representations",
        "authors": [
            "",
            "Authors:",
            "",
            "Euna Jung",
            ",",
            "Jaekeol Choi",
            ",",
            "EungGu Yun",
            ",",
            "Wonjong Rhee",
            ""
        ],
        "abstract": "Understanding the encoded representation of Deep Neural Networks (DNNs) has\nbeen a fundamental yet challenging objective. In this work, we focus on two\npossible directions for analyzing representations of DNNs by studying simple\nimage classification tasks. Specifically, we consider \\textit{On-Off pattern}\nand \\textit{PathCount} for investigating how information is stored in deep\nrepresentations. On-off pattern of a neuron is decided as `on' or `off'\ndepending on whether the neuron's activation after ReLU is non-zero or zero.\nPathCount is the number of paths that transmit non-zero energy from the input\nto a neuron. We investigate how neurons in the network encodes information by\nreplacing each layer's activation with On-Off pattern or PathCount and\nevaluating its effect on classification performance. We also examine\ncorrelation between representation and PathCount. Finally, we show a possible\nway to improve an existing DNN interpretation method, Class Activation Map\n(CAM), by directly utilizing On-Off or PathCount.",
        "date": "Not Found"
    },
    {
        "title": "Title:Privacy Engineering in Smart Home (SH) Systems: A Comprehensive Privacy  Threat Analysis and Risk Management Approach",
        "authors": [
            "",
            "Authors:",
            "",
            "Emmanuel Dare Alalade",
            ",",
            "Mohammed Mahyoub",
            ",",
            "Ashraf Matrawy",
            ""
        ],
        "abstract": "Addressing trust concerns in Smart Home (SH) systems is imperative due to the\nlimited study on preservation approaches that focus on analyzing and evaluating\nprivacy threats for effective risk management. While most research focuses\nprimarily on user privacy, device data privacy, especially identity privacy, is\nalmost neglected, which can significantly impact overall user privacy within\nthe SH system. To this end, our study incorporates privacy engineering (PE)\nprinciples in the SH system that consider user and device data privacy. We\nstart with a comprehensive reference model for a typical SH system. Based on\nthe initial stage of LINDDUN PRO for the PE framework, we present a data flow\ndiagram (DFD) based on a typical SH reference model to better understand SH\nsystem operations. To identify potential areas of privacy threat and perform a\nprivacy threat analysis (PTA), we employ the LINDDUN PRO threat model. Then, a\nprivacy impact assessment (PIA) was carried out to implement privacy risk\nmanagement by prioritizing privacy threats based on their likelihood of\noccurrence and potential consequences. Finally, we suggest possible privacy\nenhancement techniques (PETs) that can mitigate some of these threats. The\nstudy aims to elucidate the main threats to privacy, associated risks, and\neffective prioritization of privacy control in SH systems. The outcomes of this\nstudy are expected to benefit SH stakeholders, including vendors, cloud\nproviders, users, researchers, and regulatory bodies in the SH systems domain.",
        "date": "Not Found"
    },
    {
        "title": "Title:Port-Hamiltonian Neural ODE Networks on Lie Groups For Robot Dynamics  Learning and Control",
        "authors": [
            "",
            "Authors:",
            "",
            "Thai Duong",
            ",",
            "Abdullah Altawaitan",
            ",",
            "Jason Stanley",
            ",",
            "Nikolay Atanasov",
            ""
        ],
        "abstract": "Accurate models of robot dynamics are critical for safe and stable control\nand generalization to novel operational conditions. Hand-designed models,\nhowever, may be insufficiently accurate, even after careful parameter tuning.\nThis motivates the use of machine learning techniques to approximate the robot\ndynamics over a training set of state-control trajectories. The dynamics of\nmany robots are described in terms of their generalized coordinates on a matrix\nLie group, e.g. on SE(3) for ground, aerial, and underwater vehicles, and\ngeneralized velocity, and satisfy conservation of energy principles. This paper\nproposes a (port-)Hamiltonian formulation over a Lie group of the structure of\na neural ordinary differential equation (ODE) network to approximate the robot\ndynamics. In contrast to a black-box ODE network, our formulation guarantees\nenergy conservation principle and Lie group's constraints by construction and\nexplicitly accounts for energy-dissipation effect such as friction and drag\nforces in the dynamics model. We develop energy shaping and damping injection\ncontrol for the learned, potentially under-actuated Hamiltonian dynamics to\nenable a unified approach for stabilization and trajectory tracking with\nvarious robot platforms.",
        "date": "Not Found"
    },
    {
        "title": "Title:Token Jumping in Planar Graphs has Linear Sized Kernels",
        "authors": [
            "",
            "Authors:",
            "",
            "Daniel W. Cranston",
            ""
        ],
        "abstract": "Let $G$ be a planar graph and $I_s$ and $I_t$ be two independent sets in $G$,\neach of size $k$. We begin with a ``token'' on each vertex of $I_s$ and seek to\nmove all tokens to $I_t$, by repeated ``token jumping'', removing a single\ntoken from one vertex and placing it on another vertex. We require that each\nintermediate arrangement of tokens again specifies an independent set of size\n$k$. Given $G$, $I_s$, and $I_t$, we ask whether there exists a sequence of\ntoken jumps that transforms $I_s$ to $I_t$. When $k$ is part of the input, this\nproblem is known to be PSPACE-complete. However, it was shown by Ito,\nKami\\'nski, and Ono to be fixed-parameter tractable. That is, when $k$ is\nfixed, the problem can be solved in time polynomial in the order of $G$. Here\nwe strengthen the upper bound on the running time in terms of $k$ by showing\nthat the problem has a kernel of size linear in $k$. More precisely, we\ntransform an arbitrary input problem on a planar graph into an equivalent\nproblem on a (planar) graph with order $O(k)$.",
        "date": "Not Found"
    },
    {
        "title": "Title:BERTologyNavigator: Advanced Question Answering with BERT-based  Semantics",
        "authors": [
            "",
            "Authors:",
            "",
            "Shreya Rajpal",
            "(1,2),",
            "Ricardo Usbeck",
            "(1) ((1) Universit\u00e4t Hamburg, Hamburg, Germany,(2) Vellore Institute of Technology, Vellore, Tamil Nadu, India)"
        ],
        "abstract": "The development and integration of knowledge graphs and language models has\nsignificance in artificial intelligence and natural language processing. In\nthis study, we introduce the BERTologyNavigator -- a two-phased system that\ncombines relation extraction techniques and BERT embeddings to navigate the\nrelationships within the DBLP Knowledge Graph (KG). Our approach focuses on\nextracting one-hop relations and labelled candidate pairs in the first phases.\nThis is followed by employing BERT's CLS embeddings and additional heuristics\nfor relation selection in the second phase. Our system reaches an F1 score of\n0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score\non the subset of the DBLP QuAD test dataset during the QA phase.",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving Classification Performance With Human Feedback: Label a few,  we label the rest",
        "authors": [
            "",
            "Authors:",
            "",
            "Natan Vidra",
            ",",
            "Thomas Clifford",
            ",",
            "Katherine Jijo",
            ",",
            "Eden Chung",
            ",",
            "Liang Zhang",
            ""
        ],
        "abstract": "In the realm of artificial intelligence, where a vast majority of data is\nunstructured, obtaining substantial amounts of labeled data to train supervised\nmachine learning models poses a significant challenge. To address this, we\ndelve into few-shot and active learning, where are goal is to improve AI models\nwith human feedback on a few labeled examples. This paper focuses on\nunderstanding how a continuous feedback loop can refine models, thereby\nenhancing their accuracy, recall, and precision through incremental human\ninput. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and\nSetFit, we aim to analyze the efficacy of using a limited number of labeled\nexamples to substantially improve model accuracy. We benchmark this approach on\nthe Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to\nprove that with just a few labeled examples, we are able to surpass the\naccuracy of zero shot large language models to provide enhanced text\nclassification performance. We demonstrate that rather than needing to manually\nlabel millions of rows of data, we just need to label a few and the model can\neffectively predict the rest.",
        "date": "Not Found"
    },
    {
        "title": "Title:Sharing Knowledge in Multi-Task Deep Reinforcement Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Carlo D'Eramo",
            ",",
            "Davide Tateo",
            ",",
            "Andrea Bonarini",
            ",",
            "Marcello Restelli",
            ",",
            "Jan Peters",
            ""
        ],
        "abstract": "We study the benefit of sharing representations among tasks to enable the\neffective use of deep neural networks in Multi-Task Reinforcement Learning. We\nleverage the assumption that learning from different tasks, sharing common\nproperties, is helpful to generalize the knowledge of them resulting in a more\neffective feature extraction compared to learning a single task. Intuitively,\nthe resulting set of features offers performance benefits when used by\nReinforcement Learning algorithms. We prove this by providing theoretical\nguarantees that highlight the conditions for which is convenient to share\nrepresentations among tasks, extending the well-known finite-time bounds of\nApproximate Value-Iteration to the multi-task setting. In addition, we\ncomplement our analysis by proposing multi-task extensions of three\nReinforcement Learning algorithms that we empirically evaluate on widely used\nReinforcement Learning benchmarks showing significant improvements over the\nsingle-task counterparts in terms of sample efficiency and performance.",
        "date": "Not Found"
    },
    {
        "title": "Title:Aligning Large Language Models with Counterfactual DPO",
        "authors": [
            "",
            "Authors:",
            "",
            "Bradley Butcher",
            ""
        ],
        "abstract": "Advancements in large language models (LLMs) have demonstrated remarkable\ncapabilities across a diverse range of applications. These models excel in\ngenerating text completions that are contextually coherent and cover an\nextensive array of subjects. However, the vast datasets required for their\ntraining make aligning response styles during the pretraining and instruction\ntuning phases challenging. Consequently, an additional alignment phase is\ntypically employed, wherein the model is further trained with human preference\ndata to better align its outputs with human expectations. While this process\ndoesn't introduce new capabilities per se, it does accentuate generation styles\ninnate to the model. This paper explores the utilization of counterfactual\nprompting within the framework of Direct Preference Optimization (DPO) to align\nthe model's style without relying on human intervention. We demonstrate that\nthis method effectively instils desirable behaviour, mitigates undesirable\nones, and encourages the model to disregard inappropriate instructions. Our\nfindings suggest that counterfactual prompting with DPO presents a low-resource\nway to fine-tune LLMs to meet the demands for responsible and ethically aligned\nAI systems.",
        "date": "Not Found"
    },
    {
        "title": "Title:Handling Large-scale Cardinality in building recommendation systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Dhruva Dixith Kurra",
            ",",
            "Bo Ling",
            ",",
            "Chun Zh",
            ",",
            "Seyedshahin Ashrafzadeh",
            ""
        ],
        "abstract": "Effective recommendation systems rely on capturing user preferences, often\nrequiring incorporating numerous features such as universally unique\nidentifiers (UUIDs) of entities. However, the exceptionally high cardinality of\nUUIDs poses a significant challenge in terms of model degradation and increased\nmodel size due to sparsity. This paper presents two innovative techniques to\naddress the challenge of high cardinality in recommendation systems.\nSpecifically, we propose a bag-of-words approach, combined with layer sharing,\nto substantially decrease the model size while improving performance. Our\ntechniques were evaluated through offline and online experiments on Uber use\ncases, resulting in promising results demonstrating our approach's\neffectiveness in optimizing recommendation systems and enhancing their overall\nperformance.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Scalable and Robust Model Versioning",
        "authors": [
            "",
            "Authors:",
            "",
            "Wenxin Ding",
            ",",
            "Arjun Nitin Bhagoji",
            ",",
            "Ben Y. Zhao",
            ",",
            "Haitao Zheng",
            ""
        ],
        "abstract": "As the deployment of deep learning models continues to expand across\nindustries, the threat of malicious incursions aimed at gaining access to these\ndeployed models is on the rise. Should an attacker gain access to a deployed\nmodel, whether through server breaches, insider attacks, or model inversion\ntechniques, they can then construct white-box adversarial attacks to manipulate\nthe model's classification outcomes, thereby posing significant risks to\norganizations that rely on these models for critical tasks. Model owners need\nmechanisms to protect themselves against such losses without the necessity of\nacquiring fresh training data - a process that typically demands substantial\ninvestments in time and capital.\nIn this paper, we explore the feasibility of generating multiple versions of\na model that possess different attack properties, without acquiring new\ntraining data or changing model architecture. The model owner can deploy one\nversion at a time and replace a leaked version immediately with a new version.\nThe newly deployed model version can resist adversarial attacks generated\nleveraging white-box access to one or all previously leaked versions. We show\ntheoretically that this can be accomplished by incorporating parameterized\nhidden distributions into the model training data, forcing the model to learn\ntask-irrelevant features uniquely defined by the chosen data. Additionally,\noptimal choices of hidden distributions can produce a sequence of model\nversions capable of resisting compound transferability attacks over time.\nLeveraging our analytical insights, we design and implement a practical model\nversioning method for DNN classifiers, which leads to significant robustness\nimprovements over existing methods. We believe our work presents a promising\ndirection for safeguarding DNN services beyond their initial deployment.",
        "date": "Not Found"
    },
    {
        "title": "Title:Zero Trust Implementation in the Emerging Technologies Era: Survey",
        "authors": [
            "",
            "Authors:",
            "",
            "Abraham Itzhak Weinberg",
            ",",
            "Kelly Cohen",
            ""
        ],
        "abstract": "This paper presents a comprehensive analysis of the shift from the\ntraditional perimeter model of security to the Zero Trust (ZT) framework,\nemphasizing the key points in the transition and the practical application of\nZT. It outlines the differences between ZT policies and legacy security\npolicies, along with the significant events that have impacted the evolution of\nZT. Additionally, the paper explores the potential impacts of emerging\ntechnologies, such as Artificial Intelligence (AI) and quantum computing, on\nthe policy and implementation of ZT. The study thoroughly examines how AI can\nenhance ZT by utilizing Machine Learning (ML) algorithms to analyze patterns,\ndetect anomalies, and predict threats, thereby improving real-time\ndecision-making processes. Furthermore, the paper demonstrates how a chaos\ntheory-based approach, in conjunction with other technologies like eXtended\nDetection and Response (XDR), can effectively mitigate cyberattacks. As quantum\ncomputing presents new challenges to ZT and cybersecurity as a whole, the paper\ndelves into the intricacies of ZT migration, automation, and orchestration,\naddressing the complexities associated with these aspects. Finally, the paper\nprovides a best practice approach for the seamless implementation of ZT in\norganizations, laying out the proposed guidelines to facilitate organizations\nin their transition towards a more secure ZT model. The study aims to support\norganizations in successfully implementing ZT and enhancing their cybersecurity\nmeasures.",
        "date": "Not Found"
    },
    {
        "title": "Title:eipy: An Open-Source Python Package for Multi-modal Data Integration  using Heterogeneous Ensembles",
        "authors": [
            "",
            "Authors:",
            "",
            "Jamie J. R. Bennett",
            ",",
            "Yan Chak Li",
            ",",
            "Gaurav Pandey",
            ""
        ],
        "abstract": "In this paper, we introduce eipy--an open-source Python package for\ndeveloping effective, multi-modal heterogeneous ensembles for classification.\neipy simultaneously provides both a rigorous, and user-friendly framework for\ncomparing and selecting the best-performing multi-modal data integration and\npredictive modeling methods by systematically evaluating their performance\nusing nested cross-validation. The package is designed to leverage\nscikit-learn-like estimators as components to build multi-modal predictive\nmodels. An up-to-date user guide, including API reference and tutorials, for\neipy is maintained at https://eipy.readthedocs.io . The main repository for\nthis project can be found on GitHub at https://github.com/GauravPandeyLab/eipy .",
        "date": "Not Found"
    },
    {
        "title": "Title:Lower Bounds on $0$-Extension with Steiner Nodes",
        "authors": [
            "",
            "Authors:",
            "",
            "Yu Chen",
            ",",
            "Zihan Tan",
            ""
        ],
        "abstract": "In the $0$-Extension problem, we are given an edge-weighted graph\n$G=(V,E,c)$, a set $T\\subseteq V$ of its vertices called terminals, and a\nsemi-metric $D$ over $T$, and the goal is to find an assignment $f$ of each\nnon-terminal vertex to a terminal, minimizing the sum, over all edges $(u,v)\\in\nE$, the product of the edge weight $c(u,v)$ and the distance $D(f(u),f(v))$\nbetween the terminals that $u,v$ are mapped to. Current best approximation\nalgorithms on $0$-Extension are based on rounding a linear programming\nrelaxation called the \\emph{semi-metric LP relaxation}. The integrality gap of\nthis LP, with best upper bound $O(\\log |T|/\\log\\log |T|)$ and best lower bound\n$\\Omega((\\log |T|)^{2/3})$, has been shown to be closely related to the best\nquality of cut and flow vertex sparsifiers.\nWe study a variant of the $0$-Extension problem where Steiner vertices are\nallowed. Specifically, we focus on the integrality gap of the same semi-metric\nLP relaxation to this new problem. Following from previous work, this new\nintegrality gap turns out to be closely related to the quality achievable by\ncut/flow vertex sparsifiers with Steiner nodes, a major open problem in graph\ncompression. Our main result is that the new integrality gap stays\nsuperconstant $\\Omega(\\log\\log |T|)$ even if we allow a super-linear\n$O(|T|\\log^{1-\\varepsilon}|T|)$ number of Steiner nodes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Bilevel Optimization under Unbounded Smoothness: A New Algorithm and  Convergence Analysis",
        "authors": [
            "",
            "Authors:",
            "",
            "Jie Hao",
            ",",
            "Xiaochuan Gong",
            ",",
            "Mingrui Liu",
            ""
        ],
        "abstract": "Bilevel optimization is an important formulation for many machine learning\nproblems. Current bilevel optimization algorithms assume that the gradient of\nthe upper-level function is Lipschitz. However, recent studies reveal that\ncertain neural networks such as recurrent neural networks (RNNs) and\nlong-short-term memory networks (LSTMs) exhibit potential unbounded smoothness,\nrendering conventional bilevel optimization algorithms unsuitable. In this\npaper, we design a new bilevel optimization algorithm, namely BO-REP, to\naddress this challenge. This algorithm updates the upper-level variable using\nnormalized momentum and incorporates two novel techniques for updating the\nlower-level variable: \\textit{initialization refinement} and \\textit{periodic\nupdates}. Specifically, once the upper-level variable is initialized, a\nsubroutine is invoked to obtain a refined estimate of the corresponding optimal\nlower-level variable, and the lower-level variable is updated only after every\nspecific period instead of each iteration. When the upper-level problem is\nnonconvex and unbounded smooth, and the lower-level problem is strongly convex,\nwe prove that our algorithm requires $\\widetilde{\\mathcal{O}}(1/\\epsilon^4)$\niterations to find an $\\epsilon$-stationary point in the stochastic setting,\nwhere each iteration involves calling a stochastic gradient or Hessian-vector\nproduct oracle. Notably, this result matches the state-of-the-art complexity\nresults under the bounded smoothness setting and without mean-squared\nsmoothness of the stochastic gradient, up to logarithmic factors. Our proof\nrelies on novel technical lemmas for the periodically updated lower-level\nvariable, which are of independent interest. Our experiments on\nhyper-representation learning, hyperparameter optimization, and data\nhyper-cleaning for text classification tasks demonstrate the effectiveness of\nour proposed algorithm.",
        "date": "Not Found"
    },
    {
        "title": "Title:Bringing Social Computing to Secondary School Classrooms",
        "authors": [
            "",
            "Authors:",
            "",
            "Kianna Bolante",
            ",",
            "Kevin Chen",
            ",",
            "Quan Ze Chen",
            ",",
            "Amy Zhang",
            ""
        ],
        "abstract": "Social computing is the study of how technology shapes human social\ninteractions. This topic has become increasingly relevant to secondary school\nstudents (ages 11--18) as more of young people's everyday social experiences\ntake place online, particularly with the continuing effects of the COVID-19\npandemic. However, social computing topics are rarely touched upon in existing\nmiddle and high school curricula. We seek to introduce concepts from social\ncomputing to secondary school students so they can understand how computing has\nwide-ranging social implications that touch upon their everyday lives, as well\nas think critically about both the positive and negative sides of different\nsocial technology designs.\nIn this report, we present a series of six lessons combining presentations\nand hands-on activities covering topics within social computing and detail our\nexperience teaching these lessons to approximately 1,405 students across 13\nmiddle and high schools in our local school district. We developed lessons\ncovering how social computing relates to the topics of Data Management,\nEncrypted Messaging, Human-Computer Interaction Careers, Machine Learning and\nBias, Misinformation, and Online Behavior. We found that 81.13% of students\nexpressed greater interest in the content of our lessons compared to their\ninterest in STEM overall. We also found from pre- and post-lesson comprehension\nquestions that 63.65% learned new concepts from the main activity. We release\nall lesson materials on a website for public use. From our experience, we\nobserved that students were engaged in these topics and found enjoyment in\nfinding connections between computing and their own lives.",
        "date": "Not Found"
    },
    {
        "title": "Title:Efficient generative adversarial networks using linear  additive-attention Transformers",
        "authors": [
            "",
            "Authors:",
            "",
            "Emilio Morales-Juarez",
            ",",
            "Gibran Fuentes-Pineda",
            ""
        ],
        "abstract": "Although the capacity of deep generative models for image generation, such as\nDiffusion Models (DMs) and Generative Adversarial Networks (GANs), has\ndramatically improved in recent years, much of their success can be attributed\nto computationally expensive architectures. This has limited their adoption and\nuse to research laboratories and companies with large resources, while\nsignificantly raising the carbon footprint for training, fine-tuning, and\ninference. In this work, we present LadaGAN, an efficient generative\nadversarial network that is built upon a novel Transformer block named\nLadaformer. The main component of this block is a linear additive-attention\nmechanism that computes a single attention vector per head instead of the\nquadratic dot-product attention. We employ Ladaformer in both the generator and\ndiscriminator, which reduces the computational complexity and overcomes the\ntraining instabilities often associated with Transformer GANs. LadaGAN\nconsistently outperforms existing convolutional and Transformer GANs on\nbenchmark datasets at different resolutions while being significantly more\nefficient. Moreover, LadaGAN shows competitive performance compared to\nstate-of-the-art multi-step generative models (e.g. DMs) using orders of\nmagnitude less computational resources.",
        "date": "Not Found"
    },
    {
        "title": "Title:Transient dynamics under structured perturbations: bridging unstructured  and structured pseudospectra",
        "authors": [
            "",
            "Authors:",
            "",
            "Christian Lubich",
            ",",
            "Nicola Guglielmi",
            ""
        ],
        "abstract": "The structured $\\varepsilon$-stability radius is introduced as a quantity to\nassess the robustness of transient bounds of solutions to linear differential\nequations under structured perturbations of the matrix. This applies to general\nlinear structures such as complex or real matrices with a given sparsity\npattern or with restricted range and corange, or special classes such as\nToeplitz matrices. The notion conceptually combines unstructured and structured\npseudospectra in a joint pseudospectrum, allowing for the use of resolvent\nbounds as with unstructured pseudospectra and for structured perturbations as\nwith structured pseudospectra. We propose and study an algorithm for computing\nthe structured $\\varepsilon$-stability radius. This algorithm solves eigenvalue\noptimization problems via suitably discretized rank-1 matrix differential\nequations that originate from a gradient system. The proposed algorithm has\nessentially the same computational cost as the known rank-1 algorithms for\ncomputing unstructured and structured stability radii. Numerical experiments\nillustrate the behavior of the algorithm.",
        "date": "Not Found"
    },
    {
        "title": "Title:Rethinking FID: Towards a Better Evaluation Metric for Image Generation",
        "authors": [
            "",
            "Authors:",
            "",
            "Sadeep Jayasumana",
            ",",
            "Srikumar Ramalingam",
            ",",
            "Andreas Veit",
            ",",
            "Daniel Glasner",
            ",",
            "Ayan Chakrabarti",
            ",",
            "Sanjiv Kumar",
            ""
        ],
        "abstract": "As with many machine learning problems, the progress of image generation\nmethods hinges on good evaluation metrics. One of the most popular is the\nFrechet Inception Distance (FID). FID estimates the distance between a\ndistribution of Inception-v3 features of real images, and those of images\ngenerated by the algorithm. We highlight important drawbacks of FID:\nInception's poor representation of the rich and varied content generated by\nmodern text-to-image models, incorrect normality assumptions, and poor sample\ncomplexity. We call for a reevaluation of FID's use as the primary quality\nmetric for generated images. We empirically demonstrate that FID contradicts\nhuman raters, it does not reflect gradual improvement of iterative\ntext-to-image models, it does not capture distortion levels, and that it\nproduces inconsistent results when varying the sample size. We also propose an\nalternative new metric, CMMD, based on richer CLIP embeddings and the maximum\nmean discrepancy distance with the Gaussian RBF kernel. It is an unbiased\nestimator that does not make any assumptions on the probability distribution of\nthe embeddings and is sample efficient. Through extensive experiments and\nanalysis, we demonstrate that FID-based evaluations of text-to-image models may\nbe unreliable, and that CMMD offers a more robust and reliable assessment of\nimage quality.",
        "date": "Not Found"
    },
    {
        "title": "Title:MedBlindTuner: Towards Privacy-preserving Fine-tuning on Biomedical  Images with Transformers and Fully Homomorphic Encryption",
        "authors": [
            "",
            "Authors:",
            "",
            "Prajwal Panzade",
            ",",
            "Daniel Takabi",
            ",",
            "Zhipeng Cai",
            ""
        ],
        "abstract": "Advancements in machine learning (ML) have significantly revolutionized\nmedical image analysis, prompting hospitals to rely on external ML services.\nHowever, the exchange of sensitive patient data, such as chest X-rays, poses\ninherent privacy risks when shared with third parties. Addressing this concern,\nwe propose MedBlindTuner, a privacy-preserving framework leveraging fully\nhomomorphic encryption (FHE) and a data-efficient image transformer (DEiT).\nMedBlindTuner enables the training of ML models exclusively on FHE-encrypted\nmedical images. Our experimental evaluation demonstrates that MedBlindTuner\nachieves comparable accuracy to models trained on non-encrypted images,\noffering a secure solution for outsourcing ML computations while preserving\npatient data privacy. To the best of our knowledge, this is the first work that\nuses data-efficient image transformers and fully homomorphic encryption in this\ndomain.",
        "date": "Not Found"
    },
    {
        "title": "Title:Charting a Path to Efficient Onboarding: The Role of Software  Visualization",
        "authors": [
            "",
            "Authors:",
            "",
            "Fernando Padoan",
            ",",
            "Ronnie de Souza Santos",
            ",",
            "Rodrigo Pessoa Medeiros",
            ""
        ],
        "abstract": "Background. Within the software industry, it is commonly estimated that\nsoftware professionals invest a substantial portion of their work hours in the\nprocess of understanding existing systems. In this context, an ineffective\ntechnical onboarding process, which introduces newcomers to software under\ndevelopment, can result in a prolonged period for them to absorb the necessary\nknowledge required to become productive in their roles. Goal. The present study\naims to explore the familiarity of managers, leaders, and developers with\nsoftware visualization tools and how these tools are employed to facilitate the\ntechnical onboarding of new team members. Method. To address the research\nproblem, we built upon the insights gained through the literature and embraced\na sequential exploratory approach. This approach incorporated quantitative and\nqualitative analyses of data collected from practitioners using questionnaires\nand semi-structured interviews. Findings. Our findings demonstrate a gap\nbetween the concept of software visualization and the practical use of\nonboarding tools and techniques. Overall, practitioners do not systematically\nincorporate software visualization tools into their technical onboarding\nprocesses due to a lack of conceptual understanding and awareness of their\npotential benefits. Conclusion. The software industry could benefit from\nstandardized and evolving onboarding models, improved by incorporating software\nvisualization techniques and tools to support program comprehension of\nnewcomers in the software projects.",
        "date": "Not Found"
    },
    {
        "title": "Title:Robustness Evaluation of Machine Learning Models for Robot Arm Action  Recognition in Noisy Environments",
        "authors": [
            "",
            "Authors:",
            "",
            "Elaheh Motamedi",
            ",",
            "Kian Behzad",
            ",",
            "Rojin Zandi",
            ",",
            "Hojjat Salehinejad",
            ",",
            "Milad Siami",
            ""
        ],
        "abstract": "In the realm of robot action recognition, identifying distinct but spatially\nproximate arm movements using vision systems in noisy environments poses a\nsignificant challenge. This paper studies robot arm action recognition in noisy\nenvironments using machine learning techniques. Specifically, a vision system\nis used to track the robot's movements followed by a deep learning model to\nextract the arm's key points. Through a comparative analysis of machine\nlearning methods, the effectiveness and robustness of this model are assessed\nin noisy environments. A case study was conducted using the Tic-Tac-Toe game in\na 3-by-3 grid environment, where the focus is to accurately identify the\nactions of the arms in selecting specific locations within this constrained\nenvironment. Experimental results show that our approach can achieve precise\nkey point detection and action classification despite the addition of noise and\nuncertainties to the dataset.",
        "date": "Not Found"
    },
    {
        "title": "Title:Land Cover Image Classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Antonio Rangel",
            ",",
            "Juan Terven",
            ",",
            "Diana M. Cordova-Esparza",
            ",",
            "E.A. Chavez-Urbiola",
            ""
        ],
        "abstract": "Land Cover (LC) image classification has become increasingly significant in\nunderstanding environmental changes, urban planning, and disaster management.\nHowever, traditional LC methods are often labor-intensive and prone to human\nerror. This paper explores state-of-the-art deep learning models for enhanced\naccuracy and efficiency in LC analysis. We compare convolutional neural\nnetworks (CNN) against transformer-based methods, showcasing their applications\nand advantages in LC studies. We used EuroSAT, a patch-based LC classification\ndata set based on Sentinel-2 satellite images and achieved state-of-the-art\nresults using current transformer models.",
        "date": "Not Found"
    },
    {
        "title": "Title:Hidden Populations in Software Engineering: Challenges, Lessons Learned,  and Opportunities",
        "authors": [
            "",
            "Authors:",
            "",
            "Ronnie de Souza Santos",
            ",",
            "Kiev Gama",
            ""
        ],
        "abstract": "The growing emphasis on studying equity, diversity, and inclusion within\nsoftware engineering has amplified the need to explore hidden populations\nwithin this field. Exploring hidden populations becomes important to obtain\ninvaluable insights into the experiences, challenges, and perspectives of\nunderrepresented groups in software engineering and, therefore, devise\nstrategies to make the software industry more diverse. However, studying these\nhidden populations presents multifaceted challenges, including the complexities\nassociated with identifying and engaging participants due to their marginalized\nstatus. In this paper, we discuss our experiences and lessons learned while\nconducting multiple studies involving hidden populations in software\nengineering. We emphasize the importance of recognizing and addressing these\nchallenges within the software engineering research community to foster a more\ninclusive and comprehensive understanding of diverse populations of software\nprofessionals.",
        "date": "Not Found"
    },
    {
        "title": "Title:Learning Shortcuts: On the Misleading Promise of NLU in Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Geetanjali Bihani",
            ",",
            "Julia Taylor Rayz",
            ""
        ],
        "abstract": "The advent of large language models (LLMs) has enabled significant\nperformance gains in the field of natural language processing. However, recent\nstudies have found that LLMs often resort to shortcuts when performing tasks,\ncreating an illusion of enhanced performance while lacking generalizability in\ntheir decision rules. This phenomenon introduces challenges in accurately\nassessing natural language understanding in LLMs. Our paper provides a concise\nsurvey of relevant research in this area and puts forth a perspective on the\nimplications of shortcut learning in the evaluation of language models,\nspecifically for NLU tasks. This paper urges more research efforts to be put\ntowards deepening our comprehension of shortcut learning, contributing to the\ndevelopment of more robust language models, and raising the standards of NLU\nevaluation in real-world scenarios.",
        "date": "Not Found"
    },
    {
        "title": "Title:Cost-effective and performant virtual WANs with CORNIFER",
        "authors": [
            "",
            "Authors:",
            "",
            "Anjali",
            ",",
            "Rachee Singh",
            ",",
            "Michael M. Swift",
            ""
        ],
        "abstract": "Virtual wide-area networks (WANs) are WAN-as-a-service cloud offerings that\naim to bring the performance benefits of dedicated wide-area interconnects to\nenterprise customers. In this work, we show that the topology of a virtual WAN\ncan render it both performance and cost inefficient. We develop Cornifer, a\ntool that designs virtual WAN topologies by deciding the number of virtual WAN\nnodes and their location in the cloud to minimize connection latency at low\ncost to enterprises. By leveraging millions of latency measurements from\nvantage points across the world to cloud points of presence, Cornifer designs\nvirtual WAN topologies that improve weighted client latency by 26% and lower\ncost by 28% compared to the state-of-the-art. Cornifer identifies virtual WAN\ntopologies at the Pareto frontier of the deployment cost vs. connection latency\ntrade-off and proposes a heuristic for automatic selection of Pareto-optimal\nvirtual WAN topologies for enterprises.",
        "date": "Not Found"
    },
    {
        "title": "Title:XTable in Action: Seamless Interoperability in Data Lakes",
        "authors": [
            "",
            "Authors:",
            "",
            "Ashvin Agrawal",
            ",",
            "Tim Brown",
            ",",
            "Anoop Johnson",
            ",",
            "Jes\u00fas Camacho-Rodr\u00edguez",
            ",",
            "Kyle Weller",
            ",",
            "Carlo Curino",
            ",",
            "Raghu Ramakrishnan",
            ""
        ],
        "abstract": "Contemporary approaches to data management are increasingly relying on\nunified analytics and AI platforms to foster collaboration, interoperability,\nseamless access to reliable data, and high performance. Data Lakes featuring\nopen standard table formats such as Delta Lake, Apache Hudi, and Apache Iceberg\nare central components of these data architectures. Choosing the right format\nfor managing a table is crucial for achieving the objectives mentioned above.\nThe challenge lies in selecting the best format, a task that is onerous and can\nyield temporary results, as the ideal choice may shift over time with data\ngrowth, evolving workloads, and the competitive development of table formats\nand processing engines. Moreover, restricting data access to a single format\ncan hinder data sharing resulting in diminished business value over the long\nterm. The ability to seamlessly interoperate between formats and with\nnegligible overhead can effectively address these challenges. Our solution in\nthis direction is an innovative omni-directional translator, XTable, that\nfacilitates writing data in one format and reading it in any format, thus\nachieving the desired format interoperability. In this work, we demonstrate the\neffectiveness of XTable through application scenarios inspired by real-world\nuse cases.",
        "date": "Not Found"
    },
    {
        "title": "Title:SMOOTHIE: A Theory of Hyper-parameter Optimization for Software  Analytics",
        "authors": [
            "",
            "Authors:",
            "",
            "Rahul Yedida",
            ",",
            "Tim Menzies",
            ""
        ],
        "abstract": "Hyper-parameter optimization is the black art of tuning a learner's control\nparameters. In software analytics, a repeated result is that such tuning can\nresult in dramatic performance improvements. Despite this, hyper-parameter\noptimization is often applied rarely or poorly in software analytics--perhaps\ndue to the CPU cost of exploring all those parameter options can be\nprohibitive.\nWe theorize that learners generalize better when the loss landscape is\n``smooth''. This theory is useful since the influence on ``smoothness'' of\ndifferent hyper-parameter choices can be tested very quickly (e.g. for a deep\nlearner, after just one epoch).\nTo test this theory, this paper implements and tests SMOOTHIE, a novel\nhyper-parameter optimizer that guides its optimizations via considerations of\n``smothness''. The experiments of this paper test SMOOTHIE on numerous SE tasks\nincluding (a) GitHub issue lifetime prediction; (b) detecting false alarms in\nstatic code warnings; (c) defect prediction, and (d) a set of standard ML\ndatasets. In all these experiments, SMOOTHIE out-performed state-of-the-art\noptimizers. Better yet, SMOOTHIE ran 300% faster than the prior state-of-the\nart. We hence conclude that this theory (that hyper-parameter optimization is\nbest viewed as a ``smoothing'' function for the decision landscape), is both\ntheoretically interesting and practically very useful.\nTo support open science and other researchers working in this area, all our\nscripts and datasets are available on-line at\nhttps://github.com/yrahul3910/smoothness-hpo/.",
        "date": "Not Found"
    },
    {
        "title": "Title:Polynomial Convergence of Bandit No-Regret Dynamics in Congestion Games",
        "authors": [
            "",
            "Authors:",
            "",
            "Leello Dadi",
            ",",
            "Ioannis Panageas",
            ",",
            "Stratis Skoulakis",
            ",",
            "Luca Viano",
            ",",
            "Volkan Cevher",
            ""
        ],
        "abstract": "We introduce an online learning algorithm in the bandit feedback model that,\nonce adopted by all agents of a congestion game, results in game-dynamics that\nconverge to an $\\epsilon$-approximate Nash Equilibrium in a polynomial number\nof rounds with respect to $1/\\epsilon$, the number of players and the number of\navailable resources. The proposed algorithm also guarantees sublinear regret to\nany agent adopting it. As a result, our work answers an open question from\narXiv:2206.01880 and extends the recent results of arXiv:2306.15543 to the\nbandit feedback model. We additionally establish that our online learning\nalgorithm can be implemented in polynomial time for the important special case\nof Network Congestion Games on Directed Acyclic Graphs (DAG) by constructing an\nexact $1$-barycentric spanner for DAGs.",
        "date": "Not Found"
    },
    {
        "title": "Title:Multiple Locally Linear Kernel Machines",
        "authors": [
            "",
            "Authors:",
            "",
            "David Picard",
            ""
        ],
        "abstract": "In this paper we propose a new non-linear classifier based on a combination\nof locally linear classifiers. A well known optimization formulation is given\nas we cast the problem in a $\\ell_1$ Multiple Kernel Learning (MKL) problem\nusing many locally linear kernels. Since the number of such kernels is huge, we\nprovide a scalable generic MKL training algorithm handling streaming kernels.\nWith respect to the inference time, the resulting classifier fits the gap\nbetween high accuracy but slow non-linear classifiers (such as classical MKL)\nand fast but low accuracy linear classifiers.",
        "date": "Not Found"
    },
    {
        "title": "Title:Physics-Informed Calibration of Aeromagnetic Compensation in Magnetic  Navigation Systems using Liquid Time-Constant Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Favour Nerrise",
            "(1 and 2),",
            "Andrew Sosa Sosanya",
            "(2),",
            "Patrick Neary",
            "(2) ((1) Department of Electrical Engineering, Stanford University, CA, USA, (2) SandboxAQ, Palo Alto, CA, USA)"
        ],
        "abstract": "Magnetic navigation (MagNav) is a rising alternative to the Global\nPositioning System (GPS) and has proven useful for aircraft navigation.\nTraditional aircraft navigation systems, while effective, face limitations in\nprecision and reliability in certain environments and against attacks. Airborne\nMagNav leverages the Earth's magnetic field to provide accurate positional\ninformation. However, external magnetic fields induced by aircraft electronics\nand Earth's large-scale magnetic fields disrupt the weaker signal of interest.\nWe introduce a physics-informed approach using Tolles-Lawson coefficients for\ncompensation and Liquid Time-Constant Networks (LTCs) to remove complex, noisy\nsignals derived from the aircraft's magnetic sources. Using real flight data\nwith magnetometer measurements and aircraft measurements, we observe up to a\n64% reduction in aeromagnetic compensation error (RMSE nT), outperforming\nconventional models. This significant improvement underscores the potential of\na physics-informed, machine learning approach for extracting clean, reliable,\nand accurate magnetic signals for MagNav positional estimation.",
        "date": "Not Found"
    },
    {
        "title": "Title:Impact of Large Language Model Assistance on Patients Reading Clinical  Notes: A Mixed-Methods Study",
        "authors": [
            "",
            "Authors:",
            "",
            "Niklas Mannhardt",
            ",",
            "Elizabeth Bondi-Kelly",
            ",",
            "Barbara Lam",
            ",",
            "Chloe O'Connell",
            ",",
            "Mercy Asiedu",
            ",",
            "Hussein Mozannar",
            ",",
            "Monica Agrawal",
            ",",
            "Alejandro Buendia",
            ",",
            "Tatiana Urman",
            ",",
            "Irbaz B. Riaz",
            ",",
            "Catherine E. Ricciardi",
            ",",
            "Marzyeh Ghassemi",
            ",",
            "David Sontag",
            ""
        ],
        "abstract": "Patients derive numerous benefits from reading their clinical notes,\nincluding an increased sense of control over their health and improved\nunderstanding of their care plan. However, complex medical concepts and jargon\nwithin clinical notes hinder patient comprehension and may lead to anxiety. We\ndeveloped a patient-facing tool to make clinical notes more readable,\nleveraging large language models (LLMs) to simplify, extract information from,\nand add context to notes. We prompt engineered GPT-4 to perform these\naugmentation tasks on real clinical notes donated by breast cancer survivors\nand synthetic notes generated by a clinician, a total of 12 notes with 3868\nwords. In June 2023, 200 female-identifying US-based participants were randomly\nassigned three clinical notes with varying levels of augmentations using our\ntool. Participants answered questions about each note, evaluating their\nunderstanding of follow-up actions and self-reported confidence. We found that\naugmentations were associated with a significant increase in action\nunderstanding score (0.63 $\\pm$ 0.04 for select augmentations, compared to 0.54\n$\\pm$ 0.02 for the control) with p=0.002. In-depth interviews of\nself-identifying breast cancer patients (N=7) were also conducted via video\nconferencing. Augmentations, especially definitions, elicited positive\nresponses among the seven participants, with some concerns about relying on\nLLMs. Augmentations were evaluated for errors by clinicians, and we found\nmisleading errors occur, with errors more common in real donated notes than\nsynthetic notes, illustrating the importance of carefully written clinical\nnotes. Augmentations improve some but not all readability metrics. This work\ndemonstrates the potential of LLMs to improve patients' experience with\nclinical notes at a lower burden to clinicians. However, having a human in the\nloop is important to correct potential model errors.",
        "date": "Not Found"
    },
    {
        "title": "Title:Blackout Mitigation via Physics-guided RL",
        "authors": [
            "",
            "Authors:",
            "",
            "Anmol Dwivedi",
            ",",
            "Santiago Paternain",
            ",",
            "Ali Tajer",
            ""
        ],
        "abstract": "This paper considers the sequential design of remedial control actions in\nresponse to system anomalies for the ultimate objective of preventing\nblackouts. A physics-guided reinforcement learning (RL) framework is designed\nto identify effective sequences of real-time remedial look-ahead decisions\naccounting for the long-term impact on the system's stability. The paper\nconsiders a space of control actions that involve both discrete-valued\ntransmission line-switching decisions (line reconnections and removals) and\ncontinuous-valued generator adjustments. To identify an effective blackout\nmitigation policy, a physics-guided approach is designed that uses power-flow\nsensitivity factors associated with the power transmission network to guide the\nRL exploration during agent training. Comprehensive empirical evaluations using\nthe open-source Grid2Op platform demonstrate the notable advantages of\nincorporating physical signals into RL decisions, establishing the gains of the\nproposed physics-guided approach compared to its black box counterparts. One\nimportant observation is that strategically~\\emph{removing} transmission lines,\nin conjunction with multiple real-time generator adjustments, often renders\neffective long-term decisions that are likely to prevent or delay blackouts.",
        "date": "Not Found"
    },
    {
        "title": "Title:Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "",
            "Authors:",
            "",
            "Tian-Le Yang",
            ",",
            "Kuang-Yao Lee",
            ",",
            "Kun Zhang",
            ",",
            "Joe Suzuki",
            ""
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the\ncomplete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM),\nencompassing both the causal ordering of variables and their respective\nconnection strengths. However, LiNGAM can only deal with the finite-dimensional\ncase. To expand this concept, we extend the notion of variables to encompass\nvectors and even functions, leading to the Functional Linear Non-Gaussian\nAcyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify\ncausal relationships in brain-effective connectivity tasks involving, for\nexample, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to\nhandle these inherently infinite-dimensional datasets and explain the\navailability of functional data analysis from both empirical and theoretical\nperspectives. {We establish theoretical guarantees of the identifiability of\nthe causal relationship among non-Gaussian random vectors and even random\nfunctions in infinite-dimensional Hilbert spaces.} To address the issue of\nsparsity in discrete time points within intrinsic infinite-dimensional\nfunctional data, we propose optimizing the coordinates of the vectors using\nfunctional principal component analysis. Experimental results on synthetic data\nverify the ability of the proposed framework to identify causal relationships\namong multivariate functions using the observed samples. For real data, we\nfocus on analyzing the brain connectivity patterns derived from fMRI data.",
        "date": "Not Found"
    },
    {
        "title": "Title:ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on  Climate Change",
        "authors": [
            "",
            "Authors:",
            "",
            "David Thulke",
            ",",
            "Yingbo Gao",
            ",",
            "Petrus Pelser",
            ",",
            "Rein Brune",
            ",",
            "Rricha Jalota",
            ",",
            "Floris Fok",
            ",",
            "Michael Ramos",
            ",",
            "Ian van Wyk",
            ",",
            "Abdallah Nasir",
            ",",
            "Hayden Goldstein",
            ",",
            "Taylor Tragemann",
            ",",
            "Katie Nguyen",
            ",",
            "Ariana Fowler",
            ",",
            "Andrew Stanco",
            ",",
            "Jon Gabriel",
            ",",
            "Jordan Taylor",
            ",",
            "Dean Moro",
            ",",
            "Evgenii Tsymbalov",
            ",",
            "Juliette de Waal",
            ",",
            "Evgeny Matusov",
            ",",
            "Mudar Yaghi",
            ",",
            "Mohammad Shihadah",
            ",",
            "Hermann Ney",
            ",",
            "Christian Dugast",
            ",",
            "Jonathan Dotan",
            ",",
            "Daniel Erasmus",
            ""
        ],
        "abstract": "This paper introduces ClimateGPT, a model family of domain-specific large\nlanguage models that synthesize interdisciplinary research on climate change.\nWe trained two 7B models from scratch on a science-oriented dataset of 300B\ntokens. For the first model, the 4.2B domain-specific tokens were included\nduring pre-training and the second was adapted to the climate domain after\npre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously\npre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each\nmodel is instruction fine-tuned on a high-quality and human-generated\ndomain-specific dataset that has been created in close cooperation with climate\nscientists. To reduce the number of hallucinations, we optimize the model for\nretrieval augmentation and propose a hierarchical retrieval strategy. To\nincrease the accessibility of our model to non-English speakers, we propose to\nmake use of cascaded machine translation and show that this approach can\nperform comparably to natively multilingual models while being easier to scale\nto a large number of languages. Further, to address the intrinsic\ninterdisciplinary aspect of climate change we consider different research\nperspectives. Therefore, the model can produce in-depth answers focusing on\ndifferent perspectives in addition to an overall answer. We propose a suite of\nautomatic climate-specific benchmarks to evaluate LLMs. On these benchmarks,\nClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model\nwhile not degrading results on general domain benchmarks. Our human evaluation\nconfirms the trends we saw in our benchmarks. All models were trained and\nevaluated using renewable energy and are released publicly.",
        "date": "Not Found"
    },
    {
        "title": "Title:Characterizing Online Eating Disorder Communities with Large Language  Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Minh Duc Chu",
            ",",
            "Aryan Karnati",
            ",",
            "Zihao He",
            ",",
            "Kristina Lerman",
            ""
        ],
        "abstract": "The rise in eating disorders, a dangerous mental health condition with high\nmortality and morbidity, has been linked to the proliferation of idealized body\nimages on social media. However, the link between social media and eating\ndisorders is far more complex. We argue that social media platforms create a\nfeedback loop that amplifies the growth of content and communities that promote\neating disorders like anorexia and bulimia. Specifically, social media\nplatforms make it easy for vulnerable individuals to find and connect to\nlike-minded others, while group dynamic processes encourage them to stay\nengaged within communities that promote and glorify harmful behaviors linked to\neating disorders. We characterize this dynamic empirically through a\ncombination of network and language analysis. We describe a novel framework\nthat leverages large language models to analyze the discourse within online\ncommunities and probe their attitudes on topics related to eating disorders to\nidentify potentially harmful content. Our work emphasizes the need for better\nsocial media moderation to disrupt harmful feedback loops and protect\nvulnerable individuals.",
        "date": "Not Found"
    },
    {
        "title": "Title:Convex and Bilevel Optimization for Neuro-Symbolic Inference and  Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Charles Dickens",
            ",",
            "Changyu Gao",
            ",",
            "Connor Pryor",
            ",",
            "Stephen Wright",
            ",",
            "Lise Getoor",
            ""
        ],
        "abstract": "We address a key challenge for neuro-symbolic (NeSy) systems by leveraging\nconvex and bilevel optimization techniques to develop a general gradient-based\nframework for end-to-end neural and symbolic parameter learning. The\napplicability of our framework is demonstrated with NeuPSL, a state-of-the-art\nNeSy architecture. To achieve this, we propose a smooth primal and dual\nformulation of NeuPSL inference and show learning gradients are functions of\nthe optimal dual variables. Additionally, we develop a dual block coordinate\ndescent algorithm for the new formulation that naturally exploits warm-starts.\nThis leads to over 100x learning runtime improvements over the current best\nNeuPSL inference method. Finally, we provide extensive empirical evaluations\nacross $8$ datasets covering a range of tasks and demonstrate our learning\nframework achieves up to a 16% point prediction performance improvement over\nalternative learning methods.",
        "date": "Not Found"
    },
    {
        "title": "Title:User Study: Comparison of Picture Passwords and Current Login Approaches",
        "authors": [
            "",
            "Authors:",
            "",
            "Ignacio Astaburuaga",
            ""
        ],
        "abstract": "In this research, we conduct a user study that compares different\ncomputer/system authentication methods. More specifically, we look into\ncomparing regular password authentication with picture authentication. Picture\nauthentication means selecting a sequence of pictures from a set of pictures\n(30). We present users with both interfaces; various metrics are tracked while\nthe participants conduct a variety of user authentication-related tasks. Other\nmetrics include user perception of security with such technologies.",
        "date": "Not Found"
    },
    {
        "title": "Title:Mobility Accelerates Learning: Convergence Analysis on Hierarchical  Federated Learning in Vehicular Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Tan Chen",
            ",",
            "Jintao Yan",
            ",",
            "Yuxuan Sun",
            ",",
            "Sheng Zhou",
            ",",
            "Deniz G\u00fcnd\u00fcz",
            ",",
            "Zhisheng Niu",
            ""
        ],
        "abstract": "Hierarchical federated learning (HFL) enables distributed training of models\nacross multiple devices with the help of several edge servers and a cloud edge\nserver in a privacy-preserving manner. In this paper, we consider HFL with\nhighly mobile devices, mainly targeting at vehicular networks. Through\nconvergence analysis, we show that mobility influences the convergence speed by\nboth fusing the edge data and shuffling the edge models. While mobility is\nusually considered as a challenge from the perspective of communication, we\nprove that it increases the convergence speed of HFL with edge-level\nheterogeneous data, since more diverse data can be incorporated. Furthermore,\nwe demonstrate that a higher speed leads to faster convergence, since it\naccelerates the fusion of data. Simulation results show that mobility increases\nthe model accuracy of HFL by up to 15.1% when training a convolutional neural\nnetwork on the CIFAR-10 dataset.",
        "date": "Not Found"
    },
    {
        "title": "Title:An adaptive optimal control approach to monocular depth observability  maximization",
        "authors": [
            "",
            "Authors:",
            "",
            "Tochukwu Elijah Ogri",
            ",",
            "Muzaffar Qureshi",
            ",",
            "Zachary I. Bell",
            ",",
            "Kristy Waters",
            ",",
            "Rushikesh Kamalapurkar",
            ""
        ],
        "abstract": "This paper presents an integral concurrent learning (ICL)-based observer for\na monocular camera to accurately estimate the Euclidean distance to features on\na stationary object, under the restriction that state information is\nunavailable. Using distance estimates, an infinite horizon optimal regulation\nproblem is solved, which aims to regulate the camera to a goal location while\nmaximizing feature observability. Lyapunov-based stability analysis is used to\nguarantee exponential convergence of depth estimates and input-to-state\nstability of the goal location relative to the camera. The effectiveness of the\nproposed approach is verified in simulation, and a table illustrating improved\nobservability is provided.",
        "date": "Not Found"
    },
    {
        "title": "Title:Traffic Smoothing Controllers for Autonomous Vehicles Using Deep  Reinforcement Learning and Real-World Trajectory Data",
        "authors": [
            "",
            "Authors:",
            "",
            "Nathan Lichtl\u00e9",
            ",",
            "Kathy Jang",
            ",",
            "Adit Shah",
            ",",
            "Eugene Vinitsky",
            ",",
            "Jonathan W. Lee",
            ",",
            "Alexandre M. Bayen",
            ""
        ],
        "abstract": "Designing traffic-smoothing cruise controllers that can be deployed onto\nautonomous vehicles is a key step towards improving traffic flow, reducing\ncongestion, and enhancing fuel efficiency in mixed autonomy traffic. We bypass\nthe common issue of having to carefully fine-tune a large traffic\nmicrosimulator by leveraging real-world trajectory data from the I-24 highway\nin Tennessee, replayed in a one-lane simulation. Using standard deep\nreinforcement learning methods, we train energy-reducing wave-smoothing\npolicies. As an input to the agent, we observe the speed and distance of only\nthe vehicle in front, which are local states readily available on most recent\nvehicles, as well as non-local observations about the downstream state of the\ntraffic. We show that at a low 4% autonomous vehicle penetration rate, we\nachieve significant fuel savings of over 15% on trajectories exhibiting many\nstop-and-go waves. Finally, we analyze the smoothing effect of the controllers\nand demonstrate robustness to adding lane-changing into the simulation as well\nas the removal of downstream information.",
        "date": "Not Found"
    },
    {
        "title": "Title:DistServe: Disaggregating Prefill and Decoding for Goodput-optimized  Large Language Model Serving",
        "authors": [
            "",
            "Authors:",
            "",
            "Yinmin Zhong",
            ",",
            "Shengyu Liu",
            ",",
            "Junda Chen",
            ",",
            "Jianbo Hu",
            ",",
            "Yibo Zhu",
            ",",
            "Xuanzhe Liu",
            ",",
            "Xin Jin",
            ",",
            "Hao Zhang",
            ""
        ],
        "abstract": "DistServe improves the performance of large language models (LLMs) serving by\ndisaggregating the prefill and decoding computation. Existing LLM serving\nsystems colocate the two phases and batch the computation of prefill and\ndecoding across all users and requests. We find that this strategy not only\nleads to strong prefill-decoding interferences but also couples the resource\nallocation and parallelism plans for both phases. LLM applications often\nemphasize individual latency for each phase: time to first token (TTFT) for the\nprefill phase and time per output token (TPOT) of each request for the decoding\nphase. In the presence of stringent latency requirements, existing systems have\nto prioritize one latency over the other, or over-provision compute resources\nto meet both.\nDistServe assigns prefill and decoding computation to different GPUs, hence\neliminating prefill-decoding interferences. Given the application's TTFT and\nTPOT requirements, DistServe co-optimizes the resource allocation and\nparallelism strategy tailored for each phase. DistServe also places the two\nphases according to the serving cluster's bandwidth to minimize the\ncommunication caused by disaggregation. As a result, DistServe significantly\nimproves LLM serving performance in terms of the maximum rate that can be\nserved within both TTFT and TPOT constraints on each GPU. Our evaluations show\nthat on various popular LLMs, applications, and latency requirements, DistServe\ncan serve 4.48x more requests or 10.2x tighter SLO, compared to\nstate-of-the-art systems, while staying within latency constraints for > 90% of\nrequests.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Identifiable Unsupervised Domain Translation: A Diversified  Distribution Matching Approach",
        "authors": [
            "",
            "Authors:",
            "",
            "Sagar Shrestha",
            ",",
            "Xiao Fu",
            ""
        ],
        "abstract": "Unsupervised domain translation (UDT) aims to find functions that convert\nsamples from one domain (e.g., sketches) to another domain (e.g., photos)\nwithout changing the high-level semantic meaning (also referred to as\n``content''). The translation functions are often sought by probability\ndistribution matching of the transformed source domain and target domain.\nCycleGAN stands as arguably the most representative approach among this line of\nwork. However, it was noticed in the literature that CycleGAN and variants\ncould fail to identify the desired translation functions and produce\ncontent-misaligned translations. This limitation arises due to the presence of\nmultiple translation functions -- referred to as ``measure-preserving\nautomorphism\" (MPA) -- in the solution space of the learning criteria. Despite\nawareness of such identifiability issues, solutions have remained elusive. This\nstudy delves into the core identifiability inquiry and introduces an MPA\nelimination theory. Our analysis shows that MPA is unlikely to exist, if\nmultiple pairs of diverse cross-domain conditional distributions are matched by\nthe learning function. Our theory leads to a UDT learner using distribution\nmatching over auxiliary variable-induced subsets of the domains -- other than\nover the entire data domains as in the classical approaches. The proposed\nframework is the first to rigorously establish translation identifiability\nunder reasonable UDT settings, to our best knowledge. Experiments corroborate\nwith our theoretical claims.",
        "date": "Not Found"
    },
    {
        "title": "Title:Artwork Protection Against Neural Style Transfer Using Locally Adaptive  Adversarial Color Attack",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhongliang Guo",
            ",",
            "Kaixuan Wang",
            ",",
            "Weiye Li",
            ",",
            "Yifei Qian",
            ",",
            "Ognjen Arandjelovi\u0107",
            ",",
            "Lei Fang",
            ""
        ],
        "abstract": "Neural style transfer (NST) is widely adopted in computer vision to generate\nnew images with arbitrary styles. This process leverages neural networks to\nmerge aesthetic elements of a style image with the structural aspects of a\ncontent image into a harmoniously integrated visual result. However,\nunauthorized NST can exploit artwork. Such misuse raises socio-technical\nconcerns regarding artists' rights and motivates the development of technical\napproaches for the proactive protection of original creations. Adversarial\nattack is a concept primarily explored in machine learning security. Our work\nintroduces this technique to protect artists' intellectual property. In this\npaper Locally Adaptive Adversarial Color Attack (LAACA), a method for altering\nimages in a manner imperceptible to the human eyes but disruptive to NST.\nSpecifically, we design perturbations targeting image areas rich in\nhigh-frequency content, generated by disrupting intermediate features. Our\nexperiments and user study confirm that by attacking NST using the proposed\nmethod results in visually worse neural style transfer, thus making it an\neffective solution for visual artwork protection.",
        "date": "Not Found"
    },
    {
        "title": "Title:QoS-Aware 3D Coverage Deployment of UAVs for Internet of Vehicles in  Intelligent Transportation",
        "authors": [
            "",
            "Authors:",
            "",
            "engfei Du",
            ",",
            "Tingyue Xiao",
            ",",
            "Haotong Cao",
            ",",
            "Daosen Zhai",
            ""
        ],
        "abstract": "It is a challenging problem to characterize the air-to-ground (A2G) channel\nand identify the best deployment location for 3D UAVs with the QoS awareness.\nTo address this problem, we propose a QoS-aware UAV 3D coverage deployment\nalgorithm, which simulates the three-dimensional urban road scenario, considers\nthe UAV communication resource capacity and vehicle communication QoS\nrequirements comprehensively, and then obtains the optimal UAV deployment\nposition by improving the genetic algorithm. Specifically, the K-means\nclustering algorithm is used to cluster the vehicles, and the center locations\nof these clusters serve as the initial UAV positions to generate the initial\npopulation. Subsequently, we employ the K-means initialized grey wolf\noptimization (KIGWO) algorithm to achieve the UAV location with an optimal\nfitness value by performing an optimal search within the grey wolf population.\nTo enhance the algorithm's diversity and global search capability, we randomly\nsubstitute this optimal location with one of the individual locations from the\ninitial population. The fitness value is determined by the total number of\nvehicles covered by UAVs in the system, while the allocation scheme's\nfeasibility is evaluated based on the corresponding QoS requirements.\nCompetitive selection operations are conducted to retain individuals with\nhigher fitness values, while crossover and mutation operations are employed to\nmaintain the diversity of solutions. Finally, the individual with the highest\nfitness, which represents the UAV deployment position that covers the maximum\nnumber of vehicles in the entire system, is selected as the optimal solution.\nExtensive experimental results demonstrate that the proposed algorithm can\neffectively enhance the reliability and vehicle communication QoS.",
        "date": "Not Found"
    },
    {
        "title": "Title:Eye Motion Matters for 3D Face Reconstruction",
        "authors": [
            "",
            "Authors:",
            "",
            "Xuan Wang",
            ",",
            "Mengyuan Liu",
            ""
        ],
        "abstract": "Recent advances in single-image 3D face reconstruction have shown remarkable\nprogress in various applications. Nevertheless, prevailing techniques tend to\nprioritize the global facial contour and expression, often neglecting the\nnuanced dynamics of the eye region. In response, we introduce an Eye Landmark\nAdjustment Module, complemented by a Local Dynamic Loss, designed to capture\nthe dynamic features of the eyes area. Our module allows for flexible\nadjustment of landmarks, resulting in accurate recreation of various eye\nstates. In this paper, we present a comprehensive evaluation of our approach,\nconducting extensive experiments on two datasets. The results underscore the\nsuperior performance of our approach, highlighting its significant\ncontributions in addressing this particular challenge.",
        "date": "Not Found"
    },
    {
        "title": "Title:Integrating Graceful Degradation and Recovery through Requirement-driven  Adaptation",
        "authors": [
            "",
            "Authors:",
            "",
            "Simon Chu",
            ",",
            "Justin Koe",
            ",",
            "David Garlan",
            ",",
            "Eunsuk Kang",
            ""
        ],
        "abstract": "Cyber-physical systems (CPS) are subject to environmental uncertainties such\nas adverse operating conditions, malicious attacks, and hardware degradation.\nThese uncertainties may lead to failures that put the system in a sub-optimal\nor unsafe state. Systems that are resilient to such uncertainties rely on two\ntypes of operations: (1) graceful degradation, to ensure that the system\nmaintains an acceptable level of safety during unexpected environmental\nconditions and (2) recovery, to facilitate the resumption of normal system\nfunctions. Typically, mechanisms for degradation and recovery are developed\nindependently from each other, and later integrated into a system, requiring\nthe designer to develop an additional, ad-hoc logic for activating and\ncoordinating between the two operations. In this paper, we propose a\nself-adaptation approach for improving system resiliency through automated\ntriggering and coordination of graceful degradation and recovery.The key idea\nbehind our approach is to treat degradation and recovery as requirement-driven\nadaptation tasks: Degradation can be thought of as temporarily weakening an\noriginal (i.e., ideal) system requirement to be achieved by the system, and\nrecovery as strengthening the weakened requirement when the environment returns\nwithin an expected operating boundary. Furthermore, by treating weakening and\nstrengthening as dual operations, we argue that a single requirement-based\nadaptation method is sufficient to enable coordination between degradation and\nrecovery. Given system requirements specified in signal temporal logic (STL),\nwe propose a run-time adaptation framework that automatically performs\ndegradation and recovery in response to environmental changes. We describe a\nprototype implementation of our framework and demonstrate the feasibility of\nthe proposed approach using a case study in unmanned underwater vehicles\n(UUVs).",
        "date": "Not Found"
    },
    {
        "title": "Title:Tiny Multi-Agent DRL for Twins Migration in UAV Metaverses: A  Multi-Leader Multi-Follower Stackelberg Game Approach",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiawen Kang",
            ",",
            "Yue Zhong",
            ",",
            "Minrui Xu",
            ",",
            "Jiangtian Nie",
            ",",
            "Jinbo Wen",
            ",",
            "Hongyang Du",
            ",",
            "Dongdong Ye",
            ",",
            "Xumin Huang",
            ",",
            "Dusit Niyato",
            ",",
            "Shengli Xie",
            ""
        ],
        "abstract": "The synergy between Unmanned Aerial Vehicles (UAVs) and metaverses is giving\nrise to an emerging paradigm named UAV metaverses, which create a unified\necosystem that blends physical and virtual spaces, transforming drone\ninteraction and virtual exploration. UAV Twins (UTs), as the digital twins of\nUAVs that revolutionize UAV applications by making them more immersive,\nrealistic, and informative, are deployed and updated on ground base stations,\ne.g., RoadSide Units (RSUs), to offer metaverse services for UAV Metaverse\nUsers (UMUs). Due to the dynamic mobility of UAVs and limited communication\ncoverages of RSUs, it is essential to perform real-time UT migration to ensure\nseamless immersive experiences for UMUs. However, selecting appropriate RSUs\nand optimizing the required bandwidth is challenging for achieving reliable and\nefficient UT migration. To address the challenges, we propose a tiny machine\nlearning-based Stackelberg game framework based on pruning techniques for\nefficient UT migration in UAV metaverses. Specifically, we formulate a\nmulti-leader multi-follower Stackelberg model considering a new immersion\nmetric of UMUs in the utilities of UAVs. Then, we design a Tiny Multi-Agent\nDeep Reinforcement Learning (Tiny MADRL) algorithm to obtain the tiny networks\nrepresenting the optimal game solution. Specifically, the actor-critic network\nleverages the pruning techniques to reduce the number of network parameters and\nachieve model size and computation reduction, allowing for efficient\nimplementation of Tiny MADRL. Numerical results demonstrate that our proposed\nschemes have better performance than traditional schemes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Harnessing Density Ratios for Online Reinforcement Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Philip Amortila",
            ",",
            "Dylan J. Foster",
            ",",
            "Nan Jiang",
            ",",
            "Ayush Sekhari",
            ",",
            "Tengyang Xie",
            ""
        ],
        "abstract": "The theories of offline and online reinforcement learning, despite having\nevolved in parallel, have begun to show signs of the possibility for a\nunification, with algorithms and analysis techniques for one setting often\nhaving natural counterparts in the other. However, the notion of density ratio\nmodeling, an emerging paradigm in offline RL, has been largely absent from\nonline RL, perhaps for good reason: the very existence and boundedness of\ndensity ratios relies on access to an exploratory dataset with good coverage,\nbut the core challenge in online RL is to collect such a dataset without having\none to start. In this work we show -- perhaps surprisingly -- that density\nratio-based algorithms have online counterparts. Assuming only the existence of\nan exploratory distribution with good coverage, a structural condition known as\ncoverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses\ndensity ratio realizability and value function realizability to perform\nsample-efficient online exploration. GLOW addresses unbounded density ratios\nvia careful use of truncation, and combines this with optimism to guide\nexploration. GLOW is computationally inefficient; we complement it with a more\nefficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2022)\nwherein online RL is augmented with additional offline data. HyGLOW is derived\nas a special case of a more general meta-algorithm that provides a provable\nblack-box reduction from hybrid RL to offline RL, which may be of independent\ninterest.",
        "date": "Not Found"
    },
    {
        "title": "Title:Comparative Study on the Performance of Categorical Variable Encoders in  Classification and Regression Tasks",
        "authors": [
            "",
            "Authors:",
            "",
            "Wenbin Zhu",
            ",",
            "Runwen Qiu",
            ",",
            "Ying Fu",
            ""
        ],
        "abstract": "Categorical variables often appear in datasets for classification and\nregression tasks, and they need to be encoded into numerical values before\ntraining. Since many encoders have been developed and can significantly impact\nperformance, choosing the appropriate encoder for a task becomes a\ntime-consuming yet important practical issue. This study broadly classifies\nmachine learning models into three categories: 1) ATI models that implicitly\nperform affine transformations on inputs, such as multi-layer perceptron neural\nnetwork; 2) Tree-based models that are based on decision trees, such as random\nforest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot\nencoder is the best choice for ATI models in the sense that it can mimic any\nother encoders by learning suitable weights from the data. We also explain why\nthe target encoder and its variants are the most suitable encoders for\ntree-based models. This study conducted comprehensive computational experiments\nto evaluate 14 encoders, including one-hot and target encoders, along with\neight common machine-learning models on 28 datasets. The computational results\nagree with our theoretical analysis. The findings in this study shed light on\nhow to select the suitable encoder for data scientists in fields such as fraud\ndetection, disease diagnosis, etc.",
        "date": "Not Found"
    },
    {
        "title": "Title:Imitation Learning Inputting Image Feature to Each Layer of Neural  Network",
        "authors": [
            "",
            "Authors:",
            "",
            "Koki Yamane",
            ",",
            "Sho Sakaino",
            ",",
            "Toshiaki Tsuji",
            ""
        ],
        "abstract": "Imitation learning enables robots to learn and replicate human behavior from\ntraining data. Recent advances in machine learning enable end-to-end learning\napproaches that directly process high-dimensional observation data, such as\nimages. However, these approaches face a critical challenge when processing\ndata from multiple modalities, inadvertently ignoring data with a lower\ncorrelation to the desired output, especially when using short sampling\nperiods. This paper presents a useful method to address this challenge, which\namplifies the influence of data with a relatively low correlation to the output\nby inputting the data into each neural network layer. The proposed approach\neffectively incorporates diverse data sources into the learning process.\nThrough experiments using a simple pick-and-place operation with raw images and\njoint information as input, significant improvements in success rates are\ndemonstrated even when dealing with data from short sampling periods.",
        "date": "Not Found"
    },
    {
        "title": "Title:EfficientRec an unlimited user-item scale recommendation system based on  clustering and users interaction embedding profile",
        "authors": [
            "",
            "Authors:",
            "",
            "Vu Hong Quan",
            ",",
            "Le Hoang Ngan",
            ",",
            "Le Minh Duc",
            ",",
            "Nguyen Tran Ngoc Linh",
            ",",
            "Hoang Quynh-Le",
            ""
        ],
        "abstract": "Recommendation systems are highly interested in technology companies\nnowadays. The businesses are constantly growing users and products, causing the\nnumber of users and items to continuously increase over time, to very large\nnumbers. Traditional recommendation algorithms with complexity dependent on the\nnumber of users and items make them difficult to adapt to the industrial\nenvironment. In this paper, we introduce a new method applying graph neural\nnetworks with a contrastive learning framework in extracting user preferences.\nWe incorporate a soft clustering architecture that significantly reduces the\ncomputational cost of the inference process. Experiments show that the model is\nable to learn user preferences with low computational cost in both training and\nprediction phases. At the same time, the model gives a very good accuracy. We\ncall this architecture EfficientRec with the implication of model compactness\nand the ability to scale to unlimited users and products.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Multi-Area Architecture for Real-Time Feedback-Based Optimization of  Distribution Grids",
        "authors": [
            "",
            "Authors:",
            "",
            "Ilyas Farhat",
            "(1),",
            "Etinosa Ekomwenrenren",
            "(1),",
            "John W. Simpson-Porco",
            "(2),",
            "Evangelos Farantatos",
            "(3),",
            "Mahendra Patel",
            "(3),",
            "Aboutaleb Haddadi",
            "(3) ((1) University of Waterloo, (2) University of Toronto, (3) Electric Power Research Institute)"
        ],
        "abstract": "A challenge in transmission-distribution coordination is how to quickly and\nreliably coordinate Distributed Energy Resources (DERs) across large\nmulti-stakeholder Distribution Networks (DNs) to support the Transmission\nNetwork (TN), while ensuring operational constraints continue to be met within\nthe DN. Here we propose a hierarchical feedback-based control architecture for\ncoordination of DERs in DNs, enabling the DN to quickly respond to power\nset-point requests from the Transmission System Operator (TSO) while\nmaintaining local DN constraints. Our scheme allows for multiple\nindependently-managed areas within the DN to optimize their local resources\nwhile coordinating to support the TN, and while maintaining data privacy; the\nonly required inter-area communication is between physically adjacent areas\nwithin the DN control hierarchy. We conduct a rigorous stability analysis,\nestablishing intuitive conditions for closed-loop stability, and provide\ndetailed tuning recommendations. The proposal is validated via case studies on\nmultiple feeders, including IEEE-123 and IEEE-8500, using a custom MATLAB-based\napplication which integrates with OpenDSS. The simulation results show that the\nproposed structure is highly scalable and can quickly coordinate DERs in\nresponse to TSO commands, while responding to local disturbances within the DN\nand maintaining DN operational limits.",
        "date": "Not Found"
    },
    {
        "title": "Title:Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in  Relationship Dissolution",
        "authors": [
            "",
            "Authors:",
            "",
            "Yue Fu",
            ",",
            "Yixin Chen",
            ",",
            "Zelia Gomes Da Costa Lai",
            ",",
            "Alexis Hiniker",
            ""
        ],
        "abstract": "Relationships are essential to our happiness and wellbeing. The dissolution\nof a relationship, the final stage of relationship's lifecycle and one of the\nmost stressful events in an individual's life, can have profound and\nlong-lasting impacts on people. With the breakup process increasingly\nfacilitated by computer-mediated communication (CMC), and the likely future\ninfluence of AI-mediated communication (AIMC) tools, we conducted a\nsemi-structured interview study with 21 participants. We aim to understand: 1)\nthe current role of technology in the breakup process, 2) the needs and support\nindividuals have during the process, and 3) how AI might address these needs.\nOur research shows that people have distinct needs at various stages of ending\na relationship. Presently, technology is used for information gathering and\ncommunity support, acting as a catalyst for breakups, enabling ghosting and\nblocking, and facilitating communication. Participants anticipate that AI could\naid in sense-making of their relationship leading up to the breakup, act as a\nmediator, assist in crafting appropriate wording, tones, and language during\nbreakup conversations, and support companionship, reflection, recovery, and\ngrowth after a breakup. Our findings also demonstrate an overlap between the\nbreakup process and the Transtheoretical Model (TTM) of behavior change.\nThrough the lens of TTM, we explore the potential support and affordances AI\ncould offer in breakups, including its benefits and the necessary precautions\nregarding AI's role in this sensitive process.",
        "date": "Not Found"
    },
    {
        "title": "Title:Curriculum Recommendations Using Transformer Base Model with InfoNCE  Loss And Language Switching Method",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiaonan Xu",
            ",",
            "Bin Yuan",
            ",",
            "Yongyao Mo",
            ",",
            "Tianbo Song",
            ",",
            "Shulin Li",
            ""
        ],
        "abstract": "The Curriculum Recommendations paradigm is dedicated to fostering learning\nequality within the ever-evolving realms of educational technology and\ncurriculum development. In acknowledging the inherent obstacles posed by\nexisting methodologies, such as content conflicts and disruptions from language\ntranslation, this paradigm aims to confront and overcome these challenges.\nNotably, it addresses content conflicts and disruptions introduced by language\ntranslation, hindrances that can impede the creation of an all-encompassing and\npersonalized learning experience. The paradigm's objective is to cultivate an\neducational environment that not only embraces diversity but also customizes\nlearning experiences to suit the distinct needs of each learner. To overcome\nthese challenges, our approach builds upon notable contributions in curriculum\ndevelopment and personalized learning, introducing three key innovations. These\ninclude the integration of Transformer Base Model to enhance computational\nefficiency, the implementation of InfoNCE Loss for accurate content-topic\nmatching, and the adoption of a language switching strategy to alleviate\ntranslation-related ambiguities. Together, these innovations aim to\ncollectively tackle inherent challenges and contribute to forging a more\nequitable and effective learning journey for a diverse range of learners.\nCompetitive cross-validation scores underscore the efficacy of\nsentence-transformers/LaBSE, achieving 0.66314, showcasing our methodology's\neffectiveness in diverse linguistic nuances for content alignment prediction.\nIndex Terms-Curriculum Recommendation, Transformer model with InfoNCE Loss,\nLanguage Switching.",
        "date": "Not Found"
    },
    {
        "title": "Title:Fully Dynamic Min-Cut of Superconstant Size in Subpolynomial Time",
        "authors": [
            "",
            "Authors:",
            "",
            "Wenyu Jin",
            ",",
            "Xiaorui Sun",
            ",",
            "Mikkel Thorup",
            ""
        ],
        "abstract": "We present a deterministic fully dynamic algorithm with subpolynomial\nworst-case time per graph update such that after processing each update of the\ngraph, the algorithm outputs a minimum cut of the graph if the graph has a cut\nof size at most $c$ for some $c = (\\log n)^{o(1)}$. Previously, the best update\ntime was $\\widetilde O(\\sqrt{n})$ for any $c > 2$ and $c = O(\\log n)$ [Thorup,\nCombinatorica'07].",
        "date": "Not Found"
    },
    {
        "title": "Title:Fast Updating Truncated SVD for Representation Learning with Sparse  Matrices",
        "authors": [
            "",
            "Authors:",
            "",
            "Haoran Deng",
            ",",
            "Yang Yang",
            ",",
            "Jiahe Li",
            ",",
            "Cheng Chen",
            ",",
            "Weihao Jiang",
            ",",
            "Shiliang Pu",
            ""
        ],
        "abstract": "Updating a truncated Singular Value Decomposition (SVD) is crucial in\nrepresentation learning, especially when dealing with large-scale data matrices\nthat continuously evolve in practical scenarios. Aligning SVD-based models with\nfast-paced updates becomes increasingly important. Existing methods for\nupdating truncated SVDs employ Rayleigh-Ritz projection procedures, where\nprojection matrices are augmented based on original singular vectors. However,\nthese methods suffer from inefficiency due to the densification of the update\nmatrix and the application of the projection to all singular vectors. To\naddress these limitations, we introduce a novel method for dynamically\napproximating the truncated SVD of a sparse and temporally evolving matrix. Our\napproach leverages sparsity in the orthogonalization process of augmented\nmatrices and utilizes an extended decomposition to independently store\nprojections in the column space of singular vectors. Numerical experiments\ndemonstrate a remarkable efficiency improvement of an order of magnitude\ncompared to previous methods. Remarkably, this improvement is achieved while\nmaintaining a comparable precision to existing approaches.",
        "date": "Not Found"
    },
    {
        "title": "Title:Learning Hybrid Policies for MPC with Application to Drone Flight in  Unknown Dynamic Environments",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhaohan Feng",
            ",",
            "Jie Chen",
            ",",
            "Wei Xiao",
            ",",
            "Jian Sun",
            ",",
            "Bin Xin",
            ",",
            "Gang Wang",
            ""
        ],
        "abstract": "In recent years, drones have found increased applications in a wide array of\nreal-world tasks. Model predictive control (MPC) has emerged as a practical\nmethod for drone flight control, owing to its robustness against modeling\nerrors/uncertainties and external disturbances. However, MPC's sensitivity to\nmanually tuned parameters can lead to rapid performance degradation when faced\nwith unknown environmental dynamics. This paper addresses the challenge of\ncontrolling a drone as it traverses a swinging gate characterized by unknown\ndynamics. This paper introduces a parameterized MPC approach named hyMPC that\nleverages high-level decision variables to adapt to uncertain environmental\nconditions. To derive these decision variables, a novel policy search framework\naimed at training a high-level Gaussian policy is presented. Subsequently, we\nharness the power of neural network policies, trained on data gathered through\nthe repeated execution of the Gaussian policy, to provide real-time decision\nvariables. The effectiveness of hyMPC is validated through numerical\nsimulations, achieving a 100\\% success rate in 20 drone flight tests traversing\na swinging gate, demonstrating its capability to achieve safe and precise\nflight with limited prior knowledge of environmental dynamics.",
        "date": "Not Found"
    },
    {
        "title": "Title:A HPC Co-Scheduler with Reinforcement Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Abel Souza",
            ",",
            "Kristiaan Pelckmans",
            ",",
            "Johan Tordsson",
            ""
        ],
        "abstract": "Although High Performance Computing (HPC) users understand basic resource\nrequirements such as the number of CPUs and memory limits, internal\ninfrastructural utilization data is exclusively leveraged by cluster operators,\nwho use it to configure batch schedulers. This task is challenging and\nincreasingly complex due to ever larger cluster scales and heterogeneity of\nmodern scientific workflows. As a result, HPC systems achieve low utilization\nwith long job completion times (makespans). To tackle these challenges, we\npropose a co-scheduling algorithm based on an adaptive reinforcement learning\nalgorithm, where application profiling is combined with cluster monitoring. The\nresulting cluster scheduler matches resource utilization to application\nperformance in a fine-grained manner (i.e., operating system level). As opposed\nto nominal allocations, we apply decision trees to model applications' actual\nresource usage, which are used to estimate how much resource capacity from one\nallocation can be co-allocated to additional applications. Our algorithm learns\nfrom incorrect co-scheduling decisions and adapts from changing environment\nconditions, and evaluates when such changes cause resource contention that\nimpacts quality of service metrics such as jobs slowdowns. We integrate our\nalgorithm in an HPC resource manager that combines Slurm and Mesos for job\nscheduling and co-allocation, respectively. Our experimental evaluation\nperformed in a dedicated cluster executing a mix of four real different\nscientific workflows demonstrates improvements on cluster utilization of up to\n51% even in high load scenarios, with 55% average queue makespan reductions\nunder low loads.",
        "date": "Not Found"
    },
    {
        "title": "Title:P2Seg: Pointly-supervised Segmentation via Mutual Distillation",
        "authors": [
            "",
            "Authors:",
            "",
            "Zipeng Wang",
            ",",
            "Xuehui Yu",
            ",",
            "Xumeng Han",
            ",",
            "Wenwen Yu",
            ",",
            "Zhixun Huang",
            ",",
            "Jianbin Jiao",
            ",",
            "Zhenjun Han",
            ""
        ],
        "abstract": "Point-level Supervised Instance Segmentation (PSIS) aims to enhance the\napplicability and scalability of instance segmentation by utilizing low-cost\nyet instance-informative annotations. Existing PSIS methods usually rely on\npositional information to distinguish objects, but predicting precise\nboundaries remains challenging due to the lack of contour annotations.\nNevertheless, weakly supervised semantic segmentation methods are proficient in\nutilizing intra-class feature consistency to capture the boundary contours of\nthe same semantic regions. In this paper, we design a Mutual Distillation\nModule (MDM) to leverage the complementary strengths of both instance position\nand semantic information and achieve accurate instance-level object perception.\nThe MDM consists of Semantic to Instance (S2I) and Instance to Semantic (I2S).\nS2I is guided by the precise boundaries of semantic regions to learn the\nassociation between annotated points and instance contours. I2S leverages\ndiscriminative relationships between instances to facilitate the\ndifferentiation of various objects within the semantic map. Extensive\nexperiments substantiate the efficacy of MDM in fostering the synergy between\ninstance and semantic information, consequently improving the quality of\ninstance-level object representations. Our method achieves 55.7 mAP$_{50}$ and\n17.6 mAP on the PASCAL VOC and MS COCO datasets, significantly outperforming\nrecent PSIS methods and several box-supervised instance segmentation\ncompetitors.",
        "date": "Not Found"
    },
    {
        "title": "Title:Joint Beam Direction Control and Radio Resource Allocation in Dynamic  Multi-beam LEO Satellite Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Shuo Yuan",
            ",",
            "Yaohua Sun",
            ",",
            "Mugen Peng",
            ",",
            "Renzhi Yuan",
            ""
        ],
        "abstract": "Multi-beam low earth orbit (LEO) satellites are emerging as key components in\nbeyond 5G and 6G to provide global coverage and high data rate. To fully\nunleash the potential of LEO satellite communication, resource management plays\na key role. However, the uneven distribution of users, the coupling of\nmulti-dimensional resources, complex inter-beam interference, and time-varying\nnetwork topologies all impose significant challenges on effective communication\nresource management. In this paper, we study the joint optimization of beam\ndirection and the allocation of spectrum, time, and power resource in a dynamic\nmulti-beam LEO satellite network. The objective is to improve long-term user\nsum data rate while taking user fairness into account. Since the concerned\nresource management problem is mixed-integer non-convex programming, the\nproblem is decomposed into three subproblems, namely beam direction control and\ntime slot allocation, user subchannel assignment, and beam power allocation.\nThen, these subproblems are solved iteratively by leveraging matching with\nexternalities and successive convex approximation, and the proposed algorithms\nare analyzed in terms of stability, convergence, and complexity. Extensive\nsimulations are conducted, and the results demonstrate that our proposal can\nimprove the number of served users by up to two times and the sum user data\nrate by up to 68%, compared to baseline schemes.",
        "date": "Not Found"
    },
    {
        "title": "Title:SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction  Tuning with Large Language Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Yang Zhan",
            ",",
            "Zhitong Xiong",
            ",",
            "Yuan Yuan",
            ""
        ],
        "abstract": "Large language models (LLMs) have recently been extended to the\nvision-language realm, obtaining impressive general multi-modal capabilities.\nHowever, the exploration of multi-modal large language models (MLLMs) for\nremote sensing (RS) data is still in its infancy, and the performance is not\nsatisfactory. In this work, we introduce SkyEyeGPT, a unified multi-modal large\nlanguage model specifically designed for RS vision-language understanding. To\nthis end, we meticulously curate an RS multi-modal instruction tuning dataset,\nincluding single-task and multi-task conversation instructions. After manual\nverification, we obtain a high-quality RS instruction-following dataset with\n968k samples. Our research demonstrates that with a simple yet effective\ndesign, SkyEyeGPT works surprisingly well on considerably different tasks\nwithout the need for extra encoding modules. Specifically, after projecting RS\nvisual features to the language domain via an alignment layer, they are fed\njointly with task-specific instructions into an LLM-based RS decoder to predict\nanswers for RS open-ended tasks. In addition, we design a two-stage tuning\nmethod to enhance instruction-following and multi-turn dialogue ability at\ndifferent granularities. Experiments on 8 datasets for RS vision-language tasks\ndemonstrate SkyEyeGPT's superiority in image-level and region-level tasks, such\nas captioning and visual grounding. In particular, SkyEyeGPT exhibits\nencouraging results compared to GPT-4V in some qualitative tests. The online\ndemo, code, and dataset will be released in\nhttps://github.com/ZhanYang-nwpu/SkyEyeGPT.",
        "date": "Not Found"
    },
    {
        "title": "Title:Robust virtual element methods for coupled stress-assisted diffusion  problems",
        "authors": [
            "",
            "Authors:",
            "",
            "Rekha Khot",
            ",",
            "Andres E. Rubiano",
            ",",
            "Ricardo Ruiz-Baier",
            ""
        ],
        "abstract": "This paper aims first to perform robust continuous analysis of a mixed\nnonlinear formulation for stress-assisted diffusion of a solute that interacts\nwith an elastic material, and second to propose and analyse a virtual element\nformulation of the model problem. The two-way coupling mechanisms between the\nHerrmann formulation for linear elasticity and the reaction-diffusion equation\n(written in mixed form) consist of diffusion-induced active stress and\nstress-dependent diffusion. The two sub-problems are analysed using the\nextended Babu\\v{s}ka--Brezzi--Braess theory for perturbed saddle-point\nproblems. The well-posedness of the nonlinearly coupled system is established\nusing a Banach fixed-point strategy under the smallness assumption on data. The\nvirtual element formulations for the uncoupled sub-problems are proven uniquely\nsolvable by a fixed-point argument in conjunction with appropriate projection\noperators. We derive the a priori error estimates, and test the accuracy and\nperformance of the proposed method through computational simulations.",
        "date": "Not Found"
    },
    {
        "title": "Title:HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain  Generalization",
        "authors": [
            "",
            "Authors:",
            "",
            "Guanglin Zhou",
            ",",
            "Zhongyi Han",
            ",",
            "Shiming Chen",
            ",",
            "Biwei Huang",
            ",",
            "Liming Zhu",
            ",",
            "Tongliang Liu",
            ",",
            "Lina Yao",
            ",",
            "Kun Zhang",
            ""
        ],
        "abstract": "Domain Generalization (DG) endeavors to create machine learning models that\nexcel in unseen scenarios by learning invariant features. In DG, the prevalent\npractice of constraining models to a fixed structure or uniform\nparameterization to encapsulate invariant features can inadvertently blend\nspecific aspects. Such an approach struggles with nuanced differentiation of\ninter-domain variations and may exhibit bias towards certain domains, hindering\nthe precise learning of domain-invariant features. Recognizing this, we\nintroduce a novel method designed to supplement the model with domain-level and\ntask-specific characteristics. This approach aims to guide the model in more\neffectively separating invariant features from specific characteristics,\nthereby boosting the generalization. Building on the emerging trend of visual\nprompts in the DG paradigm, our work introduces the novel \\textbf{H}ierarchical\n\\textbf{C}ontrastive \\textbf{V}isual \\textbf{P}rompt (HCVP) methodology. This\nrepresents a significant advancement in the field, setting itself apart with a\nunique generative approach to prompts, alongside an explicit model structure\nand specialized loss functions. Differing from traditional visual prompts that\nare often shared across entire datasets, HCVP utilizes a hierarchical prompt\ngeneration network enhanced by prompt contrastive learning. These generative\nprompts are instance-dependent, catering to the unique characteristics inherent\nto different domains and tasks. Additionally, we devise a prompt modulation\nnetwork that serves as a bridge, effectively incorporating the generated visual\nprompts into the vision transformer backbone. Experiments conducted on five DG\ndatasets demonstrate the effectiveness of HCVP, outperforming both established\nDG algorithms and adaptation protocols.",
        "date": "Not Found"
    },
    {
        "title": "Title:GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting",
        "authors": [
            "",
            "Authors:",
            "",
            "Mengtian Li",
            ",",
            "Shengxiang Yao",
            ",",
            "Zhifeng Xie",
            ",",
            "Keyu Chen",
            ",",
            "Yu-Gang Jiang",
            ""
        ],
        "abstract": "In this work, we propose a novel clothed human reconstruction method called\nGaussianBody, based on 3D Gaussian Splatting. Compared with the costly neural\nradiance based models, 3D Gaussian Splatting has recently demonstrated great\nperformance in terms of training time and rendering quality. However, applying\nthe static 3D Gaussian Splatting model to the dynamic human reconstruction\nproblem is non-trivial due to complicated non-rigid deformations and rich cloth\ndetails. To address these challenges, our method considers explicit pose-guided\ndeformation to associate dynamic Gaussians across the canonical space and the\nobservation space, introducing a physically-based prior with regularized\ntransformations helps mitigate ambiguity between the two spaces. During the\ntraining process, we further propose a pose refinement strategy to update the\npose regression for compensating the inaccurate initial estimation and a\nsplit-with-scale mechanism to enhance the density of regressed point clouds.\nThe experiments validate that our method can achieve state-of-the-art\nphotorealistic novel-view rendering results with high-quality details for\ndynamic clothed human bodies, along with explicit geometry reconstruction.",
        "date": "Not Found"
    },
    {
        "title": "Title:fast graph-based denoising for point cloud color information",
        "authors": [
            "",
            "Authors:",
            "",
            "Ryosuke Watanabe",
            ",",
            "Keisuke Nonaka",
            ",",
            "Eduardo Pavez",
            ",",
            "Tatsuya Kobayashi",
            ",",
            "Antonio Ortega",
            ""
        ],
        "abstract": "Point clouds are utilized in various 3D applications such as cross-reality\n(XR) and realistic 3D displays. In some applications, e.g., for live streaming\nusing a 3D point cloud, real-time point cloud denoising methods are required to\nenhance the visual quality. However, conventional high-precision denoising\nmethods cannot be executed in real time for large-scale point clouds owing to\nthe complexity of graph constructions with K nearest neighbors and noise level\nestimation. This paper proposes a fast graph-based denoising (FGBD) for a\nlarge-scale point cloud. First, high-speed graph construction is achieved by\nscanning a point cloud in various directions and searching adjacent\nneighborhoods on the scanning lines. Second, we propose a fast noise level\nestimation method using eigenvalues of the covariance matrix on a graph.\nFinally, we also propose a new low-cost filter selection method to enhance\ndenoising accuracy to compensate for the degradation caused by the acceleration\nalgorithms. In our experiments, we succeeded in reducing the processing time\ndramatically while maintaining accuracy relative to conventional denoising\nmethods. Denoising was performed at 30fps, with frames containing approximately\n1 million points.",
        "date": "Not Found"
    },
    {
        "title": "Title:Predicting Viral Rumors and Vulnerable Users for Infodemic Surveillance",
        "authors": [
            "",
            "Authors:",
            "",
            "Xuan Zhang",
            ",",
            "Wei Gao",
            ""
        ],
        "abstract": "In the age of the infodemic, it is crucial to have tools for effectively\nmonitoring the spread of rampant rumors that can quickly go viral, as well as\nidentifying vulnerable users who may be more susceptible to spreading such\nmisinformation. This proactive approach allows for timely preventive measures\nto be taken, mitigating the negative impact of false information on society. We\npropose a novel approach to predict viral rumors and vulnerable users using a\nunified graph neural network model. We pre-train network-based user embeddings\nand leverage a cross-attention mechanism between users and posts, together with\na community-enhanced vulnerability propagation (CVP) method to improve user and\npropagation graph representations. Furthermore, we employ two multi-task\ntraining strategies to mitigate negative transfer effects among tasks in\ndifferent settings, enhancing the overall performance of our approach. We also\nconstruct two datasets with ground-truth annotations on information virality\nand user vulnerability in rumor and non-rumor events, which are automatically\nderived from existing rumor detection datasets. Extensive evaluation results of\nour joint learning model confirm its superiority over strong baselines in all\nthree tasks: rumor detection, virality prediction, and user vulnerability\nscoring. For instance, compared to the best baselines based on the Weibo\ndataset, our model makes 3.8\\% and 3.0\\% improvements on Accuracy and MacF1 for\nrumor detection, and reduces mean squared error (MSE) by 23.9\\% and 16.5\\% for\nvirality prediction and user vulnerability scoring, respectively. Our findings\nsuggest that our approach effectively captures the correlation between rumor\nvirality and user vulnerability, leveraging this information to improve\nprediction performance and provide a valuable tool for infodemic surveillance.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhancing Image-Text Matching with Adaptive Feature Aggregation",
        "authors": [
            "",
            "Authors:",
            "",
            "Zuhui Wang",
            ",",
            "Yunting Yin",
            ",",
            "I.V. Ramakrishnan",
            ""
        ],
        "abstract": "Image-text matching aims to find matched cross-modal pairs accurately. While\ncurrent methods often rely on projecting cross-modal features into a common\nembedding space, they frequently suffer from imbalanced feature representations\nacross different modalities, leading to unreliable retrieval results. To\naddress these limitations, we introduce a novel Feature Enhancement Module that\nadaptively aggregates single-modal features for more balanced and robust\nimage-text retrieval. Additionally, we propose a new loss function that\novercomes the shortcomings of original triplet ranking loss, thereby\nsignificantly improving retrieval performance. The proposed model has been\nevaluated on two public datasets and achieves competitive retrieval performance\nwhen compared with several state-of-the-art models. Implementation codes can be\nfound here.",
        "date": "Not Found"
    },
    {
        "title": "Title:Large Language Model Lateral Spear Phishing: A Comparative Study in  Large-Scale Organizational Settings",
        "authors": [
            "",
            "Authors:",
            "",
            "Mazal Bethany",
            ",",
            "Athanasios Galiopoulos",
            ",",
            "Emet Bethany",
            ",",
            "Mohammad Bahrami Karkevandi",
            ",",
            "Nishant Vishwamitra",
            ",",
            "Peyman Najafirad",
            ""
        ],
        "abstract": "The critical threat of phishing emails has been further exacerbated by the\npotential of LLMs to generate highly targeted, personalized, and automated\nspear phishing attacks. Two critical problems concerning LLM-facilitated\nphishing require further investigation: 1) Existing studies on lateral phishing\nlack specific examination of LLM integration for large-scale attacks targeting\nthe entire organization, and 2) Current anti-phishing infrastructure, despite\nits extensive development, lacks the capability to prevent LLM-generated\nattacks, potentially impacting both employees and IT security incident\nmanagement. However, the execution of such investigative studies necessitates a\nreal-world environment, one that functions during regular business operations\nand mirrors the complexity of a large organizational infrastructure. This\nsetting must also offer the flexibility required to facilitate a diverse array\nof experimental conditions, particularly the incorporation of phishing emails\ncrafted by LLMs. This study is a pioneering exploration into the use of Large\nLanguage Models (LLMs) for the creation of targeted lateral phishing emails,\ntargeting a large tier 1 university's operation and workforce of approximately\n9,000 individuals over an 11-month period. It also evaluates the capability of\nemail filtering infrastructure to detect such LLM-generated phishing attempts,\nproviding insights into their effectiveness and identifying potential areas for\nimprovement. Based on our findings, we propose machine learning-based detection\ntechniques for such emails to detect LLM-generated phishing emails that were\nmissed by the existing infrastructure, with an F1-score of 98.96.",
        "date": "Not Found"
    },
    {
        "title": "Title:Offline Imitation Learning by Controlling the Effective Planning Horizon",
        "authors": [
            "",
            "Authors:",
            "",
            "Hee-Jun Ahn",
            ",",
            "Seong-Woong Shim",
            ",",
            "Byung-Jun Lee",
            ""
        ],
        "abstract": "In offline imitation learning (IL), we generally assume only a handful of\nexpert trajectories and a supplementary offline dataset from suboptimal\nbehaviors to learn the expert policy. While it is now common to minimize the\ndivergence between state-action visitation distributions so that the agent also\nconsiders the future consequences of an action, a sampling error in an offline\ndataset may lead to erroneous estimates of state-action visitations in the\noffline case. In this paper, we investigate the effect of controlling the\neffective planning horizon (i.e., reducing the discount factor) as opposed to\nimposing an explicit regularizer, as previously studied. Unfortunately, it\nturns out that the existing algorithms suffer from magnified approximation\nerrors when the effective planning horizon is shortened, which results in a\nsignificant degradation in performance. We analyze the main cause of the\nproblem and provide the right remedies to correct the algorithm. We show that\nthe corrected algorithm improves on popular imitation learning benchmarks by\ncontrolling the effective planning horizon rather than an explicit\nregularization.",
        "date": "Not Found"
    },
    {
        "title": "Title:Instance Brownian Bridge as Texts for Open-vocabulary Video Instance  Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Zesen Cheng",
            ",",
            "Kehan Li",
            ",",
            "Hao Li",
            ",",
            "Peng Jin",
            ",",
            "Chang Liu",
            ",",
            "Xiawu Zheng",
            ",",
            "Rongrong Ji",
            ",",
            "Jie Chen",
            ""
        ],
        "abstract": "Temporally locating objects with arbitrary class texts is the primary pursuit\nof open-vocabulary Video Instance Segmentation (VIS). Because of the\ninsufficient vocabulary of video data, previous methods leverage image-text\npretraining model for recognizing object instances by separately aligning each\nframe and class texts, ignoring the correlation between frames. As a result,\nthe separation breaks the instance movement context of videos, causing inferior\nalignment between video and text. To tackle this issue, we propose to link\nframe-level instance representations as a Brownian Bridge to model instance\ndynamics and align bridge-level instance representation to class texts for more\nprecisely open-vocabulary VIS (BriVIS). Specifically, we build our system upon\na frozen video segmentor to generate frame-level instance queries, and design\nTemporal Instance Resampler (TIR) to generate queries with temporal context\nfrom frame queries. To mold instance queries to follow Brownian bridge and\naccomplish alignment with class texts, we design Bridge-Text Alignment (BTA) to\nlearn discriminative bridge-level representations of instances via contrastive\nobjectives. Setting MinVIS as the basic video segmentor, BriVIS surpasses the\nOpen-vocabulary SOTA (OV2Seg) by a clear margin. For example, on the\nchallenging large-vocabulary VIS dataset (BURST), BriVIS achieves 7.43 mAP and\nexhibits 49.49% improvement compared to OV2Seg (4.97 mAP).",
        "date": "Not Found"
    },
    {
        "title": "Title:ASA -- The Adaptive Scheduling Algorithm",
        "authors": [
            "",
            "Authors:",
            "",
            "Abel Souza",
            ",",
            "Kristiaan Pelckmans",
            ",",
            "Devarshi Ghoshal",
            ",",
            "Lavanya Ramakrishnan",
            ",",
            "Johan Tordsson",
            ""
        ],
        "abstract": "In High Performance Computing (HPC) infrastructures, the control of resources\nby batch systems can lead to prolonged queue waiting times and adverse effects\non the overall execution times of applications, particularly in data-intensive\nand low-latency workflows where efficient processing hinges on resource\nplanning and timely allocation. Allocating the maximum capacity upfront ensures\nthe fastest execution but results in spare and idle resources, extended queue\nwaits, and costly usage. Conversely, dynamic allocation based on workflow stage\nrequirements optimizes resource usage but may negatively impact the total\nworkflow makespan. To address these issues, we introduce ASA, the Adaptive\nScheduling Algorithm. ASA is a novel, convergence-proven scheduling technique\nthat minimizes jobs inter-stage waiting times by estimating the queue waiting\ntimes to proactively submit resource change requests ahead of time. It strikes\na balance between exploration and exploitation, considering both learning\n(waiting times) and applying learnt insights. Real-world experiments over two\nsupercomputers centers with scientific workflows demonstrate ASA's\neffectiveness, achieving near-optimal resource utilization and accuracy, with\nup to 10% and 2% reductions in average workflow queue waiting times and\nmakespan, respectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Measuring the Discrepancy between 3D Geometric Models using Directional  Distance Fields",
        "authors": [
            "",
            "Authors:",
            "",
            "Siyu Ren",
            ",",
            "Junhui Hou",
            ",",
            "Xiaodong Chen",
            ",",
            "Hongkai Xiong",
            ",",
            "Wenping Wang",
            ""
        ],
        "abstract": "Qualifying the discrepancy between 3D geometric models, which could be\nrepresented with either point clouds or triangle meshes, is a pivotal issue\nwith board applications. Existing methods mainly focus on directly establishing\nthe correspondence between two models and then aggregating point-wise distance\nbetween corresponding points, resulting in them being either inefficient or\nineffective. In this paper, we propose DirDist, an efficient, effective,\nrobust, and differentiable distance metric for 3D geometry data. Specifically,\nwe construct DirDist based on the proposed implicit representation of 3D\nmodels, namely directional distance field (DDF), which defines the directional\ndistances of 3D points to a model to capture its local surface geometry. We\nthen transfer the discrepancy between two 3D geometric models as the\ndiscrepancy between their DDFs defined on an identical domain, naturally\nestablishing model correspondence. To demonstrate the advantage of our DirDist,\nwe explore various distance metric-driven 3D geometric modeling tasks,\nincluding template surface fitting, rigid registration, non-rigid registration,\nscene flow estimation and human pose optimization. Extensive experiments show\nthat our DirDist achieves significantly higher accuracy under all tasks. As a\ngeneric distance metric, DirDist has the potential to advance the field of 3D\ngeometric modeling. The source code is available at\n\\url{https://github.com/rsy6318/DirDist}.",
        "date": "Not Found"
    },
    {
        "title": "Title:Hijacking Attacks against Neural Networks by Analyzing Training Data",
        "authors": [
            "",
            "Authors:",
            "",
            "Yunjie Ge",
            ",",
            "Qian Wang",
            ",",
            "Huayang Huang",
            ",",
            "Qi Li",
            ",",
            "Cong Wang",
            ",",
            "Chao Shen",
            ",",
            "Lingchen Zhao",
            ",",
            "Peipei Jiang",
            ",",
            "Zheng Fang",
            ",",
            "Shenyi Zhang",
            ""
        ],
        "abstract": "Backdoors and adversarial examples are the two primary threats currently\nfaced by deep neural networks (DNNs). Both attacks attempt to hijack the model\nbehaviors with unintended outputs by introducing (small) perturbations to the\ninputs. Backdoor attacks, despite the high success rates, often require a\nstrong assumption, which is not always easy to achieve in reality. Adversarial\nexample attacks, which put relatively weaker assumptions on attackers, often\ndemand high computational resources, yet do not always yield satisfactory\nsuccess rates when attacking mainstream black-box models in the real world.\nThese limitations motivate the following research question: can model hijacking\nbe achieved more simply, with a higher attack success rate and more reasonable\nassumptions? In this paper, we propose CleanSheet, a new model hijacking attack\nthat obtains the high performance of backdoor attacks without requiring the\nadversary to tamper with the model training process. CleanSheet exploits\nvulnerabilities in DNNs stemming from the training data. Specifically, our key\nidea is to treat part of the clean training data of the target model as\n\"poisoned data,\" and capture the characteristics of these data that are more\nsensitive to the model (typically called robust features) to construct\n\"triggers.\" These triggers can be added to any input example to mislead the\ntarget model, similar to backdoor attacks. We validate the effectiveness of\nCleanSheet through extensive experiments on 5 datasets, 79 normally trained\nmodels, 68 pruned models, and 39 defensive models. Results show that CleanSheet\nexhibits performance comparable to state-of-the-art backdoor attacks, achieving\nan average attack success rate (ASR) of 97.5% on CIFAR-100 and 92.4% on GTSRB,\nrespectively. Furthermore, CleanSheet consistently maintains a high ASR, when\nconfronted with various mainstream backdoor defenses.",
        "date": "Not Found"
    },
    {
        "title": "Title:Image Translation as Diffusion Visual Programmers",
        "authors": [
            "",
            "Authors:",
            "",
            "Cheng Han",
            ",",
            "James C. Liang",
            ",",
            "Qifan Wang",
            ",",
            "Majid Rabbani",
            ",",
            "Sohail Dianat",
            ",",
            "Raghuveer Rao",
            ",",
            "Ying Nian Wu",
            ",",
            "Dongfang Liu",
            ""
        ],
        "abstract": "We introduce the novel Diffusion Visual Programmer (DVP), a neuro-symbolic\nimage translation framework. Our proposed DVP seamlessly embeds a\ncondition-flexible diffusion model within the GPT architecture, orchestrating a\ncoherent sequence of visual programs (i.e., computer vision models) for various\npro-symbolic steps, which span RoI identification, style transfer, and position\nmanipulation, facilitating transparent and controllable image translation\nprocesses. Extensive experiments demonstrate DVP's remarkable performance,\nsurpassing concurrent arts. This success can be attributed to several key\nfeatures of DVP: First, DVP achieves condition-flexible translation via\ninstance normalization, enabling the model to eliminate sensitivity caused by\nthe manual guidance and optimally focus on textual descriptions for\nhigh-quality content generation. Second, the framework enhances in-context\nreasoning by deciphering intricate high-dimensional concepts in feature spaces\ninto more accessible low-dimensional symbols (e.g., [Prompt], [RoI object]),\nallowing for localized, context-free editing while maintaining overall\ncoherence. Last but not least, DVP improves systemic controllability and\nexplainability by offering explicit symbolic representations at each\nprogramming stage, empowering users to intuitively interpret and modify\nresults. Our research marks a substantial step towards harmonizing artificial\nimage translation processes with cognitive intelligence, promising broader\napplications.",
        "date": "Not Found"
    },
    {
        "title": "Title:Stochastic theta methods for random periodic solution of stochastic  differential equations under non-globally Lipschitz conditions",
        "authors": [
            "",
            "Authors:",
            "",
            "Ziheng Chen",
            ",",
            "Liangmin Cao",
            ",",
            "Lin Chen",
            ""
        ],
        "abstract": "This work focuses on the numerical approximations of random periodic\nsolutions of stochastic differential equations (SDEs). Under non-globally\nLipschitz conditions, we prove the existence and uniqueness of random periodic\nsolutions for the considered equations and its numerical approximations\ngenerated by the stochastic theta (ST) methods with theta within (1/2,1]. It is\nshown that the random periodic solution of each ST method converges strongly in\nthe mean square sense to that of SDEs for all step size. More precisely, the\nmean square convergence order is 1/2 for SDEs with multiplicative noise and 1\nfor SDEs with additive noise. Numerical results are finally reported to confirm\nthese theoretical findings.",
        "date": "Not Found"
    },
    {
        "title": "Title:Bootstrapping OTS-Funcimg Pre-training Model (Botfip) -- A Comprehensive  Symbolic Regression Framework",
        "authors": [
            "",
            "Authors:",
            "",
            "Tianhao Chen",
            ",",
            "Pengbo Xu",
            ",",
            "Haibiao Zheng",
            ""
        ],
        "abstract": "In the field of scientific computing, many problem-solving approaches tend to\nfocus only on the process and final outcome, even in AI for science, there is a\nlack of deep multimodal information mining behind the data, missing a\nmultimodal framework akin to that in the image-text domain. In this paper, we\ntake Symbolic Regression(SR) as our focal point and, drawing inspiration from\nthe BLIP model in the image-text domain, propose a scientific computing\nmultimodal framework based on Function Images (Funcimg) and Operation Tree\nSequence (OTS), named Bootstrapping OTS-Funcimg Pre-training Model (Botfip). In\nSR experiments, we validate the advantages of Botfip in low-complexity SR\nproblems, showcasing its potential. As a MED framework, Botfip holds promise\nfor future applications in a broader range of scientific computing problems.",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploration and Anti-Exploration with Distributional Random Network  Distillation",
        "authors": [
            "",
            "Authors:",
            "",
            "Kai Yang",
            ",",
            "Jian Tao",
            ",",
            "Jiafei Lyu",
            ",",
            "Xiu Li",
            ""
        ],
        "abstract": "Exploration remains a critical issue in deep reinforcement learning for an\nagent to attain high returns in unknown environments. Although the prevailing\nexploration Random Network Distillation (RND) algorithm has been demonstrated\nto be effective in numerous environments, it often needs more discriminative\npower in bonus allocation. This paper highlights the ``bonus inconsistency''\nissue within RND, pinpointing its primary limitation. To address this issue, we\nintroduce the Distributional RND (DRND), a derivative of the RND. DRND enhances\nthe exploration process by distilling a distribution of random networks and\nimplicitly incorporating pseudo counts to improve the precision of bonus\nallocation. This refinement encourages agents to engage in more extensive\nexploration. Our method effectively mitigates the inconsistency issue without\nintroducing significant computational overhead. Both theoretical analysis and\nexperimental results demonstrate the superiority of our approach over the\noriginal RND algorithm. Our method excels in challenging online exploration\nscenarios and effectively serves as an anti-exploration mechanism in D4RL\noffline tasks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving Speaker-independent Speech Emotion Recognition Using Dynamic  Joint Distribution Adaptation",
        "authors": [
            "",
            "Authors:",
            "",
            "Cheng Lu",
            ",",
            "Yuan Zong",
            ",",
            "Hailun Lian",
            ",",
            "Yan Zhao",
            ",",
            "Bj\u00f6rn Schuller",
            ",",
            "Wenming Zheng",
            ""
        ],
        "abstract": "In speaker-independent speech emotion recognition, the training and testing\nsamples are collected from diverse speakers, leading to a multi-domain shift\nchallenge across the feature distributions of data from different speakers.\nConsequently, when the trained model is confronted with data from new speakers,\nits performance tends to degrade. To address the issue, we propose a Dynamic\nJoint Distribution Adaptation (DJDA) method under the framework of multi-source\ndomain adaptation. DJDA firstly utilizes joint distribution adaptation (JDA),\ninvolving marginal distribution adaptation (MDA) and conditional distribution\nadaptation (CDA), to more precisely measure the multi-domain distribution\nshifts caused by different speakers. This helps eliminate speaker bias in\nemotion features, allowing for learning discriminative and speaker-invariant\nspeech emotion features from coarse-level to fine-level. Furthermore, we\nquantify the adaptation contributions of MDA and CDA within JDA by using a\ndynamic balance factor based on $\\mathcal{A}$-Distance, promoting to\neffectively handle the unknown distributions encountered in data from new\nspeakers. Experimental results demonstrate the superior performance of our DJDA\nas compared to other state-of-the-art (SOTA) methods.",
        "date": "Not Found"
    },
    {
        "title": "Title:Applications of Machine Learning to Optimizing Polyolefin Manufacturing",
        "authors": [
            "",
            "Authors:",
            "",
            "Niket Sharma",
            ",",
            "Y.A. Liu",
            ""
        ],
        "abstract": "This chapter is a preprint from our book by , focusing on leveraging machine\nlearning (ML) in chemical and polyolefin manufacturing optimization. It's\ncrafted for both novices and seasoned professionals keen on the latest ML\napplications in chemical processes. We trace the evolution of AI and ML in\nchemical industries, delineate core ML components, and provide resources for ML\nbeginners. A detailed discussion on various ML methods is presented, covering\nregression, classification, and unsupervised learning techniques, with\nperformance metrics and examples. Ensemble methods, deep learning networks,\nincluding MLP, DNNs, RNNs, CNNs, and transformers, are explored for their\ngrowing role in chemical applications. Practical workshops guide readers\nthrough predictive modeling using advanced ML algorithms. The chapter\nculminates with insights into science-guided ML, advocating for a hybrid\napproach that enhances model accuracy. The extensive bibliography offers\nresources for further research and practical implementation. This chapter aims\nto be a thorough primer on ML's practical application in chemical engineering,\nparticularly for polyolefin production, and sets the stage for continued\nlearning in subsequent chapters. Please cite the original work [169,170] when\nreferencing.",
        "date": "Not Found"
    },
    {
        "title": "Title:Universally Robust Graph Neural Networks by Preserving Neighbor  Similarity",
        "authors": [
            "",
            "Authors:",
            "",
            "Yulin Zhu",
            ",",
            "Yuni Lai",
            ",",
            "Xing Ai",
            ",",
            "Kai Zhou",
            ""
        ],
        "abstract": "Despite the tremendous success of graph neural networks in learning\nrelational data, it has been widely investigated that graph neural networks are\nvulnerable to structural attacks on homophilic graphs. Motivated by this, a\nsurge of robust models is crafted to enhance the adversarial robustness of\ngraph neural networks on homophilic graphs. However, the vulnerability based on\nheterophilic graphs remains a mystery to us. To bridge this gap, in this paper,\nwe start to explore the vulnerability of graph neural networks on heterophilic\ngraphs and theoretically prove that the update of the negative classification\nloss is negatively correlated with the pairwise similarities based on the\npowered aggregated neighbor features. This theoretical proof explains the\nempirical observations that the graph attacker tends to connect dissimilar node\npairs based on the similarities of neighbor features instead of ego features\nboth on homophilic and heterophilic graphs. In this way, we novelly introduce a\nnovel robust model termed NSPGNN which incorporates a dual-kNN graphs pipeline\nto supervise the neighbor similarity-guided propagation. This propagation\nutilizes the low-pass filter to smooth the features of node pairs along the\npositive kNN graphs and the high-pass filter to discriminate the features of\nnode pairs along the negative kNN graphs. Extensive experiments on both\nhomophilic and heterophilic graphs validate the universal robustness of NSPGNN\ncompared to the state-of-the-art methods.",
        "date": "Not Found"
    },
    {
        "title": "Title:Explaining Drift using Shapley Values",
        "authors": [
            "",
            "Authors:",
            "",
            "Narayanan U. Edakunni",
            ",",
            "Utkarsh Tekriwal",
            ",",
            "Anukriti Jain",
            ""
        ],
        "abstract": "Machine learning models often deteriorate in their performance when they are\nused to predict the outcomes over data on which they were not trained. These\nscenarios can often arise in real world when the distribution of data changes\ngradually or abruptly due to major events like a pandemic. There have been many\nattempts in machine learning research to come up with techniques that are\nresilient to such Concept drifts. However, there is no principled framework to\nidentify the drivers behind the drift in model performance. In this paper, we\npropose a novel framework - DBShap that uses Shapley values to identify the\nmain contributors of the drift and quantify their respective contributions. The\nproposed framework not only quantifies the importance of individual features in\ndriving the drift but also includes the change in the underlying relation\nbetween the input and output as a possible driver. The explanation provided by\nDBShap can be used to understand the root cause behind the drift and use it to\nmake the model resilient to the drift.",
        "date": "Not Found"
    },
    {
        "title": "Title:Cooperative Tri-Point Model-Based Ground-to-Air Coverage Extension in  Beyond 5G Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Ziwei Cai",
            ",",
            "Min Sheng",
            ",",
            "Junju Liu",
            ",",
            "Chenxi Zhao",
            ",",
            "Jiandong Li",
            ""
        ],
        "abstract": "The utilization of existing terrestrial infrastructures to provide coverage\nfor aerial users is a potentially low-cost solution. However, the already\ndeployed terrestrial base stations (TBSs) result in weak ground-to-air (G2A)\ncoverage due to the down-tilted antennas. Furthermore, achieving optimal\ncoverage across the entire airspace through antenna adjustment is challenging\ndue to the complex signal coverage requirements in three-dimensional space,\nespecially in the vertical direction. In this paper, we propose a cooperative\ntri-point (CoTP) model-based method that utilizes cooperative beams to enhance\nthe G2A coverage extension. To utilize existing TBSs for establishing effective\ncooperation, we prove that the cooperation among three TBSs can ensure G2A\ncoverage with a minimum coverage overlap, and design the CoTP model to analyze\nthe G2A coverage extension. Using the model, a cooperative coverage structure\nbased on Delaunay triangulation is designed to divide triangular prism-shaped\nsubspaces and corresponding TBS cooperation sets. To enable TBSs in the\ncooperation set to cover different height subspaces while maintaining ground\ncoverage, we design a cooperative beam generation algorithm to maximize the\ncoverage in the triangular prism-shaped airspace. The simulation results and\nfield trials demonstrate that the proposed method can efficiently enhance the\nG2A coverage extension while guaranteeing ground coverage.",
        "date": "Not Found"
    },
    {
        "title": "Title:Resolving Regular Polysemy in Named Entities",
        "authors": [
            "",
            "Authors:",
            "",
            "Shu-Kai Hsieh",
            ",",
            "Yu-Hsiang Tseng",
            ",",
            "Hsin-Yu Chou",
            ",",
            "Ching-Wen Yang",
            ",",
            "Yu-Yun Chang",
            ""
        ],
        "abstract": "Word sense disambiguation primarily addresses the lexical ambiguity of common\nwords based on a predefined sense inventory. Conversely, proper names are\nusually considered to denote an ad-hoc real-world referent. Once the reference\nis decided, the ambiguity is purportedly resolved. However, proper names also\nexhibit ambiguities through appellativization, i.e., they act like common words\nand may denote different aspects of their referents. We proposed to address the\nambiguities of proper names through the light of regular polysemy, which we\nformalized as dot objects. This paper introduces a combined word sense\ndisambiguation (WSD) model for disambiguating common words against Chinese\nWordnet (CWN) and proper names as dot objects. The model leverages the\nflexibility of a gloss-based model architecture, which takes advantage of the\nglosses and example sentences of CWN. We show that the model achieves\ncompetitive results on both common and proper nouns, even on a relatively\nsparse sense dataset. Aside from being a performant WSD tool, the model further\nfacilitates the future development of the lexical resource.",
        "date": "Not Found"
    },
    {
        "title": "Title:SlideAVSR: A Dataset of Paper Explanation Videos for Audio-Visual Speech  Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Hao Wang",
            ",",
            "Shuhei Kurita",
            ",",
            "Shuichiro Shimizu",
            ",",
            "Daisuke Kawahara",
            ""
        ],
        "abstract": "Audio-visual speech recognition (AVSR) is a multimodal extension of automatic\nspeech recognition (ASR), using video as a complement to audio. In AVSR,\nconsiderable efforts have been directed at datasets for facial features such as\nlip-readings, while they often fall short in evaluating the image comprehension\ncapabilities in broader contexts. In this paper, we construct SlideAVSR, an\nAVSR dataset using scientific paper explanation videos. SlideAVSR provides a\nnew benchmark where models transcribe speech utterances with texts on the\nslides on the presentation recordings. As technical terminologies that are\nfrequent in paper explanations are notoriously challenging to transcribe\nwithout reference texts, our SlideAVSR dataset spotlights a new aspect of AVSR\nproblems. As a simple yet effective baseline, we propose DocWhisper, an AVSR\nmodel that can refer to textual information from slides, and confirm its\neffectiveness on SlideAVSR.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Comparative Study on Annotation Quality of Crowdsourcing and LLM via  Label Aggregation",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiyi Li",
            ""
        ],
        "abstract": "Whether Large Language Models (LLMs) can outperform crowdsourcing on the data\nannotation task is attracting interest recently. Some works verified this issue\nwith the average performance of individual crowd workers and LLM workers on\nsome specific NLP tasks by collecting new datasets. However, on the one hand,\nexisting datasets for the studies of annotation quality in crowdsourcing are\nnot yet utilized in such evaluations, which potentially provide reliable\nevaluations from a different viewpoint. On the other hand, the quality of these\naggregated labels is crucial because, when utilizing crowdsourcing, the\nestimated labels aggregated from multiple crowd labels to the same instances\nare the eventually collected labels. Therefore, in this paper, we first\ninvestigate which existing crowdsourcing datasets can be used for a comparative\nstudy and create a benchmark. We then compare the quality between individual\ncrowd labels and LLM labels and make the evaluations on the aggregated labels.\nIn addition, we propose a Crowd-LLM hybrid label aggregation method and verify\nthe performance. We find that adding LLM labels from good LLMs to existing\ncrowdsourcing datasets can enhance the quality of the aggregated labels of the\ndatasets, which is also higher than the quality of LLM labels themselves.",
        "date": "Not Found"
    },
    {
        "title": "Title:CLIP Model for Images to Textual Prompts Based on Top-k Neighbors",
        "authors": [
            "",
            "Authors:",
            "",
            "Xin Zhang",
            ",",
            "Xin Zhang",
            ",",
            "YeMing Cai",
            ",",
            "Tianzhi Jia",
            ""
        ],
        "abstract": "Text-to-image synthesis, a subfield of multimodal generation, has gained\nsignificant attention in recent years. We propose a cost-effective approach for\nimage-to-prompt generation that leverages generative models to generate textual\nprompts without the need for large amounts of annotated data. We divide our\nmethod into two stages: online stage and offline stage. We use a combination of\nthe CLIP model and K-nearest neighbors (KNN) algorithm. The proposed system\nconsists of two main parts: an offline task and an online task. Our method owns\nthe highest metric 0.612 among these models, which is 0.013, 0.055, 0.011\nhigher than Clip, Clip + KNN(top 10) respectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Generation of weighted trees, block trees and block graphs",
        "authors": [
            "",
            "Authors:",
            "",
            "T\u0131naz Ekim",
            ",",
            "Mordechai Shalom",
            ",",
            "Mehmet Aziz Yirik",
            ""
        ],
        "abstract": "We present a general framework to generate trees every vertex of which has a\nnon-negative weight and a color. The colors are used to impose certain\nrestrictions on the weight and colors of other vertices. We first extend the\nenumeration algorithms of unweighted trees given in [19, 20] to generate\nweighted trees that allow zero weight. We avoid isomorphisms by generalizing\nthe concept of centroids to weighted trees and then using the so-called\ncentroid-rooted canonical weighted trees. We provide a time complexity analysis\nof unranking algorithms and also show that the output delay complexity of\nenumeration is linear. The framework can be used to generate graph classes\ntaking advantage of their tree-based decompositions/representations. We\ndemonstrate our framework by generating weighted block trees which are in\none-to-one correspondence with connected block graphs. All connected block\ngraphs up to 19 vertices are publicly available at [1].",
        "date": "Not Found"
    },
    {
        "title": "Title:On the Effectiveness of Function-Level Vulnerability Detectors for  Inter-Procedural Vulnerabilities",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhen Li",
            ",",
            "Ning Wang",
            ",",
            "Deqing Zou",
            ",",
            "Yating Li",
            ",",
            "Ruqian Zhang",
            ",",
            "Shouhuai Xu",
            ",",
            "Chao Zhang",
            ",",
            "Hai Jin",
            ""
        ],
        "abstract": "Software vulnerabilities are a major cyber threat and it is important to\ndetect them. One important approach to detecting vulnerabilities is to use deep\nlearning while treating a program function as a whole, known as function-level\nvulnerability detectors. However, the limitation of this approach is not\nunderstood. In this paper, we investigate its limitation in detecting one class\nof vulnerabilities known as inter-procedural vulnerabilities, where the\nto-be-patched statements and the vulnerability-triggering statements belong to\ndifferent functions. For this purpose, we create the first Inter-Procedural\nVulnerability Dataset (InterPVD) based on C/C++ open-source software, and we\npropose a tool dubbed VulTrigger for identifying vulnerability-triggering\nstatements across functions. Experimental results show that VulTrigger can\neffectively identify vulnerability-triggering statements and inter-procedural\nvulnerabilities. Our findings include: (i) inter-procedural vulnerabilities are\nprevalent with an average of 2.8 inter-procedural layers; and (ii)\nfunction-level vulnerability detectors are much less effective in detecting\nto-be-patched functions of inter-procedural vulnerabilities than detecting\ntheir counterparts of intra-procedural vulnerabilities.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Learning from Graphs with Heterophily: Progress and Future",
        "authors": [
            "",
            "Authors:",
            "",
            "Chenghua Gong",
            ",",
            "Yao Cheng",
            ",",
            "Xiang Li",
            ",",
            "Caihua Shan",
            ",",
            "Siqiang Luo",
            ",",
            "Chuan Shi",
            ""
        ],
        "abstract": "Graphs are structured data that models complex relations between real-world\nentities. Heterophilous graphs, where linked nodes are prone to be with\ndifferent labels or dissimilar features, have recently attracted significant\nattention and found many applications. Meanwhile, increasing efforts have been\nmade to advance learning from heterophilous graphs. Although there exist\nsurveys on the relevant topic, they focus on heterophilous GNNs, which are only\nsub-topics of heterophilous graph learning. In this survey, we comprehensively\noverview existing works on learning from graphs with heterophily.First, we\ncollect over 180 publications and introduce the development of this field.\nThen, we systematically categorize existing methods based on a hierarchical\ntaxonomy including learning strategies, model architectures and practical\napplications. Finally, we discuss the primary challenges of existing studies\nand highlight promising avenues for future research.More publication details\nand corresponding open-source codes can be accessed and will be continuously\nupdated at our\nrepositories:https://github.com/gongchenghua/Awesome-Survey-Graphs-with-Heterophily.",
        "date": "Not Found"
    },
    {
        "title": "Title:Reliability-based G1 Continuous Arc Spline Approximation",
        "authors": [
            "",
            "Authors:",
            "",
            "Jinhwan Jeon",
            ",",
            "Yoonjin Hwang",
            ",",
            "Seibum B. Choi",
            ""
        ],
        "abstract": "In this paper, we present an algorithm to approximate a set of data points\nwith G1 continuous arcs, using points' covariance data. To the best of our\nknowledge, previous arc spline approximation approaches assumed that all data\npoints contribute equally (i.e. have the same weights) during the approximation\nprocess. However, this assumption may cause serious instability in the\nalgorithm, if the collected data contains outliers. To resolve this issue, a\nrobust method for arc spline approximation is suggested in this work, assuming\nthat the 2D covariance for each data point is given. Starting with the\ndefinition of models and parameters for single arc approximation, the framework\nis extended to multiple-arc approximation for general usage. Then the proposed\nalgorithm is verified using generated noisy data and real-world collected data\nvia vehicle experiment in Sejong City, South Korea.",
        "date": "Not Found"
    },
    {
        "title": "Title:Robotic Test Tube Rearrangement Using Combined Reinforcement Learning  and Motion Planning",
        "authors": [
            "",
            "Authors:",
            "",
            "Hao Chen",
            ",",
            "Weiwei Wan",
            ",",
            "Masaki Matsushita",
            ",",
            "Takeyuki Kotaka",
            ",",
            "Kensuke Harada",
            ""
        ],
        "abstract": "A combined task-level reinforcement learning and motion planning framework is\nproposed in this paper to address a multi-class in-rack test tube rearrangement\nproblem. At the task level, the framework uses reinforcement learning to infer\na sequence of swap actions while ignoring robotic motion details. At the motion\nlevel, the framework accepts the swapping action sequences inferred by\ntask-level agents and plans the detailed robotic pick-and-place motion. The\ntask and motion-level planning form a closed loop with the help of a condition\nset maintained for each rack slot, which allows the framework to perform\nreplanning and effectively find solutions in the presence of low-level\nfailures. Particularly for reinforcement learning, the framework leverages a\ndistributed deep Q-learning structure with the Dueling Double Deep Q Network\n(D3QN) to acquire near-optimal policies and uses an A${}^\\star$-based\npost-processing technique to amplify the collected training data. The D3QN and\ndistributed learning help increase training efficiency. The post-processing\nhelps complete unfinished action sequences and remove redundancy, thus making\nthe training data more effective. We carry out both simulations and real-world\nstudies to understand the performance of the proposed framework. The results\nverify the performance of the RL and post-processing and show that the\nclosed-loop combination improves robustness. The framework is ready to\nincorporate various sensory feedback. The real-world studies also demonstrated\nthe incorporation.",
        "date": "Not Found"
    },
    {
        "title": "Title:SEINE: Structure Encoding and Interaction Network for Nuclei Instance  Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Ye Zhang",
            ",",
            "Linghan Cai",
            ",",
            "Ziyue Wang",
            ",",
            "Yongbing Zhang",
            ""
        ],
        "abstract": "Nuclei instance segmentation in histopathological images is of great\nimportance for biological analysis and cancer diagnosis but remains challenging\nfor two reasons. (1) Similar visual presentation of intranuclear and\nextranuclear regions of chromophobe nuclei often causes under-segmentation, and\n(2) current methods lack the exploration of nuclei structure, resulting in\nfragmented instance predictions. To address these problems, this paper proposes\na structure encoding and interaction network, termed SEINE, which develops the\nstructure modeling scheme of nuclei and exploits the structure similarity\nbetween nuclei to improve the integrality of each segmented instance.\nConcretely, SEINE introduces a contour-based structure encoding (SE) that\nconsiders the correlation between nuclei structure and semantics, realizing a\nreasonable representation of the nuclei structure. Based on the encoding, we\npropose a structure-guided attention (SGA) that takes the clear nuclei as\nprototypes to enhance the structure learning for the fuzzy nuclei. To\nstrengthen the structural learning ability, a semantic feature fusion (SFF) is\npresented to boost the semantic consistency of semantic and structure branches.\nFurthermore, a position enhancement (PE) method is applied to suppress\nincorrect nuclei boundary predictions. Extensive experiments demonstrate the\nsuperiority of our approaches, and SEINE achieves state-of-the-art (SOTA)\nperformance on four datasets. The code is available at\n\\href{https://github.com/zhangye-zoe/SEINE}{https://github.com/zhangye-zoe/SEINE}.",
        "date": "Not Found"
    },
    {
        "title": "Title:On the Audio Hallucinations in Large Audio-Video Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Taichi Nishimura",
            ",",
            "Shota Nakada",
            ",",
            "Masayoshi Kondo",
            ""
        ],
        "abstract": "Large audio-video language models can generate descriptions for both video\nand audio. However, they sometimes ignore audio content, producing audio\ndescriptions solely reliant on visual information. This paper refers to this as\naudio hallucinations and analyzes them in large audio-video language models. We\ngather 1,000 sentences by inquiring about audio information and annotate them\nwhether they contain hallucinations. If a sentence is hallucinated, we also\ncategorize the type of hallucination. The results reveal that 332 sentences are\nhallucinated with distinct trends observed in nouns and verbs for each\nhallucination type. Based on this, we tackle a task of audio hallucination\nclassification using pre-trained audio-text models in the zero-shot and\nfine-tuning settings. Our experimental results reveal that the zero-shot models\nachieve higher performance (52.2% in F1) than the random (40.3%) and the\nfine-tuning models achieve 87.9%, outperforming the zero-shot models.",
        "date": "Not Found"
    },
    {
        "title": "Title:Controllable Decontextualization of Yes/No Question and Answers into  Factual Statements",
        "authors": [
            "",
            "Authors:",
            "",
            "Lingbo Mo",
            ",",
            "Besnik Fetahu",
            ",",
            "Oleg Rokhlenko",
            ",",
            "Shervin Malmasi",
            ""
        ],
        "abstract": "Yes/No or polar questions represent one of the main linguistic question\ncategories. They consist of a main interrogative clause, for which the answer\nis binary (assertion or negation). Polar questions and answers (PQA) represent\na valuable knowledge resource present in many community and other curated QA\nsources, such as forums or e-commerce applications. Using answers to polar\nquestions alone in other contexts is not trivial. Answers are contextualized,\nand presume that the interrogative question clause and any shared knowledge\nbetween the asker and answerer are provided.\nWe address the problem of controllable rewriting of answers to polar\nquestions into decontextualized and succinct factual statements. We propose a\nTransformer sequence to sequence model that utilizes soft-constraints to ensure\ncontrollable rewriting, such that the output statement is semantically\nequivalent to its PQA input. Evaluation on three separate PQA datasets as\nmeasured through automated and human evaluation metrics show that our proposed\napproach achieves the best performance when compared to existing baselines.",
        "date": "Not Found"
    },
    {
        "title": "Title:Leveraging Biases in Large Language Models: \"bias-kNN'' for Effective  Few-Shot Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Yong Zhang",
            ",",
            "Hanzhang Li",
            ",",
            "Zhitao Li",
            ",",
            "Ning Cheng",
            ",",
            "Ming Li",
            ",",
            "Jing Xiao",
            ",",
            "Jianzong Wang",
            ""
        ],
        "abstract": "Large Language Models (LLMs) have shown significant promise in various\napplications, including zero-shot and few-shot learning. However, their\nperformance can be hampered by inherent biases. Instead of traditionally sought\nmethods that aim to minimize or correct these biases, this study introduces a\nnovel methodology named ``bias-kNN''. This approach capitalizes on the biased\noutputs, harnessing them as primary features for kNN and supplementing with\ngold labels. Our comprehensive evaluations, spanning diverse domain text\nclassification datasets and different GPT-2 model sizes, indicate the\nadaptability and efficacy of the ``bias-kNN'' method. Remarkably, this approach\nnot only outperforms conventional in-context learning in few-shot scenarios but\nalso demonstrates robustness across a spectrum of samples, templates and\nverbalizers. This study, therefore, presents a unique perspective on harnessing\nbiases, transforming them into assets for enhanced model performance.",
        "date": "Not Found"
    },
    {
        "title": "Title:Instant Answering in E-Commerce Buyer-Seller Messaging",
        "authors": [
            "",
            "Authors:",
            "",
            "Besnik Fetahu",
            ",",
            "Tejas Mehta",
            ",",
            "Qun Song",
            ",",
            "Nikhita Vedula",
            ",",
            "Oleg Rokhlenko",
            ",",
            "Shervin Malmasi",
            ""
        ],
        "abstract": "E-commerce customers frequently seek detailed product information for\npurchase decisions, commonly contacting sellers directly with extended queries.\nThis manual response requirement imposes additional costs and disrupts buyer's\nshopping experience with response time fluctuations ranging from hours to days.\nWe seek to automate buyer inquiries to sellers in a leading e-commerce store\nusing a domain-specific federated Question Answering (QA) system. The main\nchallenge is adapting current QA systems, designed for single questions, to\naddress detailed customer queries. We address this with a low-latency,\nsequence-to-sequence approach, MESSAGE-TO-QUESTION ( M2Q ). It reformulates\nbuyer messages into succinct questions by identifying and extracting the most\nsalient information from a message. Evaluation against baselines shows that M2Q\nyields relative increases of 757% in question understanding, and 1,746% in\nanswering rate from the federated QA system. Live deployment shows that\nautomatic answering saves sellers from manually responding to millions of\nmessages per year, and also accelerates customer purchase decisions by\neliminating the need for buyers to wait for a reply",
        "date": "Not Found"
    },
    {
        "title": "Title:Adaptive Self-training Framework for Fine-grained Scene Graph Generation",
        "authors": [
            "",
            "Authors:",
            "",
            "Kibum Kim",
            ",",
            "Kanghoon Yoon",
            ",",
            "Yeonjun In",
            ",",
            "Jinyoung Moon",
            ",",
            "Donghyun Kim",
            ",",
            "Chanyoung Park",
            ""
        ],
        "abstract": "Scene graph generation (SGG) models have suffered from inherent problems\nregarding the benchmark datasets such as the long-tailed predicate distribution\nand missing annotation problems. In this work, we aim to alleviate the\nlong-tailed problem of SGG by utilizing unannotated triplets. To this end, we\nintroduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels\nfor unannotated triplets based on which the SGG models are trained. While there\nhas been significant progress in self-training for image recognition, designing\na self-training framework for the SGG task is more challenging due to its\ninherent nature such as the semantic ambiguity and the long-tailed distribution\nof predicate classes. Hence, we propose a novel pseudo-labeling technique for\nSGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is\na model-agnostic framework that can be applied to any existing SGG models.\nFurthermore, we devise a graph structure learner (GSL) that is beneficial when\nadopting our proposed self-training framework to the state-of-the-art\nmessage-passing neural network (MPNN)-based SGG models. Our extensive\nexperiments verify the effectiveness of ST-SGG on various SGG models,\nparticularly in enhancing the performance on fine-grained predicate classes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Querying Easily Flip-flopped Samples for Deep Active Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Seong Jin Cho",
            ",",
            "Gwangsu Kim",
            ",",
            "Junghyun Lee",
            ",",
            "Jinwoo Shin",
            ",",
            "Chang D. Yoo",
            ""
        ],
        "abstract": "Active learning is a machine learning paradigm that aims to improve the\nperformance of a model by strategically selecting and querying unlabeled data.\nOne effective selection strategy is to base it on the model's predictive\nuncertainty, which can be interpreted as a measure of how informative a sample\nis. The sample's distance to the decision boundary is a natural measure of\npredictive uncertainty, but it is often intractable to compute, especially for\ncomplex decision boundaries formed in multiclass classification tasks. To\naddress this issue, this paper proposes the {\\it least disagree metric} (LDM),\ndefined as the smallest probability of disagreement of the predicted label, and\nan estimator for LDM proven to be asymptotically consistent under mild\nassumptions. The estimator is computationally efficient and can be easily\nimplemented for deep learning models using parameter perturbation. The\nLDM-based active learning is performed by querying unlabeled data with the\nsmallest LDM. Experimental results show that our LDM-based active learning\nalgorithm obtains state-of-the-art overall performance on all considered\ndatasets and deep architectures.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Semantic Approach for Big Data Exploration in Industry 4.0",
        "authors": [
            "",
            "Authors:",
            "",
            "Idoia Berges",
            ",",
            "V\u00edctor Julio Ram\u00edrez-Dur\u00e1n",
            ",",
            "Arantza Illarramendi",
            ""
        ],
        "abstract": "The growing trends in automation, Internet of Things, big data and cloud\ncomputing technologies have led to the fourth industrial revolution (Industry\n4.0), where it is possible to visualize and identify patterns and insights,\nwhich results in a better understanding of the data and can improve the\nmanufacturing process. However, many times, the task of data exploration\nresults difficult for manufacturing experts because they might be interested in\nanalyzing also data that does not appear in pre-designed visualizations and\ntherefore they must be assisted by Information Technology experts. In this\npaper, we present a proposal materialized in a semantic-based visual query\nsystem developed for a real Industry 4.0 scenario that allows domain experts to\nexplore and visualize data in a friendly way. The main novelty of the system is\nthe combined use that it makes of captured data that are semantically annotated\nfirst, and a 2D customized digital representation of a machine that is also\nlinked with semantic descriptions. Those descriptions are expressed using terms\nof an ontology, where, among others, the sensors that are used to capture\nindicators about the performance of a machine that belongs to a Industry 4.0\nscenario have been modeled. Moreover, this semantic description allows to:\nformulate queries at a higher level of abstraction, provide customized\ngraphical visualizations of the results based on the format and nature of the\ndata, and download enriched data enabling further types of analysis.",
        "date": "Not Found"
    },
    {
        "title": "Title:PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhijie Zhong",
            ",",
            "Zhiwen Yu",
            ",",
            "Yiyuan Yang",
            ",",
            "Weizheng Wang",
            ",",
            "Kaixiang Yang",
            ""
        ],
        "abstract": "Anomaly detection stands as a crucial aspect of time series analysis, aiming\nto identify abnormal events in time series samples. The central challenge of\nthis task lies in effectively learning the representations of normal and\nabnormal patterns in a label-lacking scenario. Previous research mostly relied\non reconstruction-based approaches, restricting the representational abilities\nof the models. In addition, most of the current deep learning-based methods are\nnot lightweight enough, which prompts us to design a more efficient framework\nfor anomaly detection. In this study, we introduce PatchAD, a novel multi-scale\npatch-based MLP-Mixer architecture that leverages contrastive learning for\nrepresentational extraction and anomaly detection. Specifically, PatchAD is\ncomposed of four distinct MLP Mixers, exclusively utilizing the MLP\narchitecture for high efficiency and lightweight architecture. Additionally, we\nalso innovatively crafted a dual project constraint module to mitigate\npotential model degradation. Comprehensive experiments demonstrate that PatchAD\nachieves state-of-the-art results across multiple real-world multivariate time\nseries datasets. Our code is publicly\navailable.\\footnote{\\url{https://github.com/EmorZz1G/PatchAD}}",
        "date": "Not Found"
    },
    {
        "title": "Title:Wavelet-Guided Acceleration of Text Inversion in Diffusion-Based Image  Editing",
        "authors": [
            "",
            "Authors:",
            "",
            "Gwanhyeong Koo",
            ",",
            "Sunjae Yoon",
            ",",
            "Chang D. Yoo",
            ""
        ],
        "abstract": "In the field of image editing, Null-text Inversion (NTI) enables fine-grained\nediting while preserving the structure of the original image by optimizing null\nembeddings during the DDIM sampling process. However, the NTI process is\ntime-consuming, taking more than two minutes per image. To address this, we\nintroduce an innovative method that maintains the principles of the NTI while\naccelerating the image editing process. We propose the WaveOpt-Estimator, which\ndetermines the text optimization endpoint based on frequency characteristics.\nUtilizing wavelet transform analysis to identify the image's frequency\ncharacteristics, we can limit text optimization to specific timesteps during\nthe DDIM sampling process. By adopting the Negative-Prompt Inversion (NPI)\nconcept, a target prompt representing the original image serves as the initial\ntext value for optimization. This approach maintains performance comparable to\nNTI while reducing the average editing time by over 80% compared to the NTI\nmethod. Our method presents a promising approach for efficient, high-quality\nimage editing based on diffusion models.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Comparative Analysis on Metaheuristic Algorithms Based Vision  Transformer Model for Early Detection of Alzheimer's Disease",
        "authors": [
            "",
            "Authors:",
            "",
            "Anuvab Sen",
            ",",
            "Udayon Sen",
            ",",
            "Subhabrata Roy",
            ""
        ],
        "abstract": "A number of life threatening neuro-degenerative disorders had degraded the\nquality of life for the older generation in particular. Dementia is one such\nsymptom which may lead to a severe condition called Alzheimer's disease if not\ndetected at an early stage. It has been reported that the progression of such\ndisease from a normal stage is due to the change in several parameters inside\nthe human brain. In this paper, an innovative metaheuristic algorithms based\nViT model has been proposed for the identification of dementia at different\nstage. A sizeable number of test data have been utilized for the validation of\nthe proposed scheme. It has also been demonstrated that our model exhibits\nsuperior performance in terms of accuracy, precision, recall as well as\nF1-score.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Fast, Performant, Secure Distributed Training Framework For Large  Language Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Wei Huang",
            ",",
            "Yinggui Wang",
            ",",
            "Anda Cheng",
            ",",
            "Aihui Zhou",
            ",",
            "Chaofan Yu",
            ",",
            "Lei Wang",
            ""
        ],
        "abstract": "The distributed (federated) LLM is an important method for co-training the\ndomain-specific LLM using siloed data. However, maliciously stealing model\nparameters and data from the server or client side has become an urgent problem\nto be solved. In this paper, we propose a secure distributed LLM based on model\nslicing. In this case, we deploy the Trusted Execution Environment (TEE) on\nboth the client and server side, and put the fine-tuned structure (LoRA or\nembedding of P-tuning v2) into the TEE. Then, secure communication is executed\nin the TEE and general environments through lightweight encryption. In order to\nfurther reduce the equipment cost as well as increase the model performance and\naccuracy, we propose a split fine-tuning scheme. In particular, we split the\nLLM by layers and place the latter layers in a server-side TEE (the client does\nnot need a TEE). We then combine the proposed Sparsification Parameter\nFine-tuning (SPF) with the LoRA part to improve the accuracy of the downstream\ntask. Numerous experiments have shown that our method guarantees accuracy while\nmaintaining security.",
        "date": "Not Found"
    },
    {
        "title": "Title:All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks",
        "authors": [
            "",
            "Authors:",
            "",
            "Kazuhiro Takemoto",
            ""
        ],
        "abstract": "Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where\nsafeguards are bypassed to produce ethically harmful prompts. This study\nintroduces a simple black-box method to effectively generate jailbreak prompts,\novercoming the limitations of high complexity and computational costs\nassociated with existing methods. The proposed technique iteratively rewrites\nharmful prompts into non-harmful expressions using the target LLM itself, based\non the hypothesis that LLMs can directly sample safeguard-bypassing\nexpressions. Demonstrated through experiments with ChatGPT (GPT-3.5 and GPT-4)\nand Gemini-Pro, this method achieved an attack success rate of over 80% within\nan average of 5 iterations and remained effective despite model updates. The\njailbreak prompts generated were naturally-worded and concise, suggesting they\nare less detectable. The results indicate that creating effective jailbreak\nprompts is simpler than previously considered, and black-box jailbreak attacks\npose a more serious security threat.",
        "date": "Not Found"
    },
    {
        "title": "Title:Power System Fault Diagnosis with Quantum Computing and Efficient Gate  Decomposition",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiang Fei",
            ",",
            "Huan Zhao",
            ",",
            "Xiyuan Zhou",
            ",",
            "Junhua Zhao",
            ",",
            "Ting Shu",
            ",",
            "Fushuan Wen",
            ""
        ],
        "abstract": "Power system fault diagnosis is crucial for identifying the location and\ncauses of faults and providing decision-making support for power dispatchers.\nHowever, most classical methods suffer from significant time-consuming, memory\noverhead, and computational complexity issues as the scale of the power system\nconcerned increases. With rapid development of quantum computing technology,\nthe combinatorial optimization method based on quantum computing has shown\ncertain advantages in computational time over existing methods. Given this\nbackground, this paper proposes a quantum computing based power system fault\ndiagnosis method with the Quantum Approximate Optimization Algorithm (QAOA).\nThe proposed method reformulates the fault diagnosis problem as a Hamiltonian\nby using Ising model, which completely preserves the coupling relationship\nbetween faulty components and various operations of protective relays and\ncircuit breakers. Additionally, to enhance problem-solving efficiency under\ncurrent equipment limitations, the symmetric equivalent decomposition method of\nmulti-z-rotation gate is proposed. Furthermore, the small probability\ncharacteristics of power system events is utilized to reduce the number of\nqubits. Simulation results based on the test system show that the proposed\nmethods can achieve the same optimal results with a faster speed compared with\nthe classical higher-order solver provided by D-Wave.",
        "date": "Not Found"
    },
    {
        "title": "Title:Clickbait vs. Quality: How Engagement-Based Optimization Shapes the  Content Landscape in Online Platforms",
        "authors": [
            "",
            "Authors:",
            "",
            "Nicole Immorlica",
            ",",
            "Meena Jagadeesan",
            ",",
            "Brendan Lucier",
            ""
        ],
        "abstract": "Online content platforms commonly use engagement-based optimization when\nmaking recommendations. This encourages content creators to invest in quality,\nbut also rewards gaming tricks such as clickbait. To understand the total\nimpact on the content landscape, we study a game between content creators\ncompeting on the basis of engagement metrics and analyze the equilibrium\ndecisions about investment in quality and gaming. First, we show the content\ncreated at equilibrium exhibits a positive correlation between quality and\ngaming, and we empirically validate this finding on a Twitter dataset. Using\nthe equilibrium structure of the content landscape, we then examine the\ndownstream performance of engagement-based optimization along several axes.\nPerhaps counterintuitively, the average quality of content consumed by users\ncan decrease at equilibrium as gaming tricks become more costly for content\ncreators to employ. Moreover, engagement-based optimization can perform worse\nin terms of user utility than a baseline with random recommendations, and\nengagement-based optimization is also suboptimal in terms of realized\nengagement relative to quality-based optimization. Altogether, our results\nhighlight the need to consider content creator incentives when evaluating a\nplatform's choice of optimization metric.",
        "date": "Not Found"
    },
    {
        "title": "Title:SensoDat: Simulation-based Sensor Dataset of Self-driving Cars",
        "authors": [
            "",
            "Authors:",
            "",
            "Christian Birchler",
            ",",
            "Cyrill Rohrbach",
            ",",
            "Timo Kehrer",
            ",",
            "Sebastiano Panichella",
            ""
        ],
        "abstract": "Developing tools in the context of autonomous systems [22, 24 ], such as\nself-driving cars (SDCs), is time-consuming and costly since researchers and\npractitioners rely on expensive computing hardware and simulation software. We\npropose SensoDat, a dataset of 32,580 executed simulation-based SDC test cases\ngenerated with state-of-the-art test generators for SDCs. The dataset consists\nof trajectory logs and a variety of sensor data from the SDCs (e.g., rpm, wheel\nspeed, brake thermals, transmission, etc.) represented as a time series. In\ntotal, SensoDat provides data from 81 different simulated sensors. Future\nresearch in the domain of SDCs does not necessarily depend on executing\nexpensive test cases when using SensoDat. Furthermore, with the high amount and\nvariety of sensor data, we think SensoDat can contribute to research,\nparticularly for AI development, regression testing techniques for\nsimulation-based SDC testing, flakiness in simulation, etc. Link to the\ndataset: https://doi.org/10.5281/zenodo.10307479",
        "date": "Not Found"
    },
    {
        "title": "Title:Simple and effective data augmentation for compositional generalization",
        "authors": [
            "",
            "Authors:",
            "",
            "Yuekun Yao",
            ",",
            "Alexander Koller",
            ""
        ],
        "abstract": "Compositional generalization, the ability to predict complex meanings from\ntraining on simpler sentences, poses challenges for powerful pretrained seq2seq\nmodels. In this paper, we show that data augmentation methods that sample MRs\nand backtranslate them can be effective for compositional generalization, but\nonly if we sample from the right distribution. Remarkably, sampling from a\nuniform distribution performs almost as well as sampling from the test\ndistribution, and greatly outperforms earlier methods that sampled from the\ntraining distribution. We further conduct experiments to investigate the reason\nwhy this happens and where the benefit of such data augmentation methods come\nfrom.",
        "date": "Not Found"
    },
    {
        "title": "Title:PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path  Planning",
        "authors": [
            "",
            "Authors:",
            "",
            "Qinglong Meng",
            ",",
            "Chongkun Xia",
            ",",
            "Xueqian Wang",
            ",",
            "Songping Mai",
            ",",
            "Bin Liang",
            ""
        ],
        "abstract": "The classical path planners, such as sampling-based path planners, have the\nlimitations of sensitivity to the initial solution and slow convergence to the\noptimal solution. However, finding a near-optimal solution in a short period is\nchallenging in many applications such as the autonomous vehicle with limited\npower/fuel. To achieve an end-to-end near-optimal path planner, we first divide\nthe path planning problem into two subproblems, which are path's space\nsegmentation and waypoints generation in the given path's space. We further\npropose a two-level cascade neural network named Path Planning Network (PPNet)\nto solve the path planning problem by solving the abovementioned subproblems.\nMoreover, we propose a novel efficient data generation method for path planning\nnamed EDaGe-PP. The results show the total computation time is less than 1/33\nand the success rate of PPNet trained by the dataset that is generated by\nEDaGe-PP is about $2 \\times$ compared to other methods. We validate PPNet\nagainst state-of-the-art path planning methods. The results show PPNet can find\na near-optimal solution in 15.3ms, which is much shorter than the\nstate-of-the-art path planners.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhancing Small Object Encoding in Deep Neural Networks: Introducing  Fast&Focused-Net with Volume-wise Dot Product Layer",
        "authors": [
            "",
            "Authors:",
            "",
            "Ali Tofik",
            ",",
            "Roy Partha Pratim",
            ""
        ],
        "abstract": "In this paper, we introduce Fast&Focused-Net, a novel deep neural network\narchitecture tailored for efficiently encoding small objects into fixed-length\nfeature vectors. Contrary to conventional Convolutional Neural Networks (CNNs),\nFast&Focused-Net employs a series of our newly proposed layer, the Volume-wise\nDot Product (VDP) layer, designed to address several inherent limitations of\nCNNs. Specifically, CNNs often exhibit a smaller effective receptive field than\ntheir theoretical counterparts, limiting their vision span. Additionally, the\ninitial layers in CNNs produce low-dimensional feature vectors, presenting a\nbottleneck for subsequent learning. Lastly, the computational overhead of CNNs,\nparticularly in capturing diverse image regions by parameter sharing, is\nsignificantly high. The VDP layer, at the heart of Fast&Focused-Net, aims to\nremedy these issues by efficiently covering the entire image patch information\nwith reduced computational demand. Experimental results demonstrate the prowess\nof Fast&Focused-Net in a variety of applications. For small object\nclassification tasks, our network outperformed state-of-the-art methods on\ndatasets such as CIFAR-10, CIFAR-100, STL-10, SVHN-Cropped, and Fashion-MNIST.\nIn the context of larger image classification, when combined with a transformer\nencoder (ViT), Fast&Focused-Net produced competitive results for OpenImages V6,\nImageNet-1K, and Places365 datasets. Moreover, the same combination showcased\nunparalleled performance in text recognition tasks across SVT, IC15, SVTP, and\nHOST datasets. This paper presents the architecture, the underlying motivation,\nand extensive empirical evidence suggesting that Fast&Focused-Net is a\npromising direction for efficient and focused deep learning.",
        "date": "Not Found"
    },
    {
        "title": "Title:Conning the Crypto Conman: End-to-End Analysis of Cryptocurrency-based  Technical Support Scams",
        "authors": [
            "",
            "Authors:",
            "",
            "Bhupendra Acharya",
            ",",
            "Muhammad Saad",
            ",",
            "Antonio Emanuele Cin\u00e0",
            ",",
            "Lea Sch\u00f6nherr",
            ",",
            "Hoang Dai Nguyen",
            ",",
            "Adam Oest",
            ",",
            "Phani Vadrevu",
            ",",
            "Thorsten Holz",
            ""
        ],
        "abstract": "The mainstream adoption of cryptocurrencies has led to a surge in\nwallet-related issues reported by ordinary users on social media platforms. In\nparallel, there is an increase in an emerging fraud trend called\ncryptocurrency-based technical support scam, in which fraudsters offer fake\nwallet recovery services and target users experiencing wallet-related issues.\nIn this paper, we perform a comprehensive study of cryptocurrency-based\ntechnical support scams. We present an analysis apparatus called HoneyTweet to\nanalyze this kind of scam. Through HoneyTweet, we lure over 9K scammers by\nposting 25K fake wallet support tweets (so-called honey tweets). We then deploy\nautomated systems to interact with scammers to analyze their modus operandi. In\nour experiments, we observe that scammers use Twitter as a starting point for\nthe scam, after which they pivot to other communication channels (eg email,\nInstagram, or Telegram) to complete the fraud activity. We track scammers\nacross those communication channels and bait them into revealing their payment\nmethods. Based on the modes of payment, we uncover two categories of scammers\nthat either request secret key phrase submissions from their victims or direct\npayments to their digital wallets. Furthermore, we obtain scam confirmation by\ndeploying honey wallet addresses and validating private key theft. We also\ncollaborate with the prominent payment service provider by sharing scammer data\ncollections. The payment service provider feedback was consistent with our\nfindings, thereby supporting our methodology and results. By consolidating our\nanalysis across various vantage points, we provide an end-to-end scam lifecycle\nanalysis and propose recommendations for scam mitigation.",
        "date": "Not Found"
    },
    {
        "title": "Title:Boosting Few-Shot Semantic Segmentation Via Segment Anything Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Chen-Bin Feng",
            ",",
            "Qi Lai",
            ",",
            "Kangdao Liu",
            ",",
            "Houcheng Su",
            ",",
            "Chi-Man Vong",
            ""
        ],
        "abstract": "In semantic segmentation, accurate prediction masks are crucial for\ndownstream tasks such as medical image analysis and image editing. Due to the\nlack of annotated data, few-shot semantic segmentation (FSS) performs poorly in\npredicting masks with precise contours. Recently, we have noticed that the\nlarge foundation model segment anything model (SAM) performs well in processing\ndetailed features. Inspired by SAM, we propose FSS-SAM to boost FSS methods by\naddressing the issue of inaccurate contour. The FSS-SAM is training-free. It\nworks as a post-processing tool for any FSS methods and can improve the\naccuracy of predicted masks. Specifically, we use predicted masks from FSS\nmethods to generate prompts and then use SAM to predict new masks. To avoid\npredicting wrong masks with SAM, we propose a prediction result selection (PRS)\nalgorithm. The algorithm can remarkably decrease wrong predictions. Experiment\nresults on public datasets show that our method is superior to base FSS methods\nin both quantitative and qualitative aspects.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhanced Automated Quality Assessment Network for Interactive Building  Segmentation in High-Resolution Remote Sensing Imagery",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhili Zhang",
            ",",
            "Xiangyun Hu",
            ",",
            "Jiabo Xu",
            ""
        ],
        "abstract": "In this research, we introduce the enhanced automated quality assessment\nnetwork (IBS-AQSNet), an innovative solution for assessing the quality of\ninteractive building segmentation within high-resolution remote sensing\nimagery. This is a new challenge in segmentation quality assessment, and our\nproposed IBS-AQSNet allievate this by identifying missed and mistaken segment\nareas. First of all, to acquire robust image features, our method combines a\nrobust, pre-trained backbone with a lightweight counterpart for comprehensive\nfeature extraction from imagery and segmentation results. These features are\nthen fused through a simple combination of concatenation, convolution layers,\nand residual connections. Additionally, ISR-AQSNet incorporates a multi-scale\ndifferential quality assessment decoder, proficient in pinpointing areas where\nsegmentation result is either missed or mistaken. Experiments on a newly-built\nEVLab-BGZ dataset, which includes over 39,198 buildings, demonstrate the\nsuperiority of the proposed method in automating segmentation quality\nassessment, thereby setting a new benchmark in the field.",
        "date": "Not Found"
    },
    {
        "title": "Title:Measuring Object Rotation via Visuo-Tactile Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Julio Casta\u00f1o",
            ",",
            "Pablo Gil",
            ""
        ],
        "abstract": "When carrying out robotic manipulation tasks, objects occasionally fall as a\nresult of the rotation caused by slippage. This can be prevented by obtaining\ntactile information that provides better knowledge on the physical properties\nof the grasping. In this paper, we estimate the rotation angle of a grasped\nobject when slippage occurs. We implement a system made up of a neural network\nwith which to segment the contact region and an algorithm with which to\nestimate the rotated angle of that region. This method is applied to DIGIT\ntactile sensors. Our system has additionally been trained and tested with our\npublicly available dataset which is, to the best of our knowledge, the first\ndataset related to tactile segmentation from non-synthetic images to appear in\nthe literature, and with which we have attained results of 95% and 90% as\nregards Dice and IoU metrics in the worst scenario. Moreover, we have obtained\na maximum error of 3 degrees when testing with objects not previously seen by\nour system in 45 different lifts. This, therefore, proved that our approach is\nable to detect the slippage movement, thus providing a possible reaction that\nwill prevent the object from falling.",
        "date": "Not Found"
    },
    {
        "title": "Title:Convergence of a spatial semidiscretization for a three-dimensional  stochastic Allen-Cahn equation with multiplicative noise",
        "authors": [
            "",
            "Authors:",
            "",
            "Binjie Li",
            ",",
            "Qin Zhou",
            ""
        ],
        "abstract": "This paper studies the convergence of a spatial semidiscretization of a\nthree-dimensional stochastic Allen-Cahn equation with multiplicative noise. For\nnon-smooth initial values, the regularity of the mild solution is investigated,\nand an error estimate is derived with the spatial $ L^2 $-norm. For smooth\ninitial values, two error estimates with the general spatial $ L^q $-norms are\nestablished.",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploring Latent Cross-Channel Embedding for Accurate 3D Human Pose  Reconstruction in a Diffusion Framework",
        "authors": [
            "",
            "Authors:",
            "",
            "Junkun Jiang",
            ",",
            "Jie Chen",
            ""
        ],
        "abstract": "Monocular 3D human pose estimation poses significant challenges due to the\ninherent depth ambiguities that arise during the reprojection process from 2D\nto 3D. Conventional approaches that rely on estimating an over-fit projection\nmatrix struggle to effectively address these challenges and often result in\nnoisy outputs. Recent advancements in diffusion models have shown promise in\nincorporating structural priors to address reprojection ambiguities. However,\nthere is still ample room for improvement as these methods often overlook the\nexploration of correlation between the 2D and 3D joint-level features. In this\nstudy, we propose a novel cross-channel embedding framework that aims to fully\nexplore the correlation between joint-level features of 3D coordinates and\ntheir 2D projections. In addition, we introduce a context guidance mechanism to\nfacilitate the propagation of joint graph attention across latent channels\nduring the iterative diffusion process. To evaluate the effectiveness of our\nproposed method, we conduct experiments on two benchmark datasets, namely\nHuman3.6M and MPI-INF-3DHP. Our results demonstrate a significant improvement\nin terms of reconstruction accuracy compared to state-of-the-art methods. The\ncode for our method will be made available online for further reference.",
        "date": "Not Found"
    },
    {
        "title": "Title:CATMA: Conformance Analysis Tool For Microservice Applications",
        "authors": [
            "",
            "Authors:",
            "",
            "Clinton Cao",
            ",",
            "Simon Schneider",
            ",",
            "Nicol\u00e1s E. D\u00edaz Ferreyra",
            ",",
            "Sicco Verwer",
            ",",
            "Annibale Panichella",
            ",",
            "Riccardo Scandariato",
            ""
        ],
        "abstract": "The microservice architecture allows developers to divide the core\nfunctionality of their software system into multiple smaller services. However,\nthis architectural style also makes it harder for them to debug and assess\nwhether the system's deployment conforms to its implementation. We present\nCATMA, an automated tool that detects non-conformances between the system's\ndeployment and implementation. It automatically visualizes and generates\npotential interpretations for the detected discrepancies. Our evaluation of\nCATMA shows promising results in terms of performance and providing useful\ninsights. CATMA is available at\n\\url{https://cyber-analytics.nl/catma.github.io/}, and a demonstration video is\navailable at \\url{https://youtu.be/WKP1hG-TDKc}.",
        "date": "Not Found"
    },
    {
        "title": "Title:MatSciRE: Leveraging Pointer Networks to Automate Entity and Relation  Extraction for Material Science Knowledge-base Construction",
        "authors": [
            "",
            "Authors:",
            "",
            "Ankan Mullick",
            ",",
            "Akash Ghosh",
            ",",
            "G Sai Chaitanya",
            ",",
            "Samir Ghui",
            ",",
            "Tapas Nayak",
            ",",
            "Seung-Cheol Lee",
            ",",
            "Satadeep Bhattacharjee",
            ",",
            "Pawan Goyal",
            ""
        ],
        "abstract": "Material science literature is a rich source of factual information about\nvarious categories of entities (like materials and compositions) and various\nrelations between these entities, such as conductivity, voltage, etc.\nAutomatically extracting this information to generate a material science\nknowledge base is a challenging task. In this paper, we propose MatSciRE\n(Material Science Relation Extractor), a Pointer Network-based encoder-decoder\nframework, to jointly extract entities and relations from material science\narticles as a triplet ($entity1, relation, entity2$). Specifically, we target\nthe battery materials and identify five relations to work on - conductivity,\ncoulombic efficiency, capacity, voltage, and energy. Our proposed approach\nachieved a much better F1-score (0.771) than a previous attempt using\nChemDataExtractor (0.716). The overall graphical framework of MatSciRE is shown\nin Fig 1. The material information is extracted from material science\nliterature in the form of entity-relation triplets using MatSciRE.",
        "date": "Not Found"
    },
    {
        "title": "Title:Behavioral Simulation: Exploring A Possible Next Paradigm for Science",
        "authors": [
            "",
            "Authors:",
            "",
            "Cheng Wang",
            ",",
            "Chuwen Wang",
            ",",
            "Yu Zhao",
            ",",
            "Shirong Zeng",
            ",",
            "Wang Zhang",
            ",",
            "Ronghui Ning",
            ""
        ],
        "abstract": "Simulation technologies have been widely utilized in many scientific research\nfields such as weather forecasting, fluid mechanics and biological populations.\nIt is the best tool to handle problems in complex systems, where closed-form\nexpressions are unavailable and the target distribution in the representation\nspace is too complex to be fully represented by a deep learning (DL) model. We\nbelieve that the development of simulation technologies is consistent with\nscientific paradigms. This paper induces the evolution of scientific paradigms\nfrom the perspective of data, algorithms, and computational power. Building\nupon this perspective, we divide simulation technologies into three stages\naligning with the emergence of new paradigms, and find that advanced simulation\ntechnologies are typical instances of paradigms integration. Moreover, we\npropose the concept of behavioral simulation (BS), specifically sophisticated\nbehavioral simulation (SBS), representing a higher degree of paradigms\nintegration based on foundation models to simulate complex social systems\ninvolving sophisticated human strategies and behaviors. BS and further SBS are\ndesigned to tackle challenges concerning the complex human system that\nsurpasses the capacity of traditional agent-based modeling simulation (ABMS),\nwhich can be regarded as a possible next paradigm for science. Through this\nwork, we look forward to more powerful BS and SBS applications in scientific\nresearch branches within social science.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhancing the Fairness and Performance of Edge Cameras with Explainable  AI",
        "authors": [
            "",
            "Authors:",
            "",
            "Truong Thanh Hung Nguyen",
            ",",
            "Vo Thanh Khang Nguyen",
            ",",
            "Quoc Hung Cao",
            ",",
            "Van Binh Truong",
            ",",
            "Quoc Khanh Nguyen",
            ",",
            "Hung Cao",
            ""
        ],
        "abstract": "The rising use of Artificial Intelligence (AI) in human detection on Edge\ncamera systems has led to accurate but complex models, challenging to interpret\nand debug. Our research presents a diagnostic method using Explainable AI (XAI)\nfor model debugging, with expert-driven problem identification and solution\ncreation. Validated on the Bytetrack model in a real-world office Edge network,\nwe found the training dataset as the main bias source and suggested model\naugmentation as a solution. Our approach helps identify model biases, essential\nfor achieving fair and trustworthy models.",
        "date": "Not Found"
    },
    {
        "title": "Title:Game-theoretic Model Predictive Control for Modelling Competitive Supply  Chains",
        "authors": [
            "",
            "Authors:",
            "",
            "Sophie Hall",
            ",",
            "Laura Guerrini",
            ",",
            "Florian D\u00f6rfler",
            ",",
            "Dominic Liao-McPherson",
            ""
        ],
        "abstract": "Supply chains transform raw materials into finished goods and distribute them\nto end consumers. The vast majority of products we use daily are supplied to us\nthrough complex global supply chains. This paper proposes a modelling\nmethodology for dynamic competitive supply chains based on game theory and\nmodel predictive control. We model each manufacturer in the supply chain as a\nrational utility maximizing agent that selects their actions by finding an\nopen-loop generalized Nash equilibrium of a multi-stage game. To react to\ncompetitors and the state of the market, every agent re-plans their actions in\na receding horizon manner based on estimates of market and supplier parameters\nthereby creating an approximate closed-loop equilibrium policy. We demonstrate\nthrough numerical simulations that this modelling approach is computationally\ntractable and generates economically interpretable behaviors in a variety of\nsettings such as demand spikes, supply shocks, and information asymmetry.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Survey on Energy Consumption and Environmental Impact of Video  Streaming",
        "authors": [
            "",
            "Authors:",
            "",
            "Samira Afzal",
            ",",
            "Narges Mehran",
            ",",
            "Zoha Azimi Ourimi",
            ",",
            "Farzad Tashtarian",
            ",",
            "Hadi Amirpour",
            ",",
            "Radu Prodan",
            ",",
            "Christian Timmerer",
            ""
        ],
        "abstract": "Climate change challenges require a notable decrease in worldwide greenhouse\ngas (GHG) emissions across technology sectors. Digital technologies, especially\nvideo streaming, accounting for most Internet traffic, make no exception. Video\nstreaming demand increases with remote working, multimedia communication\nservices (e.g., WhatsApp, Skype), video streaming content (e.g., YouTube,\nNetflix), video resolution (4K/8K, 50 fps/60 fps), and multi-view video, making\nenergy consumption and environmental footprint critical. This survey\ncontributes to a better understanding of sustainable and efficient video\nstreaming technologies by providing insights into the state-of-the-art and\npotential future directions for researchers, developers, and engineers, service\nproviders, hosting platforms, and consumers. We widen this survey's focus on\ncontent provisioning and content consumption based on the observation that\ncontinuously active network equipment underneath video streaming consumes\nsubstantial energy independent of the transmitted data type. We propose a\ntaxonomy of factors that affect the energy consumption in video streaming, such\nas encoding schemes, resource requirements, storage, content retrieval,\ndecoding, and display. We identify notable weaknesses in video streaming that\nrequire further research for improved energy efficiency: (1) fixed bitrate\nladders in HTTP live streaming; (2) inefficient hardware utilization of\nexisting video players; (3) lack of comprehensive open energy measurement\ndataset covering various device types and coding parameters for reproducible\nresearch.",
        "date": "Not Found"
    },
    {
        "title": "Title:EDAF: An End-to-End Delay Analytics Framework for 5G-and-Beyond Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Samie Mostafavi",
            ",",
            "Marius Tillner",
            ",",
            "Gourav Prateek Sharma",
            ",",
            "James Gross",
            ""
        ],
        "abstract": "Supporting applications in emerging domains like cyber-physical systems and\nhuman-in-the-loop scenarios typically requires adherence to strict end-to-end\ndelay guarantees. Contributions of many tandem processes unfolding layer by\nlayer within the wireless network result in violations of delay constraints,\nthereby severely degrading application performance. Meeting the application's\nstringent requirements necessitates coordinated optimization of the end-to-end\ndelay by fine-tuning all contributing processes. To achieve this task, we\ndesigned and implemented EDAF, a framework to decompose packets' end-to-end\ndelays and determine each component's significance for 5G network. We showcase\nEDAF on OpenAirInterface 5G uplink, modified to report timestamps across the\ndata plane. By applying the obtained insights, we optimized end-to-end uplink\ndelay by eliminating segmentation and frame-alignment delays, decreasing\naverage delay from 12ms to 4ms.",
        "date": "Not Found"
    },
    {
        "title": "Title:The Distortion of Threshold Approval Matching",
        "authors": [
            "",
            "Authors:",
            "",
            "Mohamad Latifian",
            ",",
            "Alexandros A. Voudouris",
            ""
        ],
        "abstract": "We study matching settings in which a set of agents have private utilities\nover a set of items. Each agent reports a partition of the items into approval\nsets of different threshold utility levels. Given this limited information on\ninput, the goal is to compute an assignment of the items to the agents (subject\nto cardinality constraints depending on the application) that (approximately)\nmaximizes the social welfare (the total utility of the agents for their\nassigned items). We first consider the well-known, simple one-sided matching\nproblem in which each of $n$ agents is to be assigned exactly one of $n$ items.\nWe show that with $t$ threshold utility levels, the distortion of deterministic\nmatching algorithms is $\\Theta(\\sqrt[t]{n})$ while that of randomized\nalgorithms is $\\Theta(\\sqrt[t+1]{n})$. We then show that our distortion bounds\nextend to a more general setting in which there are multiple copies of the\nitems, each agent can be assigned a number of items (even copies of the same\none) up to a capacity, and the utility of an agent for an item depends on the\nnumber of its copies that the agent is given.",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving the Accuracy of Analog-Based In-Memory Computing Accelerators  Post-Training",
        "authors": [
            "",
            "Authors:",
            "",
            "Corey Lammie",
            ",",
            "Athanasios Vasilopoulos",
            ",",
            "Julian B\u00fcchel",
            ",",
            "Giacomo Camposampiero",
            ",",
            "Manuel Le Gallo",
            ",",
            "Malte Rasch",
            ",",
            "Abu Sebastian",
            ""
        ],
        "abstract": "Analog-Based In-Memory Computing (AIMC) inference accelerators can be used to\nefficiently execute Deep Neural Network (DNN) inference workloads. However, to\nmitigate accuracy losses, due to circuit and device non-idealities,\nHardware-Aware (HWA) training methodologies must be employed. These typically\nrequire significant information about the underlying hardware. In this paper,\nwe propose two Post-Training (PT) optimization methods to improve accuracy\nafter training is performed. For each crossbar, the first optimizes the\nconductance range of each column, and the second optimizes the input, i.e,\nDigital-to-Analog Converter (DAC), range. It is demonstrated that, when these\nmethods are employed, the complexity during training, and the amount of\ninformation about the underlying hardware can be reduced, with no notable\nchange in accuracy ($\\leq$0.1%) when finetuning the pretrained RoBERTa\ntransformer model for all General Language Understanding Evaluation (GLUE)\nbenchmark tasks. Additionally, it is demonstrated that further optimizing\nlearned parameters PT improves accuracy.",
        "date": "Not Found"
    },
    {
        "title": "Title:Succinctness of Cosafety Fragments of LTL via Combinatorial Proof  Systems (extended version)",
        "authors": [
            "",
            "Authors:",
            "",
            "Luca Geatti",
            ",",
            "Alessio Mansutti",
            ",",
            "Angelo Montanari",
            ""
        ],
        "abstract": "This paper focuses on succinctness results for fragments of Linear Temporal\nLogic with Past (LTL) devoid of binary temporal operators like until, and\nprovides methods to establish them. We prove that there is a family of cosafety\nlanguages (Ln)_{n>=1} such that Ln can be expressed with a pure future formula\nof size O(n), but it requires formulae of size 2^{\\Omega}(n) to be captured\nwith past formulae. As a by-product, such a succinctness result shows the\noptimality of the pastification algorithm proposed in [Artale et al., KR,\n2023]. We show that, in the considered case, succinctness cannot be proven by\nrelying on the classical automata-based method introduced in [Markey, Bull.\nEATCS, 2003]. In place of this method, we devise and apply a combinatorial\nproof system whose deduction trees represent LTL formulae. The system can be\nseen as a proof-centric (one-player) view on the games used by Adler and\nImmerman to study the succinctness of CTL.",
        "date": "Not Found"
    },
    {
        "title": "Title:Temporal Insight Enhancement: Mitigating Temporal Hallucination in  Multimodal Large Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Li Sun",
            ",",
            "Liuan Wang",
            ",",
            "Jun Sun",
            ",",
            "Takayuki Okatani",
            ""
        ],
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the comprehension of multimedia content, bringing\ntogether diverse modalities such as text, images, and videos. However, a\ncritical challenge faced by these models, especially when processing video\ninputs, is the occurrence of hallucinations - erroneous perceptions or\ninterpretations, particularly at the event level. This study introduces an\ninnovative method to address event-level hallucinations in MLLMs, focusing on\nspecific temporal understanding in video content. Our approach leverages a\nnovel framework that extracts and utilizes event-specific information from both\nthe event query and the provided video to refine MLLMs' response. We propose a\nunique mechanism that decomposes on-demand event queries into iconic actions.\nSubsequently, we employ models like CLIP and BLIP2 to predict specific\ntimestamps for event occurrences. Our evaluation, conducted using the\nCharades-STA dataset, demonstrates a significant reduction in temporal\nhallucinations and an improvement in the quality of event-related responses.\nThis research not only provides a new perspective in addressing a critical\nlimitation of MLLMs but also contributes a quantitatively measurable method for\nevaluating MLLMs in the context of temporal-related questions.",
        "date": "Not Found"
    },
    {
        "title": "Title:Evolutionary Multi-Objective Optimization of Large Language Model  Prompts for Balancing Sentiments",
        "authors": [
            "",
            "Authors:",
            "",
            "Jill Baumann",
            ",",
            "Oliver Kramer",
            ""
        ],
        "abstract": "The advent of large language models (LLMs) such as ChatGPT has attracted\nconsiderable attention in various domains due to their remarkable performance\nand versatility. As the use of these models continues to grow, the importance\nof effective prompt engineering has come to the fore. Prompt optimization\nemerges as a crucial challenge, as it has a direct impact on model performance\nand the extraction of relevant information. Recently, evolutionary algorithms\n(EAs) have shown promise in addressing this issue, paving the way for novel\noptimization strategies. In this work, we propose a evolutionary\nmulti-objective (EMO) approach specifically tailored for prompt optimization\ncalled EMO-Prompts, using sentiment analysis as a case study. We use sentiment\nanalysis capabilities as our experimental targets. Our results demonstrate that\nEMO-Prompts effectively generates prompts capable of guiding the LLM to produce\ntexts embodying two conflicting emotions simultaneously.",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving fine-grained understanding in image-text pre-training",
        "authors": [
            "",
            "Authors:",
            "",
            "Ioana Bica",
            ",",
            "Anastasija Ili\u0107",
            ",",
            "Matthias Bauer",
            ",",
            "Goker Erdogan",
            ",",
            "Matko Bo\u0161njak",
            ",",
            "Christos Kaplanis",
            ",",
            "Alexey A. Gritsenko",
            ",",
            "Matthias Minderer",
            ",",
            "Charles Blundell",
            ",",
            "Razvan Pascanu",
            ",",
            "Jovana Mitrovi\u0107",
            ""
        ],
        "abstract": "We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple\nmethod for pretraining more fine-grained multimodal representations from\nimage-text pairs. Given that multiple image patches often correspond to single\nwords, we propose to learn a grouping of image patches for every token in the\ncaption. To achieve this, we use a sparse similarity metric between image\npatches and language tokens and compute for each token a language-grouped\nvision embedding as the weighted average of patches. The token and\nlanguage-grouped vision embeddings are then contrasted through a fine-grained\nsequence-wise loss that only depends on individual samples and does not require\nother batch samples as negatives. This enables more detailed information to be\nlearned in a computationally inexpensive manner. SPARC combines this\nfine-grained loss with a contrastive loss between global image and text\nembeddings to learn representations that simultaneously encode global and local\ninformation. We thoroughly evaluate our proposed method and show improved\nperformance over competing approaches both on image-level tasks relying on\ncoarse-grained information, e.g. classification, as well as region-level tasks\nrelying on fine-grained information, e.g. retrieval, object detection, and\nsegmentation. Moreover, SPARC improves model faithfulness and captioning in\nfoundational vision-language models.",
        "date": "Not Found"
    },
    {
        "title": "Title:Boosting Few-Shot Segmentation via Instance-Aware Data Augmentation and  Local Consensus Guided Cross Attention",
        "authors": [
            "",
            "Authors:",
            "",
            "Li Guo",
            ",",
            "Haoming Liu",
            ",",
            "Yuxuan Xia",
            ",",
            "Chengyu Zhang",
            ",",
            "Xiaochen Lu",
            ""
        ],
        "abstract": "Few-shot segmentation aims to train a segmentation model that can fast adapt\nto a novel task for which only a few annotated images are provided. Most recent\nmodels have adopted a prototype-based paradigm for few-shot inference. These\napproaches may have limited generalization capacity beyond the standard 1- or\n5-shot settings. In this paper, we closely examine and reevaluate the\nfine-tuning based learning scheme that fine-tunes the classification layer of a\ndeep segmentation network pre-trained on diverse base classes. To improve the\ngeneralizability of the classification layer optimized with sparsely annotated\nsamples, we introduce an instance-aware data augmentation (IDA) strategy that\naugments the support images based on the relative sizes of the target objects.\nThe proposed IDA effectively increases the support set's diversity and promotes\nthe distribution consistency between support and query images. On the other\nhand, the large visual difference between query and support images may hinder\nknowledge transfer and cripple the segmentation performance. To cope with this\nchallenge, we introduce the local consensus guided cross attention (LCCA) to\nalign the query feature with support features based on their dense correlation,\nfurther improving the model's generalizability to the query image. The\nsignificant performance improvements on the standard few-shot segmentation\nbenchmarks PASCAL-$5^i$ and COCO-$20^i$ verify the efficacy of our proposed\nmethod.",
        "date": "Not Found"
    },
    {
        "title": "Title:Reconciling Spatial and Temporal Abstractions for Goal Representation",
        "authors": [
            "",
            "Authors:",
            "",
            "Mehdi Zadem",
            ",",
            "Sergio Mover",
            ",",
            "Sao Mai Nguyen",
            ""
        ],
        "abstract": "Goal representation affects the performance of Hierarchical Reinforcement\nLearning (HRL) algorithms by decomposing the complex learning problem into\neasier subtasks. Recent studies show that representations that preserve\ntemporally abstract environment dynamics are successful in solving difficult\nproblems and provide theoretical guarantees for optimality. These methods\nhowever cannot scale to tasks where environment dynamics increase in complexity\ni.e. the temporally abstract transition relations depend on larger number of\nvariables. On the other hand, other efforts have tried to use spatial\nabstraction to mitigate the previous issues. Their limitations include\nscalability to high dimensional environments and dependency on prior knowledge.\nIn this paper, we propose a novel three-layer HRL algorithm that introduces,\nat different levels of the hierarchy, both a spatial and a temporal goal\nabstraction. We provide a theoretical study of the regret bounds of the learned\npolicies. We evaluate the approach on complex continuous control tasks,\ndemonstrating the effectiveness of spatial and temporal abstractions learned by\nthis approach.",
        "date": "Not Found"
    },
    {
        "title": "Title:Accurate and Scalable Many-Node Simulation",
        "authors": [
            "",
            "Authors:",
            "",
            "Stijn Eyerman",
            ",",
            "Wim Heirman",
            ",",
            "Kristof Du Bois",
            ",",
            "Ibrahim Hur",
            ""
        ],
        "abstract": "Accurate performance estimation of future many-node machines is challenging\nbecause it requires detailed simulation models of both node and network.\nHowever, simulating the full system in detail is unfeasible in terms of compute\nand memory resources. State-of-the-art techniques use a two-phase approach that\ncombines detailed simulation of a single node with network-only simulation of\nthe full system. We show that these techniques, where the detailed node\nsimulation is done in isolation, are inaccurate because they ignore two\nimportant node-level effects: compute time variability, and inter-node\ncommunication.\nWe propose a novel three-stage simulation method to allow scalable and\naccurate many-node simulation, combining native profiling, detailed node\nsimulation and high-level network simulation. By including timing variability\nand the impact of external nodes, our method leads to more accurate estimates.\nWe validate our technique against measurements on a multi-node cluster, and\nreport an average 6.7% error on 64 nodes (maximum error of 12%), compared to on\naverage 27% error and up to 54% when timing variability and the scaling\noverhead are ignored. At higher node counts, the prediction error of ignoring\nvariable timings and scaling overhead continues to increase compared to our\ntechnique, and may lead to selecting the wrong optimal cluster configuration.\nUsing our technique, we are able to accurately project performance to\nthousands of nodes within a day of simulation time, using only a single or a\nfew simulation hosts. Our method can be used to quickly explore large many-node\ndesign spaces, including node micro-architecture, node count and network\nconfiguration.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Comparison Benchmark for Distributed Hybrid MPC Control Methods:  Distributed Vehicle Platooning",
        "authors": [
            "",
            "Authors:",
            "",
            "Samuel Mallick",
            ",",
            "Azita Dabiri",
            ",",
            "Bart De Schutter",
            ""
        ],
        "abstract": "Distributed model predictive control (MPC) is currently being investigated as\na solution to the important control challenge presented by networks of hybrid\ndynamical systems. However, a benchmark problem for distributed hybrid MPC is\nabsent from the literature. We propose distributed control of a platoon of\nautonomous vehicles as a comparison benchmark problem. The problem provides a\ncomplex and adaptable case study, upon which existing and future approaches to\ndistributed MPC for hybrid systems can be evaluated. Two hybrid modeling\nframeworks are presented for the vehicle dynamics. Five hybrid MPC controllers\nare then evaluated and extensively assessed on the fleet of vehicles. Finally,\nwe comment on the need for new efficient and high performing distributed MPC\nschemes for hybrid systems.",
        "date": "Not Found"
    },
    {
        "title": "Title:Attention-Based Recurrent Neural Network For Automatic Behavior Laying  Hen Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Fr\u00e9jus A. A. Laleye",
            ",",
            "Mika\u00ebl A. Mousse",
            ""
        ],
        "abstract": "One of the interests of modern poultry farming is the vocalization of laying\nhens which contain very useful information on health behavior. This information\nis used as health and well-being indicators that help breeders better monitor\nlaying hens, which involves early detection of problems for rapid and more\neffective intervention. In this work, we focus on the sound analysis for the\nrecognition of the types of calls of the laying hens in order to propose a\nrobust system of characterization of their behavior for a better monitoring. To\ndo this, we first collected and annotated laying hen call signals, then\ndesigned an optimal acoustic characterization based on the combination of time\nand frequency domain features. We then used these features to build the\nmulti-label classification models based on recurrent neural network to assign a\nsemantic class to the vocalization that characterize the laying hen behavior.\nThe results show an overall performance with our model based on the combination\nof time and frequency domain features that obtained the highest F1-score\n(F1=92.75) with a gain of 17% on the models using the frequency domain features\nand of 8% on the compared approaches from the litterature.",
        "date": "Not Found"
    },
    {
        "title": "Title:GA-SmaAt-GNet: Generative Adversarial Small Attention GNet for Extreme  Precipitation Nowcasting",
        "authors": [
            "",
            "Authors:",
            "",
            "Eloy Reulen",
            ",",
            "Siamak Mehrkanoon",
            ""
        ],
        "abstract": "In recent years, data-driven modeling approaches have gained considerable\ntraction in various meteorological applications, particularly in the realm of\nweather forecasting. However, these approaches often encounter challenges when\ndealing with extreme weather conditions. In light of this, we propose\nGA-SmaAt-GNet, a novel generative adversarial architecture that makes use of\ntwo methodologies aimed at enhancing the performance of deep learning models\nfor extreme precipitation nowcasting. Firstly, it uses a novel SmaAt-GNet built\nupon the successful SmaAt-UNet architecture as generator. This network\nincorporates precipitation masks (binarized precipitation maps) as an\nadditional data source, leveraging valuable information for improved\npredictions. Additionally, GA-SmaAt-GNet utilizes an attention-augmented\ndiscriminator inspired by the well-established Pix2Pix architecture.\nFurthermore, we assess the performance of GA-SmaAt-GNet using real-life\nprecipitation dataset from the Netherlands. Our experimental results reveal a\nnotable improvement in both overall performance and for extreme precipitation\nevents. Furthermore, we conduct uncertainty analysis on the proposed\nGA-SmaAt-GNet model as well as on the precipitation dataset, providing\nadditional insights into the predictive capabilities of the model. Finally, we\noffer further insights into the predictions of our proposed model using\nGrad-CAM. This visual explanation technique generates activation heatmaps,\nillustrating areas of the input that are more activated for various parts of\nthe network.",
        "date": "Not Found"
    },
    {
        "title": "Title:Question-Answer Cross Language Image Matching for Weakly Supervised  Semantic Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Songhe Deng",
            ",",
            "Wei Zhuo",
            ",",
            "Jinheng Xie",
            ",",
            "Linlin Shen",
            ""
        ],
        "abstract": "Class Activation Map (CAM) has emerged as a popular tool for weakly\nsupervised semantic segmentation (WSSS), allowing the localization of object\nregions in an image using only image-level labels. However, existing CAM\nmethods suffer from under-activation of target object regions and\nfalse-activation of background regions due to the fact that a lack of detailed\nsupervision can hinder the model's ability to understand the image as a whole.\nIn this paper, we propose a novel Question-Answer Cross-Language-Image Matching\nframework for WSSS (QA-CLIMS), leveraging the vision-language foundation model\nto maximize the text-based understanding of images and guide the generation of\nactivation maps. First, a series of carefully designed questions are posed to\nthe VQA (Visual Question Answering) model with Question-Answer Prompt\nEngineering (QAPE) to generate a corpus of both foreground target objects and\nbackgrounds that are adaptive to query images. We then employ contrastive\nlearning in a Region Image Text Contrastive (RITC) network to compare the\nobtained foreground and background regions with the generated corpus. Our\napproach exploits the rich textual information from the open vocabulary as\nadditional supervision, enabling the model to generate high-quality CAMs with a\nmore complete object region and reduce false-activation of background regions.\nWe conduct extensive analysis to validate the proposed method and show that our\napproach performs state-of-the-art on both PASCAL VOC 2012 and MS COCO\ndatasets. Code is available at: https://github.com/CVI-SZU/QA-CLIMS",
        "date": "Not Found"
    },
    {
        "title": "Title:Source Code Clone Detection Using Unsupervised Similarity Measures",
        "authors": [
            "",
            "Authors:",
            "",
            "Jorge Martinez-Gil",
            ""
        ],
        "abstract": "Assessing similarity in source code has gained significant attention in\nrecent years due to its importance in software engineering tasks such as clone\ndetection and code search and recommendation. This work presents a comparative\nanalysis of unsupervised similarity measures for identifying source code clone\ndetection. The goal is to overview the current state-of-the-art techniques,\ntheir strengths, and weaknesses. To do that, we compile the existing\nunsupervised strategies and evaluate their performance on a benchmark dataset\nto guide software engineers in selecting appropriate methods for their specific\nuse cases. The source code of this study is available at\n\\url{https://github.com/jorge-martinez-gil/codesim}",
        "date": "Not Found"
    },
    {
        "title": "Title:Cooperative Edge Caching Based on Elastic Federated and Multi-Agent Deep  Reinforcement Learning in Next-Generation Network",
        "authors": [
            "",
            "Authors:",
            "",
            "Qiong Wu",
            ",",
            "Wenhua Wang",
            ",",
            "Pingyi Fan",
            ",",
            "Qiang Fan",
            ",",
            "Huiling Zhu",
            ",",
            "Khaled B. Letaief",
            ""
        ],
        "abstract": "Edge caching is a promising solution for next-generation networks by\nempowering caching units in small-cell base stations (SBSs), which allows user\nequipments (UEs) to fetch users' requested contents that have been pre-cached\nin SBSs. It is crucial for SBSs to predict accurate popular contents through\nlearning while protecting users' personal information. Traditional federated\nlearning (FL) can protect users' privacy but the data discrepancies among UEs\ncan lead to a degradation in model quality. Therefore, it is necessary to train\npersonalized local models for each UE to predict popular contents accurately.\nIn addition, the cached contents can be shared among adjacent SBSs in\nnext-generation networks, thus caching predicted popular contents in different\nSBSs may affect the cost to fetch contents. Hence, it is critical to determine\nwhere the popular contents are cached cooperatively. To address these issues,\nwe propose a cooperative edge caching scheme based on elastic federated and\nmulti-agent deep reinforcement learning (CEFMR) to optimize the cost in the\nnetwork. We first propose an elastic FL algorithm to train the personalized\nmodel for each UE, where adversarial autoencoder (AAE) model is adopted for\ntraining to improve the prediction accuracy, then {a popular} content\nprediction algorithm is proposed to predict the popular contents for each SBS\nbased on the trained AAE model. Finally, we propose a multi-agent deep\nreinforcement learning (MADRL) based algorithm to decide where the predicted\npopular contents are collaboratively cached among SBSs. Our experimental\nresults demonstrate the superiority of our proposed scheme to existing baseline\ncaching schemes.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Survey on Hardware Accelerators for Large Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Christoforos Kachris",
            ""
        ],
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural\nlanguage processing tasks, revolutionizing the field with their ability to\nunderstand and generate human-like text. As the demand for more sophisticated\nLLMs continues to grow, there is a pressing need to address the computational\nchallenges associated with their scale and complexity. This paper presents a\ncomprehensive survey on hardware accelerators designed to enhance the\nperformance and energy efficiency of Large Language Models. By examining a\ndiverse range of accelerators, including GPUs, FPGAs, and custom-designed\narchitectures, we explore the landscape of hardware solutions tailored to meet\nthe unique computational demands of LLMs. The survey encompasses an in-depth\nanalysis of architecture, performance metrics, and energy efficiency\nconsiderations, providing valuable insights for researchers, engineers, and\ndecision-makers aiming to optimize the deployment of LLMs in real-world\napplications.",
        "date": "Not Found"
    },
    {
        "title": "Title:Skeleton-Guided Instance Separation for Fine-Grained Segmentation in  Microscopy",
        "authors": [
            "",
            "Authors:",
            "",
            "Jun Wang",
            ",",
            "Chengfeng Zhou",
            ",",
            "Zhaoyan Ming",
            ",",
            "Lina Wei",
            ",",
            "Xudong Jiang",
            ",",
            "Dahong Qian",
            ""
        ],
        "abstract": "One of the fundamental challenges in microscopy (MS) image analysis is\ninstance segmentation (IS), particularly when segmenting cluster regions where\nmultiple objects of varying sizes and shapes may be connected or even\noverlapped in arbitrary orientations. Existing IS methods usually fail in\nhandling such scenarios, as they rely on coarse instance representations such\nas keypoints and horizontal bounding boxes (h-bboxes). In this paper, we\npropose a novel one-stage framework named A2B-IS to address this challenge and\nenhance the accuracy of IS in MS images. Our approach represents each instance\nwith a pixel-level mask map and a rotated bounding box (r-bbox). Unlike\ntwo-stage methods that use box proposals for segmentations, our method\ndecouples mask and box predictions, enabling simultaneous processing to\nstreamline the model pipeline. Additionally, we introduce a Gaussian skeleton\nmap to aid the IS task in two key ways: (1) It guides anchor placement,\nreducing computational costs while improving the model's capacity to learn\nRoI-aware features by filtering out noise from background regions. (2) It\nensures accurate isolation of densely packed instances by rectifying erroneous\nbox predictions near instance boundaries. To further enhance the performance,\nwe integrate two modules into the framework: (1) An Atrous Attention Block\n(A2B) designed to extract high-resolution feature maps with fine-grained\nmultiscale information, and (2) A Semi-Supervised Learning (SSL) strategy that\nleverages both labeled and unlabeled images for model training. Our method has\nbeen thoroughly validated on two large-scale MS datasets, demonstrating its\nsuperiority over most state-of-the-art approaches.",
        "date": "Not Found"
    },
    {
        "title": "Title:Experimental Shake Gesture Detection API for Apple Watch",
        "authors": [
            "",
            "Authors:",
            "",
            "Ezequiel Fran\u00e7a dos Santos",
            ""
        ],
        "abstract": "In this paper we present the WatchShaker project The project involves an\nexperimental API that detects the Apple Watchs shake gesturea surprisingly\nabsent natively feature Through a simple heuristic leveraging the Apple Watchs\naccelerometer data the API discerns not just the occurrence of shake gestures\nbut also their direction enhancing the interactivity potential of the device\nDespite the projects simplicity and lack of formal testing it has garnered\nsignificant attention indicating a genuine interest and need within the\ndeveloper community for such functionality The WatchShaker project exemplifies\nhow a minimalistic approach can yield a practical and impactful tool in\nwearable technology providing a springboard for further research and\ndevelopment in intuitive gesture recognition",
        "date": "Not Found"
    },
    {
        "title": "Title:Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes  Through Multimodal Explanations",
        "authors": [
            "",
            "Authors:",
            "",
            "Prince Jha",
            ",",
            "Krishanu Maity",
            ",",
            "Raghav Jain",
            ",",
            "Apoorv Verma",
            ",",
            "Sriparna Saha",
            ",",
            "Pushpak Bhattacharyya",
            ""
        ],
        "abstract": "Internet memes have gained significant influence in communicating political,\npsychological, and sociocultural ideas. While memes are often humorous, there\nhas been a rise in the use of memes for trolling and cyberbullying. Although a\nwide variety of effective deep learning-based models have been developed for\ndetecting offensive multimodal memes, only a few works have been done on\nexplainability aspect. Recent laws like \"right to explanations\" of General Data\nProtection Regulation, have spurred research in developing interpretable models\nrather than only focusing on performance. Motivated by this, we introduce {\\em\nMultiBully-Ex}, the first benchmark dataset for multimodal explanation from\ncode-mixed cyberbullying memes. Here, both visual and textual modalities are\nhighlighted to explain why a given meme is cyberbullying. A Contrastive\nLanguage-Image Pretraining (CLIP) projection-based multimodal shared-private\nmultitask approach has been proposed for visual and textual explanation of a\nmeme. Experimental results demonstrate that training with multimodal\nexplanations improves performance in generating textual justifications and more\naccurately identifying the visual evidence supporting a decision with reliable\nperformance improvements.",
        "date": "Not Found"
    },
    {
        "title": "Title:XAI-Enhanced Semantic Segmentation Models for Visual Quality Inspection",
        "authors": [
            "",
            "Authors:",
            "",
            "Tobias Clement",
            ",",
            "Truong Thanh Hung Nguyen",
            ",",
            "Mohamed Abdelaal",
            ",",
            "Hung Cao",
            ""
        ],
        "abstract": "Visual quality inspection systems, crucial in sectors like manufacturing and\nlogistics, employ computer vision and machine learning for precise, rapid\ndefect detection. However, their unexplained nature can hinder trust, error\nidentification, and system improvement. This paper presents a framework to\nbolster visual quality inspection by using CAM-based explanations to refine\nsemantic segmentation models. Our approach consists of 1) Model Training, 2)\nXAI-based Model Explanation, 3) XAI Evaluation, and 4) Annotation Augmentation\nfor Model Enhancement, informed by explanations and expert insights.\nEvaluations show XAI-enhanced models surpass original DeepLabv3-ResNet101\nmodels, especially in intricate object segmentation.",
        "date": "Not Found"
    },
    {
        "title": "Title:BUMP: A Benchmark of Reproducible Breaking Dependency Updates",
        "authors": [
            "",
            "Authors:",
            "",
            "Frank Reyes",
            ",",
            "Yogya Gamage",
            ",",
            "Gabriel Skoglund",
            ",",
            "Benoit Baudry",
            ",",
            "Martin Monperrus",
            ""
        ],
        "abstract": "Third-party dependency updates can cause a build to fail if the new\ndependency version introduces a change that is incompatible with the usage:\nthis is called a breaking dependency update. Research on breaking dependency\nupdates is active, with works on characterization, understanding, automatic\nrepair of breaking updates, and other software engineering aspects. All such\nresearch projects require a benchmark of breaking updates that has the\nfollowing properties: 1) it contains real-world breaking updates; 2) the\nbreaking updates can be executed; 3) the benchmark provides stable scientific\nartifacts of breaking updates over time, a property we call reproducibility. To\nthe best of our knowledge, such a benchmark is missing. To address this\nproblem, we present BUMP, a new benchmark that contains reproducible breaking\ndependency updates in the context of Java projects built with the Maven build\nsystem. BUMP contains 571 breaking dependency updates collected from 153 Java\nprojects. BUMP ensures long-term reproducibility of dependency updates on\ndifferent platforms, guaranteeing consistent build failures. We categorize the\ndifferent causes of build breakage in BUMP, providing novel insights for future\nwork on breaking update engineering. To our knowledge, BUMP is the first of its\nkind, providing hundreds of real-world breaking updates that have all been made\nreproducible.",
        "date": "Not Found"
    },
    {
        "title": "Title:Deep Back-Filling: a Split Window Technique for Deep Online Cluster Job  Scheduling",
        "authors": [
            "",
            "Authors:",
            "",
            "Lingfei Wang",
            ",",
            "Aaron Harwood",
            ",",
            "Maria A. Rodriguez",
            ""
        ],
        "abstract": "Job scheduling is a critical component of workload management systems that\ncan significantly influence system performance, e.g., in HPC clusters. The\nscheduling objectives are often mixed, such as maximizing resource utilization\nand minimizing job waiting time. An increasing number of researchers are moving\nfrom heuristic-based approaches to Deep Reinforcement Learning approaches in\norder to optimize scheduling objectives. However, the job scheduler's state\nspace is partially observable to a DRL-based agent because the job queue is\npractically unbounded. The agent's observation of the state space is constant\nin size since the input size of the neural networks is predefined. All existing\nsolutions to this problem intuitively allow the agent to observe a fixed window\nsize of jobs at the head of the job queue. In our research, we have seen that\nsuch an approach can lead to \"window staleness\" where the window becomes full\nof jobs that can not be scheduled until the cluster has completed sufficient\nwork. In this paper, we propose a novel general technique that we call\n\\emph{split window}, which allows the agent to observe both the head \\emph{and\ntail} of the queue. With this technique, the agent can observe all arriving\njobs at least once, which completely eliminates the window staleness problem.\nBy leveraging the split window, the agent can significantly reduce the average\njob waiting time and average queue length, alternatively allowing the use of\nmuch smaller windows and, therefore, faster training times. We show a range of\nsimulation results using HPC job scheduling trace data that supports the\neffectiveness of our technique.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enabling On-device Continual Learning with Binary Neural Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Lorenzo Vorabbi",
            ",",
            "Davide Maltoni",
            ",",
            "Guido Borghi",
            ",",
            "Stefano Santi",
            ""
        ],
        "abstract": "On-device learning remains a formidable challenge, especially when dealing\nwith resource-constrained devices that have limited computational capabilities.\nThis challenge is primarily rooted in two key issues: first, the memory\navailable on embedded devices is typically insufficient to accommodate the\nmemory-intensive back-propagation algorithm, which often relies on\nfloating-point precision. Second, the development of learning algorithms on\nmodels with extreme quantization levels, such as Binary Neural Networks (BNNs),\nis critical due to the drastic reduction in bit representation. In this study,\nwe propose a solution that combines recent advancements in the field of\nContinual Learning (CL) and Binary Neural Networks to enable on-device training\nwhile maintaining competitive performance. Specifically, our approach leverages\nbinary latent replay (LR) activations and a novel quantization scheme that\nsignificantly reduces the number of bits required for gradient computation. The\nexperimental validation demonstrates a significant accuracy improvement in\ncombination with a noticeable reduction in memory requirement, confirming the\nsuitability of our approach in expanding the practical applications of deep\nlearning in real-world scenarios.",
        "date": "Not Found"
    },
    {
        "title": "Title:Probabilistic Truly Unordered Rule Sets",
        "authors": [
            "",
            "Authors:",
            "",
            "Lincen Yang",
            ",",
            "Matthijs van Leeuwen",
            ""
        ],
        "abstract": "Rule set learning has recently been frequently revisited because of its\ninterpretability. Existing methods have several shortcomings though. First,\nmost existing methods impose orders among rules, either explicitly or\nimplicitly, which makes the models less comprehensible. Second, due to the\ndifficulty of handling conflicts caused by overlaps (i.e., instances covered by\nmultiple rules), existing methods often do not consider probabilistic rules.\nThird, learning classification rules for multi-class target is understudied, as\nmost existing methods focus on binary classification or multi-class\nclassification via the ``one-versus-rest\" approach.\nTo address these shortcomings, we propose TURS, for Truly Unordered Rule\nSets. To resolve conflicts caused by overlapping rules, we propose a novel\nmodel that exploits the probabilistic properties of our rule sets, with the\nintuition of only allowing rules to overlap if they have similar probabilistic\noutputs. We next formalize the problem of learning a TURS model based on the\nMDL principle and develop a carefully designed heuristic algorithm. We\nbenchmark against a wide range of rule-based methods and demonstrate that our\nmethod learns rule sets that have lower model complexity and highly competitive\npredictive performance. In addition, we empirically show that rules in our\nmodel are empirically ``independent\" and hence truly unordered.",
        "date": "Not Found"
    },
    {
        "title": "Title:Tractability of linear ill-posed problems in Hilbert space",
        "authors": [
            "",
            "Authors:",
            "",
            "Peter Math\u00e9",
            ",",
            "Bernd Hofmann",
            ""
        ],
        "abstract": "We introduce a notion of tractability for ill-posed operator equations in\nHilbert space. For such operator equations the\nasymptotics of the best possible rate of reconstruction in terms of the\nunderlying noise level is known in many cases. However, the relevant question\nis, which level of discretization, again driven by the noise level, is required\nin order to\nachieve this best possible accuracy. The proposed concept adapts the one from\nInformation-based Complexity.\nSeveral examples indicate the relevance of this concept in the light of the\ncurse of dimensionality.",
        "date": "Not Found"
    },
    {
        "title": "Title:BlenDA: Domain Adaptive Object Detection through diffusion-based  blending",
        "authors": [
            "",
            "Authors:",
            "",
            "Tzuhsuan Huang",
            ",",
            "Chen-Che Huang",
            ",",
            "Chung-Hao Ku",
            ",",
            "Jun-Cheng Chen",
            ""
        ],
        "abstract": "Unsupervised domain adaptation (UDA) aims to transfer a model learned using\nlabeled data from the source domain to unlabeled data in the target domain. To\naddress the large domain gap issue between the source and target domains, we\npropose a novel regularization method for domain adaptive object detection,\nBlenDA, by generating the pseudo samples of the intermediate domains and their\ncorresponding soft domain labels for adaptation training. The intermediate\nsamples are generated by dynamically blending the source images with their\ncorresponding translated images using an off-the-shelf pre-trained\ntext-to-image diffusion model which takes the text label of the target domain\nas input and has demonstrated superior image-to-image translation quality.\nBased on experimental results from two adaptation benchmarks, our proposed\napproach can significantly enhance the performance of the state-of-the-art\ndomain adaptive object detector, Adversarial Query Transformer (AQT).\nParticularly, in the Cityscapes to Foggy Cityscapes adaptation, we achieve an\nimpressive 53.4% mAP on the Foggy Cityscapes dataset, surpassing the previous\nstate-of-the-art by 1.5%. It is worth noting that our proposed method is also\napplicable to various paradigms of domain adaptive object detection. The code\nis available at:https://github.com/aiiu-lab/BlenDA",
        "date": "Not Found"
    },
    {
        "title": "Title:MAMBA: Multi-level Aggregation via Memory Bank for Video Object  Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Guanxiong Sun",
            ",",
            "Yang Hua",
            ",",
            "Guosheng Hu",
            ",",
            "Neil Robertson",
            ""
        ],
        "abstract": "State-of-the-art video object detection methods maintain a memory structure,\neither a sliding window or a memory queue, to enhance the current frame using\nattention mechanisms. However, we argue that these memory structures are not\nefficient or sufficient because of two implied operations: (1) concatenating\nall features in memory for enhancement, leading to a heavy computational cost;\n(2) frame-wise memory updating, preventing the memory from capturing more\ntemporal information. In this paper, we propose a multi-level aggregation\narchitecture via memory bank called MAMBA. Specifically, our memory bank\nemploys two novel operations to eliminate the disadvantages of existing\nmethods: (1) light-weight key-set construction which can significantly reduce\nthe computational cost; (2) fine-grained feature-wise updating strategy which\nenables our method to utilize knowledge from the whole video. To better enhance\nfeatures from complementary levels, i.e., feature maps and proposals, we\nfurther propose a generalized enhancement operation (GEO) to aggregate\nmulti-level features in a unified manner. We conduct extensive evaluations on\nthe challenging ImageNetVID dataset. Compared with existing state-of-the-art\nmethods, our method achieves superior performance in terms of both speed and\naccuracy. More remarkably, MAMBA achieves mAP of 83.7/84.6% at 12.6/9.1 FPS\nwith ResNet-101. Code is available at\nhttps://github.com/guanxiongsun/video_feature_enhancement.",
        "date": "Not Found"
    },
    {
        "title": "Title:Discretization of fractional fully nonlinear equations by powers of  discrete Laplacians",
        "authors": [
            "",
            "Authors:",
            "",
            "Indranil Chowdhury",
            ",",
            "Espen Robstad Jakobsen",
            ",",
            "Robin \u00d8stern Lien",
            ""
        ],
        "abstract": "We study discretizations of fractional fully nonlinear equations by powers of\ndiscrete Laplacians. Our problems are parabolic and of order $\\sigma\\in(0,2)$\nsince they involve fractional Laplace operators $(-\\Delta)^{\\sigma/2}$. They\narise e.g.~in control and game theory as dynamic programming equations, and\nsolutions are non-smooth in general and should be interpreted as viscosity\nsolutions. Our approximations are realized as finite-difference quadrature\napproximations and are 2nd order accurate for all values of $\\sigma$. The\naccuracy of previous approximations depend on $\\sigma$ and are worse when\n$\\sigma$ is close to $2$. We show that the schemes are monotone, consistent,\n$L^\\infty$-stable, and convergent using a priori estimates, viscosity solutions\ntheory, and the method of half-relaxed limits. We present several numerical\nexamples.",
        "date": "Not Found"
    },
    {
        "title": "Title:From Cash to Cashless: UPI's Impact on Spending Behavior among Indian  Users",
        "authors": [
            "",
            "Authors:",
            "",
            "Harshal Dev",
            ",",
            "Raj Gupta",
            ",",
            "Dhruv Kumar",
            ""
        ],
        "abstract": "The emergence of digital payment systems has transformed how individuals\nconduct financial transactions, offering convenience, security, and efficiency.\nOne groundbreaking innovation making waves in the Indian financial landscape is\nthe Unified Payments Interface (UPI), developed by the National Payments\nCorporation of India (NPCI). Existing work has explored how digital payments\nbenefit a country's economy and GDP. However, our study explores how the\nintroduction of UPI has influenced spending behavior among Indian users on an\n\"individual\" level. We gathered 235 valid survey responses encompassing diverse\ndemographics and conducted semi-structured interviews with 20 survey\nrespondents. Approximately 75% of the survey respondents reported increased\nspending due to UPI, with only 7% indicating reduced spending. Significantly,\n91.5% of the respondents reported satisfaction with their UPI usage. Also 95.2%\nof the survey respondents found making payments via UPI convenient. Our\nresearch also provides suggestions for UPI applications and various\nstakeholders to enhance digital payment systems, enabling users to make\ninformed decisions and fostering responsible financial management.",
        "date": "Not Found"
    },
    {
        "title": "Title:ICGNet: A Unified Approach for Instance-Centric Grasping",
        "authors": [
            "",
            "Authors:",
            "",
            "Ren\u00e9 Zurbr\u00fcgg",
            ",",
            "Yifan Liu",
            ",",
            "Francis Engelmann",
            ",",
            "Suryansh Kumar",
            ",",
            "Marco Hutter",
            ",",
            "Vaishakh Patil",
            ",",
            "Fisher Yu",
            ""
        ],
        "abstract": "Accurate grasping is the key to several robotic tasks including assembly and\nhousehold robotics. Executing a successful grasp in a cluttered environment\nrequires multiple levels of scene understanding: First, the robot needs to\nanalyze the geometric properties of individual objects to find feasible grasps.\nThese grasps need to be compliant with the local object geometry. Second, for\neach proposed grasp, the robot needs to reason about the interactions with\nother objects in the scene. Finally, the robot must compute a collision-free\ngrasp trajectory while taking into account the geometry of the target object.\nMost grasp detection algorithms directly predict grasp poses in a monolithic\nfashion, which does not capture the composability of the environment. In this\npaper, we introduce an end-to-end architecture for object-centric grasping. The\nmethod uses pointcloud data from a single arbitrary viewing direction as an\ninput and generates an instance-centric representation for each partially\nobserved object in the scene. This representation is further used for object\nreconstruction and grasp detection in cluttered table-top scenes. We show the\neffectiveness of the proposed method by extensively evaluating it against\nstate-of-the-art methods on synthetic datasets, indicating superior performance\nfor grasping and reconstruction. Additionally, we demonstrate real-world\napplicability by decluttering scenes with varying numbers of objects.",
        "date": "Not Found"
    },
    {
        "title": "Title:Biases in Expected Goals Models Confound Finishing Ability",
        "authors": [
            "",
            "Authors:",
            "",
            "Jesse Davis",
            ",",
            "Pieter Robberechts",
            ""
        ],
        "abstract": "Expected Goals (xG) has emerged as a popular tool for evaluating finishing\nskill in soccer analytics. It involves comparing a player's cumulative xG with\ntheir actual goal output, where consistent overperformance indicates strong\nfinishing ability. However, the assessment of finishing skill in soccer using\nxG remains contentious due to players' difficulty in consistently outperforming\ntheir cumulative xG. In this paper, we aim to address the limitations and\nnuances surrounding the evaluation of finishing skill using xG statistics.\nSpecifically, we explore three hypotheses: (1) the deviation between actual and\nexpected goals is an inadequate metric due to the high variance of shot\noutcomes and limited sample sizes, (2) the inclusion of all shots in cumulative\nxG calculation may be inappropriate, and (3) xG models contain biases arising\nfrom interdependencies in the data that affect skill measurement. We found that\nsustained overperformance of cumulative xG requires both high shot volumes and\nexceptional finishing, including all shot types can obscure the finishing\nability of proficient strikers, and that there is a persistent bias that makes\nthe actual and expected goals closer for excellent finishers than it really is.\nOverall, our analysis indicates that we need more nuanced quantitative\napproaches for investigating a player's finishing ability, which we achieved\nusing a technique from AI fairness to learn an xG model that is calibrated for\nmultiple subgroups of players. As a concrete use case, we show that (1) the\nstandard biased xG model underestimates Messi's GAX by 17% and (2) Messi's GAX\nis 27% higher than the typical elite high-shot-volume attacker, indicating that\nMessi is even a more exceptional finisher than people commonly believed.",
        "date": "Not Found"
    },
    {
        "title": "Title:Multi-task Learning for Joint Re-identification, Team Affiliation, and  Role Classification for Sports Visual Tracking",
        "authors": [
            "",
            "Authors:",
            "",
            "Amir M. Mansourian",
            ",",
            "Vladimir Somers",
            ",",
            "Christophe De Vleeschouwer",
            ",",
            "Shohreh Kasaei",
            ""
        ],
        "abstract": "Effective tracking and re-identification of players is essential for\nanalyzing soccer videos. But, it is a challenging task due to the non-linear\nmotion of players, the similarity in appearance of players from the same team,\nand frequent occlusions. Therefore, the ability to extract meaningful\nembeddings to represent players is crucial in developing an effective tracking\nand re-identification system. In this paper, a multi-purpose part-based person\nrepresentation method, called PRTreID, is proposed that performs three tasks of\nrole classification, team affiliation, and re-identification, simultaneously.\nIn contrast to available literature, a single network is trained with\nmulti-task supervision to solve all three tasks, jointly. The proposed joint\nmethod is computationally efficient due to the shared backbone. Also, the\nmulti-task learning leads to richer and more discriminative representations, as\ndemonstrated by both quantitative and qualitative results. To demonstrate the\neffectiveness of PRTreID, it is integrated with a state-of-the-art tracking\nmethod, using a part-based post-processing module to handle long-term tracking.\nThe proposed tracking method outperforms all existing tracking methods on the\nchallenging SoccerNet tracking dataset.",
        "date": "Not Found"
    },
    {
        "title": "Title:Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance  Sparse Information Aggregation",
        "authors": [
            "",
            "Authors:",
            "",
            "Ruizhe Zhang",
            ",",
            "Xinke Jiang",
            ",",
            "Yuchen Fang",
            ",",
            "Jiayuan Luo",
            ",",
            "Yongxin Xu",
            ",",
            "Yichen Zhu",
            ",",
            "Xu Chu",
            ",",
            "Junfeng Zhao",
            ",",
            "Yasha Zhao",
            ""
        ],
        "abstract": "Graph Neural Networks (GNNs) have shown considerable effectiveness in a\nvariety of graph learning tasks, particularly those based on the\nmessage-passing approach in recent years. However, their performance is often\nconstrained by a limited receptive field, a challenge that becomes more acute\nin the presence of sparse graphs. In light of the power series, which possesses\ninfinite expansion capabilities, we propose a novel \\underline{G}raph\n\\underline{P}ower \\underline{F}ilter \\underline{N}eural Network (GPFN) that\nenhances node classification by employing a power series graph filter to\naugment the receptive field. Concretely, our GPFN designs a new way to build a\ngraph filter with an infinite receptive field based on the convergence power\nseries, which can be analyzed in the spectral and spatial domains. Besides, we\ntheoretically prove that our GPFN is a general framework that can integrate any\npower series and capture long-range dependencies. Finally, experimental results\non three datasets demonstrate the superiority of our GPFN over state-of-the-art\nbaselines.",
        "date": "Not Found"
    },
    {
        "title": "Title:WindSeer: Real-time volumetric wind prediction over complex terrain  aboard a small UAV",
        "authors": [
            "",
            "Authors:",
            "",
            "Florian Achermann",
            ",",
            "Thomas Stastny",
            ",",
            "Bogdan Danciu",
            ",",
            "Andrey Kolobov",
            ",",
            "Jen Jen Chung",
            ",",
            "Roland Siegwart",
            ",",
            "Nicholas Lawrance",
            ""
        ],
        "abstract": "Real-time high-resolution wind predictions are beneficial for various\napplications including safe manned and unmanned aviation. Current weather\nmodels require too much compute and lack the necessary predictive capabilities\nas they are valid only at the scale of multiple kilometers and hours - much\nlower spatial and temporal resolutions than these applications require. Our\nwork, for the first time, demonstrates the ability to predict low-altitude wind\nin real-time on limited-compute devices, from only sparse measurement data. We\ntrain a neural network, WindSeer, using only synthetic data from computational\nfluid dynamics simulations and show that it can successfully predict real wind\nfields over terrain with known topography from just a few noisy and spatially\nclustered wind measurements. WindSeer can generate accurate predictions at\ndifferent resolutions and domain sizes on previously unseen topography without\nretraining. We demonstrate that the model successfully predicts historical wind\ndata collected by weather stations and wind measured onboard drones.",
        "date": "Not Found"
    },
    {
        "title": "Title:HGAttack: Transferable Heterogeneous Graph Adversarial Attack",
        "authors": [
            "",
            "Authors:",
            "",
            "He Zhao",
            ",",
            "Zhiwei Zeng",
            ",",
            "Yongwei Wang",
            ",",
            "Deheng Ye",
            ",",
            "Chunyan Miao",
            ""
        ],
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are increasingly recognized for\ntheir performance in areas like the web and e-commerce, where resilience\nagainst adversarial attacks is crucial. However, existing adversarial attack\nmethods, which are primarily designed for homogeneous graphs, fall short when\napplied to HGNNs due to their limited ability to address the structural and\nsemantic complexity of HGNNs. This paper introduces HGAttack, the first\ndedicated gray box evasion attack method for heterogeneous graphs. We design a\nnovel surrogate model to closely resemble the behaviors of the target HGNN and\nutilize gradient-based methods for perturbation generation. Specifically, the\nproposed surrogate model effectively leverages heterogeneous information by\nextracting meta-path induced subgraphs and applying GNNs to learn node\nembeddings with distinct semantics from each subgraph. This approach improves\nthe transferability of generated attacks on the target HGNN and significantly\nreduces memory costs. For perturbation generation, we introduce a\nsemantics-aware mechanism that leverages subgraph gradient information to\nautonomously identify vulnerable edges across a wide range of relations within\na constrained perturbation budget. We validate HGAttack's efficacy with\ncomprehensive experiments on three datasets, providing empirical analyses of\nits generated perturbations. Outperforming baseline methods, HGAttack\ndemonstrated significant efficacy in diminishing the performance of target HGNN\nmodels, affirming the effectiveness of our approach in evaluating the\nrobustness of HGNNs against adversarial attacks.",
        "date": "Not Found"
    },
    {
        "title": "Title:SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning",
        "authors": [
            "",
            "Authors:",
            "",
            "Ho Fung Tsoi",
            ",",
            "Vladimir Loncar",
            ",",
            "Sridhara Dasu",
            ",",
            "Philip Harris",
            ""
        ],
        "abstract": "Contrary to the use of genetic programming, the neural network approach to\nsymbolic regression can scale well with high input dimension and leverage\ngradient methods for faster equation searching. Common ways of constraining\nexpression complexity have relied on multistage pruning methods with\nfine-tuning, but these often lead to significant performance loss. In this\nwork, we propose SymbolNet, a neural network approach to symbolic regression in\na novel framework that enables dynamic pruning of model weights, input\nfeatures, and mathematical operators in a single training, where both training\nloss and expression complexity are optimized simultaneously. We introduce a\nsparsity regularization term per pruning type, which can adaptively adjust its\nown strength and lead to convergence to a target sparsity level. In contrast to\nmost existing symbolic regression methods that cannot efficiently handle\ndatasets with more than $O$(10) inputs, we demonstrate the effectiveness of our\nmodel on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN\n(3072 inputs).",
        "date": "Not Found"
    },
    {
        "title": "Title:Through the Dual-Prism: A Spectral Perspective on Graph Data  Augmentation for Graph Classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Yutong Xia",
            ",",
            "Runpeng Yu",
            ",",
            "Yuxuan Liang",
            ",",
            "Xavier Bresson",
            ",",
            "Xinchao Wang",
            ",",
            "Roger Zimmermann",
            ""
        ],
        "abstract": "Graph Neural Networks (GNNs) have become the preferred tool to process graph\ndata, with their efficacy being boosted through graph data augmentation\ntechniques. Despite the evolution of augmentation methods, issues like graph\nproperty distortions and restricted structural changes persist. This leads to\nthe question: Is it possible to develop more property-conserving and\nstructure-sensitive augmentation methods? Through a spectral lens, we\ninvestigate the interplay between graph properties, their augmentation, and\ntheir spectral behavior, and found that keeping the low-frequency eigenvalues\nunchanged can preserve the critical properties at a large scale when generating\naugmented graphs. These observations inform our introduction of the Dual-Prism\n(DP) augmentation method, comprising DP-Noise and DP-Mask, which adeptly\nretains essential graph properties while diversifying augmented graphs.\nExtensive experiments validate the efficiency of our approach, providing a new\nand promising direction for graph data augmentation.",
        "date": "Not Found"
    },
    {
        "title": "Title:Most General Winning Secure Equilibria Synthesis in Graph Games",
        "authors": [
            "",
            "Authors:",
            "",
            "Satya Prakash Nayak",
            ",",
            "Anne-Kathrin Schmuck",
            ""
        ],
        "abstract": "This paper considers the problem of co-synthesis in $k$-player games over a\nfinite graph where each player has an individual $\\omega$-regular specification\n$\\phi_i$. In this context, a secure equilibrium (SE) is a Nash equilibrium\nw.r.t. the lexicographically ordered objectives of each player to first satisfy\ntheir own specification, and second, to falsify other players' specifications.\nA winning secure equilibrium (WSE) is an SE strategy profile\n$(\\pi_i)_{i\\in[1;k]}$ that ensures the specification\n$\\phi:=\\bigwedge_{i\\in[1;k]}\\phi_i$ if no player deviates from their strategy\n$\\pi_i$. Distributed implementations generated from a WSE make components act\nrationally by ensuring that a deviation from the WSE strategy profile is\nimmediately punished by a retaliating strategy that makes the involved players\nlose.\nIn this paper, we move from deviation punishment in WSE-based implementations\nto a distributed, assume-guarantee based realization of WSE. This shift is\nobtained by generalizing WSE from strategy profiles to specification profiles\n$(\\varphi_i)_{i\\in[1;k]}$ with $\\bigwedge_{i\\in[1;k]}\\varphi_i = \\phi$, which\nwe call most general winning secure equilibria (GWSE). Such GWSE have the\nproperty that each player can individually pick a strategy $\\pi_i$ winning for\n$\\varphi_i$ (against all other players) and all resulting strategy profiles\n$(\\pi_i)_{i\\in[1;k]}$ are guaranteed to be a WSE. The obtained flexibility in\nplayers' strategy choices can be utilized for robustness and adaptability of\nlocal implementations.\nConcretely, our contribution is three-fold: (1) we formalize GWSE for\n$k$-player games over finite graphs, where each player has an $\\omega$-regular\nspecification $\\phi_i$; (2) we devise an iterative semi-algorithm for GWSE\nsynthesis in such games, and (3) obtain an exponential-time algorithm for GWSE\nsynthesis with parity specifications $\\phi_i$.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Comprehensive Scalable Framework for Cloud-Native Pattern Detection  with Enhanced Expressiveness",
        "authors": [
            "",
            "Authors:",
            "",
            "Ioannis Mavroudopoulos",
            ",",
            "Anastasios Gounaris",
            ""
        ],
        "abstract": "Detecting complex patterns in large volumes of event logs has diverse\napplications in various domains, such as business processes and fraud\ndetection. Existing systems like ELK are commonly used to tackle this\nchallenge, but their performance deteriorates for large patterns, while they\nsuffer from limitations in terms of expressiveness and explanatory capabilities\nfor their responses. In this work, we propose a solution that integrates a\nComplex Event Processing (CEP) engine into a broader query processsor on top of\na decoupled storage infrastructure containing inverted indices of log events.\nThe results demonstrate that our system excels in scalability and robustness,\nparticularly in handling complex queries. Notably, our proposed system delivers\nresponses for large complex patterns within seconds, while ELK experiences\ntimeouts after 10 minutes. It also significantly outperforms solutions relying\non FlinkCEP and executing MATCH_RECOGNIZE SQL queries.",
        "date": "Not Found"
    },
    {
        "title": "Title:CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhao Wang",
            ",",
            "Aoxue Li",
            ",",
            "Enze Xie",
            ",",
            "Lingting Zhu",
            ",",
            "Yong Guo",
            ",",
            "Qi Dou",
            ",",
            "Zhenguo Li",
            ""
        ],
        "abstract": "Customized text-to-video generation aims to generate high-quality videos\nguided by text prompts and subject references. Current approaches designed for\nsingle subjects suffer from tackling multiple subjects, which is a more\nchallenging and practical scenario. In this work, we aim to promote\nmulti-subject guided text-to-video customization. We propose CustomVideo, a\nnovel framework that can generate identity-preserving videos with the guidance\nof multiple subjects. To be specific, firstly, we encourage the co-occurrence\nof multiple subjects via composing them in a single image. Further, upon a\nbasic text-to-video diffusion model, we design a simple yet effective attention\ncontrol strategy to disentangle different subjects in the latent space of\ndiffusion model. Moreover, to help the model focus on the specific object area,\nwe segment the object from given reference images and provide a corresponding\nobject mask for attention learning. Also, we collect a multi-subject\ntext-to-video generation dataset as a comprehensive benchmark, with 69\nindividual subjects and 57 meaningful pairs. Extensive qualitative,\nquantitative, and user study results demonstrate the superiority of our method,\ncompared with the previous state-of-the-art approaches.",
        "date": "Not Found"
    },
    {
        "title": "Title:When Neural Code Completion Models Size up the Situation: Attaining  Cheaper and Faster Completion through Dynamic Model Inference",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhensu Sun",
            ",",
            "Xiaoning Du",
            ",",
            "Fu Song",
            ",",
            "Shangwen Wang",
            ",",
            "Li Li",
            ""
        ],
        "abstract": "Leveraging recent advancements in large language models, modern neural code\ncompletion models have demonstrated the capability to generate highly accurate\ncode suggestions. However, their massive size poses challenges in terms of\ncomputational costs and environmental impact, hindering their widespread\nadoption in practical scenarios. Dynamic inference emerges as a promising\nsolution, as it allocates minimal computation during inference while\nmaintaining the model's performance. In this research, we explore dynamic\ninference within the context of code completion. Initially, we conducted an\nempirical investigation on GPT-2, focusing on the inference capabilities of\nintermediate layers for code completion. We found that 54.4% of tokens can be\naccurately generated using just the first layer, signifying significant\ncomputational savings potential. Moreover, despite using all layers, the model\nstill fails to predict 14.5% of tokens correctly, and the subsequent\ncompletions continued from them are rarely considered helpful, with only a 4.2%\nAcceptance Rate. These findings motivate our exploration of dynamic inference\nin code completion and inspire us to enhance it with a decision-making\nmechanism that stops the generation of incorrect code. We thus propose a novel\ndynamic inference method specifically tailored for code completion models. This\nmethod aims not only to produce correct predictions with largely reduced\ncomputation but also to prevent incorrect predictions proactively. Our\nextensive evaluation shows that it can averagely skip 1.7 layers out of 16\nlayers in the models, leading to an 11.2% speedup with only a marginal 1.1%\nreduction in ROUGE-L.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Generative Abstract Reasoning: Completing Raven's Progressive  Matrix via Rule Abstraction and Selection",
        "authors": [
            "",
            "Authors:",
            "",
            "Fan Shi",
            ",",
            "Bin Li",
            ",",
            "Xiangyang Xue",
            ""
        ],
        "abstract": "Endowing machines with abstract reasoning ability has been a long-term\nresearch topic in artificial intelligence. Raven's Progressive Matrix (RPM) is\nwidely used to probe abstract visual reasoning in machine intelligence, where\nmodels need to understand the underlying rules and select the missing\nbottom-right images out of candidate sets to complete image matrices. The\nparticipators can display powerful reasoning ability by inferring the\nunderlying attribute-changing rules and imagining the missing images at\narbitrary positions. However, existing solvers can hardly manifest such an\nability in realistic RPM problems. In this paper, we propose a conditional\ngenerative model to solve answer generation problems through Rule AbstractIon\nand SElection (RAISE) in the latent space. RAISE encodes image attributes as\nlatent concepts and decomposes underlying rules into atomic rules by means of\nconcepts, which are abstracted as global learnable parameters. When generating\nthe answer, RAISE selects proper atomic rules out of the global knowledge set\nfor each concept and composes them into the integrated rule of an RPM. In most\nconfigurations, RAISE outperforms the compared generative solvers in tasks of\ngenerating bottom-right and arbitrary-position answers. We test RAISE in the\nodd-one-out task and two held-out configurations to demonstrate how learning\ndecoupled latent concepts and atomic rules helps find the image breaking the\nunderlying rules and handle RPMs with unseen combinations of rules and\nattributes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language  Models without Logit Access",
        "authors": [
            "",
            "Authors:",
            "",
            "Saibo Geng",
            ",",
            "Berkay D\u00f6ner",
            ",",
            "Chris Wendler",
            ",",
            "Martin Josifoski",
            ",",
            "Robert West",
            ""
        ],
        "abstract": "Constrained decoding, a technique for enforcing constraints on language model\noutputs, offers a way to control text generation without retraining or\narchitectural modifications. Its application is, however, typically restricted\nto models that give users access to next-token distributions (usually via\nsoftmax logits), which poses a limitation with blackbox large language models\n(LLMs). This paper introduces sketch-guided constrained decoding (SGCD), a\nnovel approach to constrained decoding for blackbox LLMs, which operates\nwithout access to the logits of the blackbox LLM. SGCD utilizes a locally\nhosted auxiliary model to refine the output of an unconstrained blackbox LLM,\neffectively treating this initial output as a \"sketch\" for further elaboration.\nThis approach is complementary to traditional logit-based techniques and\nenables the application of constrained decoding in settings where full model\ntransparency is unavailable. We demonstrate the efficacy of SGCD through\nexperiments in closed information extraction and constituency parsing, showing\nhow it enhances the utility and flexibility of blackbox LLMs for complex NLP\ntasks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Better Explain Transformers by Illuminating Important Information",
        "authors": [
            "",
            "Authors:",
            "",
            "Linxin Song",
            ",",
            "Yan Cui",
            ",",
            "Ao Luo",
            ",",
            "Freddy Lecue",
            ",",
            "Irene Li",
            ""
        ],
        "abstract": "Transformer-based models excel in various natural language processing (NLP)\ntasks, attracting countless efforts to explain their inner workings. Prior\nmethods explain Transformers by focusing on the raw gradient and attention as\ntoken attribution scores, where non-relevant information is often considered\nduring explanation computation, resulting in confusing results. In this work,\nwe propose highlighting the important information and eliminating irrelevant\ninformation by a refined information flow on top of the layer-wise relevance\npropagation (LRP) method. Specifically, we consider identifying syntactic and\npositional heads as important attention heads and focus on the relevance\nobtained from these important heads. Experimental results demonstrate that\nirrelevant information does distort output attribution scores and then should\nbe masked during explanation computation. Compared to eight baselines on both\nclassification and question-answering datasets, our method consistently\noutperforms with over 3\\% to 33\\% improvement on explanation metrics, providing\nsuperior explanation performance. Our anonymous code repository is available\nat: https://github.com/LinxinS97/Mask-LRP",
        "date": "Not Found"
    },
    {
        "title": "Title:Accelerated Bounded Model Checking",
        "authors": [
            "",
            "Authors:",
            "",
            "Florian Frohn",
            ",",
            "J\u00fcrgen Giesl",
            ""
        ],
        "abstract": "Bounded Model Checking (BMC) is a powerful technique for proving reachability\nof error states, i.e., unsafety. However, finding deep counterexamples that\nrequire a large bound is challenging for BMC. On the other hand, acceleration\ntechniques compute \"shortcuts\" that \"compress\" many execution steps into a\nsingle one. In this paper, we tightly integrate acceleration techniques into\nSMT-based bounded model checking. By adding suitable \"shortcuts\" to the\nSMT-problem on the fly, our approach can quickly detect deep counterexamples,\neven when only using small bounds. Moreover, using so-called blocking clauses,\nour approach can prove safety of examples where BMC diverges. An empirical\ncomparison with other state-of-the-art techniques shows that our approach is\nhighly competitive for proving unsafety, and orthogonal to existing techniques\nfor proving safety.",
        "date": "Not Found"
    },
    {
        "title": "Title:Material-Response-Informed DeepONet and its Application to Polycrystal  Stress-strain Prediction in Crystal Plasticity",
        "authors": [
            "",
            "Authors:",
            "",
            "Junyan He",
            ",",
            "Deepankar Pal",
            ",",
            "Ali Najafi",
            ",",
            "Diab Abueidda",
            ",",
            "Seid Koric",
            ",",
            "Iwona Jasiuk",
            ""
        ],
        "abstract": "Crystal plasticity (CP) simulations are a tool for understanding how\nmicrostructure morphology and texture affect mechanical properties and are an\nessential component of elucidating the structure-property relations. However,\nit can be computationally expensive. Hence, data-driven machine learning models\nhave been applied to predict the mean-field response of a polycrystal\nrepresentative volume element to reduce computation time. In this work, we\nproposed a novel Deep Operator Network (DeepONet) architecture for predicting\nmicrostructure stress-strain response. It employs a convolutional neural\nnetwork in the trunk to encode the microstructure. To account for different\nmaterial properties, boundary conditions, and loading, we proposed using single\ncrystal stress-strain curves as inputs to the branch network, furnishing a\nmaterial-response-informed DeepONet. Using four numerical examples, we\ndemonstrate that the current DeepONet can be trained on a single material and\nloading and then generalized to new conditions via transfer learning. Results\nshow that using single crystal responses as input outperforms a similar model\nusing material properties as inputs and overcomes limitations with changing\nboundary conditions and temporal resolution. In all cases, the new model\nachieved a $R^2$ value of above 0.99, and over 95\\% of predicted stresses have\na relative error of $\\le$ 5\\%, indicating superior accuracy. With as few as 20\nnew data points and under 1min training time, the trained DeepONet can be\nfine-tuned to generate accurate predictions on different materials and loading.\nOnce trained, the prediction speed is almost $1\\times10^{4}$ times faster the\nCP simulations. The efficiency and high generalizability of our DeepONet render\nit a powerful data-driven surrogate model for CP simulations in multi-scale\nanalyses.",
        "date": "Not Found"
    },
    {
        "title": "Title:Multiobjective Optimization Analysis for Finding Infrastructure-as-Code  Deployment Configurations",
        "authors": [
            "",
            "Authors:",
            "",
            "Eneko Osaba",
            ",",
            "Josu Diaz-de-Arcaya",
            ",",
            "Juncal Alonso",
            ",",
            "Jesus L. Lobo",
            ",",
            "Gorka Benguria",
            ",",
            "I\u00f1aki Etxaniz",
            ""
        ],
        "abstract": "Multiobjective optimization is a hot topic in the artificial intelligence and\noperations research communities. The design and development of multiobjective\nmethods is a frequent task for researchers and practitioners. As a result of\nthis vibrant activity, a myriad of techniques have been proposed in the\nliterature to date, demonstrating a significant effectiveness for dealing with\nsituations coming from a wide range of real-world areas. This paper is focused\non a multiobjective problem related to optimizing Infrastructure-as-Code\ndeployment configurations. The system implemented for solving this problem has\nbeen coined as IaC Optimizer Platform (IOP). Despite the fact that a\nprototypical version of the IOP has been introduced in the literature before, a\ndeeper analysis focused on the resolution of the problem is needed, in order to\ndetermine which is the most appropriate multiobjective method for embedding in\nthe IOP. The main motivation behind the analysis conducted in this work is to\nenhance the IOP performance as much as possible. This is a crucial aspect of\nthis system, deeming that it will be deployed in a real environment, as it is\nbeing developed as part of a H2020 European project. Going deeper, we resort in\nthis paper to nine different evolutionary computation-based multiobjective\nalgorithms. For assessing the quality of the considered solvers, 12 different\nproblem instances have been generated based on real-world settings. Results\nobtained by each method after 10 independent runs have been compared using\nFriedman's non-parametric tests. Findings reached from the tests carried out\nlad to the creation of a multi-algorithm system, capable of applying different\ntechniques according to the user's needs.",
        "date": "Not Found"
    },
    {
        "title": "Title:Gradable ChatGPT Translation Evaluation",
        "authors": [
            "",
            "Authors:",
            "",
            "Hui Jiao",
            ",",
            "Bei Peng",
            ",",
            "Lu Zong",
            ",",
            "Xiaojun Zhang",
            ",",
            "Xinwei Li",
            ""
        ],
        "abstract": "ChatGPT, as a language model based on large-scale pre-training, has exerted a\nprofound influence on the domain of machine translation. In ChatGPT, a \"Prompt\"\nrefers to a segment of text or instruction employed to steer the model towards\ngenerating a specific category of response. The design of the translation\nprompt emerges as a key aspect that can wield influence over factors such as\nthe style, precision and accuracy of the translation to a certain extent.\nHowever, there is a lack of a common standard and methodology on how to design\nand select a translation prompt. Accordingly, this paper proposes a generic\ntaxonomy, which defines gradable translation prompts in terms of expression\ntype, translation style, POS information and explicit statement, thus\nfacilitating the construction of prompts endowed with distinct attributes\ntailored for various translation tasks. Specific experiments and cases are\nselected to validate and illustrate the effectiveness of the method.",
        "date": "Not Found"
    },
    {
        "title": "Title:WorldDreamer: Towards General World Models for Video Generation via  Predicting Masked Tokens",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiaofeng Wang",
            ",",
            "Zheng Zhu",
            ",",
            "Guan Huang",
            ",",
            "Boyuan Wang",
            ",",
            "Xinze Chen",
            ",",
            "Jiwen Lu",
            ""
        ],
        "abstract": "World models play a crucial role in understanding and predicting the dynamics\nof the world, which is essential for video generation. However, existing world\nmodels are confined to specific scenarios such as gaming or driving, limiting\ntheir ability to capture the complexity of general world dynamic environments.\nTherefore, we introduce WorldDreamer, a pioneering world model to foster a\ncomprehensive comprehension of general world physics and motions, which\nsignificantly enhances the capabilities of video generation. Drawing\ninspiration from the success of large language models, WorldDreamer frames\nworld modeling as an unsupervised visual sequence modeling challenge. This is\nachieved by mapping visual inputs to discrete tokens and predicting the masked\nones. During this process, we incorporate multi-modal prompts to facilitate\ninteraction within the world model. Our experiments show that WorldDreamer\nexcels in generating videos across different scenarios, including natural\nscenes and driving environments. WorldDreamer showcases versatility in\nexecuting tasks such as text-to-video conversion, image-tovideo synthesis, and\nvideo editing. These results underscore WorldDreamer's effectiveness in\ncapturing dynamic elements within diverse general world environments.",
        "date": "Not Found"
    },
    {
        "title": "Title:FLex&Chill: Improving Local Federated Learning Training with Logit  Chilling",
        "authors": [
            "",
            "Authors:",
            "",
            "Kichang Lee",
            ",",
            "Songkuk Kim",
            ",",
            "JeongGil Ko",
            ""
        ],
        "abstract": "Federated learning are inherently hampered by data heterogeneity: non-iid\ndistributed training data over local clients. We propose a novel model training\napproach for federated learning, FLex&Chill, which exploits the Logit Chilling\nmethod. Through extensive evaluations, we demonstrate that, in the presence of\nnon-iid data characteristics inherent in federated learning systems, this\napproach can expedite model convergence and improve inference accuracy.\nQuantitatively, from our experiments, we observe up to 6X improvement in the\nglobal federated learning model convergence time, and up to 3.37% improvement\nin inference accuracy.",
        "date": "Not Found"
    },
    {
        "title": "Title:A-KIT: Adaptive Kalman-Informed Transformer",
        "authors": [
            "",
            "Authors:",
            "",
            "Nadav Cohen",
            ",",
            "Itzik Klein",
            ""
        ],
        "abstract": "The extended Kalman filter (EKF) is a widely adopted method for sensor fusion\nin navigation applications. A crucial aspect of the EKF is the online\ndetermination of the process noise covariance matrix reflecting the model\nuncertainty. While common EKF implementation assumes a constant process noise,\nin real-world scenarios, the process noise varies, leading to inaccuracies in\nthe estimated state and potentially causing the filter to diverge. To cope with\nsuch situations, model-based adaptive EKF methods were proposed and\ndemonstrated performance improvements, highlighting the need for a robust\nadaptive approach. In this paper, we derive and introduce A-KIT, an adaptive\nKalman-informed transformer to learn the varying process noise covariance\nonline. The A-KIT framework is applicable to any type of sensor fusion. Here,\nwe present our approach to nonlinear sensor fusion based on an inertial\nnavigation system and Doppler velocity log. By employing real recorded data\nfrom an autonomous underwater vehicle, we show that A-KIT outperforms the\nconventional EKF by more than 49.5% and model-based adaptive EKF by an average\nof 35.4% in terms of position accuracy.",
        "date": "Not Found"
    },
    {
        "title": "Title:Developing an AI-based Integrated System for Bee Health Evaluation",
        "authors": [
            "",
            "Authors:",
            "",
            "Andrew Liang",
            ""
        ],
        "abstract": "Honey bees pollinate about one-third of the world's food supply, but bee\ncolonies have alarmingly declined by nearly 40% over the past decade due to\nseveral factors, including pesticides and pests. Traditional methods for\nmonitoring beehives, such as human inspection, are subjective, disruptive, and\ntime-consuming. To overcome these limitations, artificial intelligence has been\nused to assess beehive health. However, previous studies have lacked an\nend-to-end solution and primarily relied on data from a single source, either\nbee images or sounds. This study introduces a comprehensive system consisting\nof bee object detection and health evaluation. Additionally, it utilized a\ncombination of visual and audio signals to analyze bee behaviors. An\nAttention-based Multimodal Neural Network (AMNN) was developed to adaptively\nfocus on key features from each type of signal for accurate bee health\nassessment. The AMNN achieved an overall accuracy of 92.61%, surpassing eight\nexisting single-signal Convolutional Neural Networks and Recurrent Neural\nNetworks. It outperformed the best image-based model by 32.51% and the top\nsound-based model by 13.98% while maintaining efficient processing times.\nFurthermore, it improved prediction robustness, attaining an F1-score higher\nthan 90% across all four evaluated health conditions. The study also shows that\naudio signals are more reliable than images for assessing bee health. By\nseamlessly integrating AMNN with image and sound data in a comprehensive bee\nhealth monitoring system, this approach provides a more efficient and\nnon-invasive solution for the early detection of bee diseases and the\npreservation of bee colonies.",
        "date": "Not Found"
    },
    {
        "title": "Title:Power Grid Parameter Estimation Without Phase Measurements: Theory and  Empirical Validation",
        "authors": [
            "",
            "Authors:",
            "",
            "Jean-S\u00e9bastien Brouillon",
            ",",
            "Keith Moffat",
            ",",
            "Florian D\u00f6rfler",
            ",",
            "Giancarlo Ferrari-trecate",
            ""
        ],
        "abstract": "Reliable integration and operation of renewable distributed energy resources\nrequires accurate distribution grid models. However, obtaining precise models\nis often prohibitively expensive, given their large scale and the ongoing\nnature of grid operations. To address this challenge, considerable efforts have\nbeen devoted to harnessing abundant consumption data for automatic model\ninference. The primary result of the paper is that, while the impedance of a\nline or a network can be estimated without synchronized phase angle\nmeasurements in a consistent way, the admittance cannot. Furthermore, a\ndetailed statistical analysis is presented, quantifying the expected estimation\nerrors of four prevalent admittance estimation methods. Such errors constitute\nfundamental model inference limitations that cannot be resolved with more data.\nThese findings are empirically validated using synthetic data and real\nmeasurements from the town of Walenstadt, Switzerland, confirming the theory.\nThe results contribute to our understanding of grid estimation limitations and\nuncertainties, offering guidance for both practitioners and researchers in the\npursuit of more reliable and cost-effective solutions.",
        "date": "Not Found"
    },
    {
        "title": "Title:BPDO:Boundary Points Dynamic Optimization for Arbitrary Shape Scene Text  Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Jinzhi Zheng",
            ",",
            "Libo Zhang",
            ",",
            "Yanjun Wu",
            ",",
            "Chen Zhao",
            ""
        ],
        "abstract": "Arbitrary shape scene text detection is of great importance in scene\nunderstanding tasks. Due to the complexity and diversity of text in natural\nscenes, existing scene text algorithms have limited accuracy for detecting\narbitrary shape text. In this paper, we propose a novel arbitrary shape scene\ntext detector through boundary points dynamic optimization(BPDO). The proposed\nmodel is designed with a text aware module (TAM) and a boundary point dynamic\noptimization module (DOM). Specifically, the model designs a text aware module\nbased on segmentation to obtain boundary points describing the central region\nof the text by extracting a priori information about the text region. Then,\nbased on the idea of deformable attention, it proposes a dynamic optimization\nmodel for boundary points, which gradually optimizes the exact position of the\nboundary points based on the information of the adjacent region of each\nboundary point. Experiments on CTW-1500, Total-Text, and MSRA-TD500 datasets\nshow that the model proposed in this paper achieves a performance that is\nbetter than or comparable to the state-of-the-art algorithm, proving the\neffectiveness of the model.",
        "date": "Not Found"
    },
    {
        "title": "Title:Distantly Supervised Morpho-Syntactic Model for Relation Extraction",
        "authors": [
            "",
            "Authors:",
            "",
            "Nicolas Gutehrl\u00e9",
            ",",
            "Iana Atanassova",
            ""
        ],
        "abstract": "The task of Information Extraction (IE) involves automatically converting\nunstructured textual content into structured data. Most research in this field\nconcentrates on extracting all facts or a specific set of relationships from\ndocuments. In this paper, we present a method for the extraction and\ncategorisation of an unrestricted set of relationships from text. Our method\nrelies on morpho-syntactic extraction patterns obtained by a distant\nsupervision method, and creates Syntactic and Semantic Indices to extract and\nclassify candidate graphs. We evaluate our approach on six datasets built on\nWikidata and Wikipedia. The evaluation shows that our approach can achieve\nPrecision scores of up to 0.85, but with lower Recall and F1 scores. Our\napproach allows to quickly create rule-based systems for Information Extraction\nand to build annotated datasets to train machine-learning and deep-learning\nbased classifiers.",
        "date": "Not Found"
    },
    {
        "title": "Title:Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and  Visual Question Generation",
        "authors": [
            "",
            "Authors:",
            "",
            "Kohei Uehara",
            ",",
            "Nabarun Goswami",
            ",",
            "Hanqin Wang",
            ",",
            "Toshiaki Baba",
            ",",
            "Kohtaro Tanaka",
            ",",
            "Tomohiro Hashimoto",
            ",",
            "Kai Wang",
            ",",
            "Rei Ito",
            ",",
            "Takagi Naoya",
            ",",
            "Ryo Umagami",
            ",",
            "Yingyi Wen",
            ",",
            "Tanachai Anakewat",
            ",",
            "Tatsuya Harada",
            ""
        ],
        "abstract": "The increasing demand for intelligent systems capable of interpreting and\nreasoning about visual content requires the development of Large Multi-Modal\nModels (LMMs) that are not only accurate but also have explicit reasoning\ncapabilities. This paper presents a novel approach to imbue an LMM with the\nability to conduct explicit reasoning based on visual content and textual\ninstructions. We introduce a system that can ask a question to acquire\nnecessary knowledge, thereby enhancing the robustness and explicability of the\nreasoning process. Our method comprises the development of a novel dataset\ngenerated by a Large Language Model (LLM), designed to promote chain-of-thought\nreasoning combined with a question-asking mechanism. We designed an LMM, which\nhas high capabilities on region awareness to address the intricate requirements\nof image-text alignment. The model undergoes a three-stage training phase,\nstarting with large-scale image-text alignment using a large-scale datasets,\nfollowed by instruction tuning, and fine-tuning with a focus on\nchain-of-thought reasoning. The results demonstrate a stride toward a more\nrobust, accurate, and interpretable LMM, capable of reasoning explicitly and\nseeking information proactively when confronted with ambiguous visual input.",
        "date": "Not Found"
    },
    {
        "title": "Title:Spintronic logic: from transducers to logic gates and circuits",
        "authors": [
            "",
            "Authors:",
            "",
            "Christoph Adelmann",
            ",",
            "Florin Ciubotaru",
            ",",
            "Fanfan Meng",
            ",",
            "Sorin Cotofana",
            ",",
            "Sebastien Couet",
            ""
        ],
        "abstract": "While magnetic solid-state memory has found commercial applications to date,\nmagnetic logic has rather remained on a conceptual level so far. Here, we\ndiscuss open challenges of different spintronic logic approaches, which use\nmagnetic excitations for computation. While different logic gate designs have\nbeen proposed and proof of concept experiments have been reported, no\nnontrivial operational spintronic circuit has been demonstrated due to many\nopen challenges in spintronic circuit and system design. Furthermore, the\nintegration of spintronic circuits in CMOS systems will require the usage of\ntransducers between the electric (CMOS) and magnetic domains. We show that\nthese transducers can limit the performance as well as the energy consumption\nof hybrid CMOS-spintronic systems. Hence, the optimization of transducer\nefficiency will be a major step towards competitive spintronic logic system.",
        "date": "Not Found"
    },
    {
        "title": "Title:Attack tree metrics are operad algebras",
        "authors": [
            "",
            "Authors:",
            "",
            "Milan Lopuha\u00e4-Zwakenberg",
            ""
        ],
        "abstract": "Attack Trees (ATs) are a widely used tool for security analysis. ATs can be\nemployed in quantitative security analysis through metrics, which assign a\nsecurity value to an AT. Many different AT metrics exist, and there exist\nmultiple general definitions that aim to study a wide variety of AT metrics at\nonce. However, these all have drawbacks: they do not capture all metrics, and\nthey do not easily generalize to extensions of ATs. In this paper, we introduce\na definition of AT metrics based on category theory, specifically operad\nalgebras. This encompasses all previous definitions of AT metrics, and is\neasily generalized to extensions of ATs. Furthermore, we show that under easily\nexpressed operad-theoretic conditions, existing metric calculation algorithms\ncan be extended in considerable generality.",
        "date": "Not Found"
    },
    {
        "title": "Title:CPCL: Cross-Modal Prototypical Contrastive Learning for Weakly  Supervised Text-based Person Re-Identification",
        "authors": [
            "",
            "Authors:",
            "",
            "Yanwei Zheng",
            ",",
            "Xinpeng Zhao",
            ",",
            "Chuanlin Lan",
            ",",
            "Xiaowei Zhang",
            ",",
            "Bowen Huang",
            ",",
            "Jibin Yang",
            ",",
            "Dongxiao Yu",
            ""
        ],
        "abstract": "Weakly supervised text-based person re-identification (TPRe-ID) seeks to\nretrieve images of a target person using textual descriptions, without relying\non identity annotations and is more challenging and practical. The primary\nchallenge is the intra-class differences, encompassing intra-modal feature\nvariations and cross-modal semantic gaps. Prior works have focused on\ninstance-level samples and ignored prototypical features of each person which\nare intrinsic and invariant. Toward this, we propose a Cross-Modal Prototypical\nContrastive Learning (CPCL) method. In practice, the CPCL introduces the CLIP\nmodel to weakly supervised TPRe-ID for the first time, mapping visual and\ntextual instances into a shared latent space. Subsequently, the proposed\nPrototypical Multi-modal Memory (PMM) module captures associations between\nheterogeneous modalities of image-text pairs belonging to the same person\nthrough the Hybrid Cross-modal Matching (HCM) module in a many-to-many mapping\nfashion. Moreover, the Outlier Pseudo Label Mining (OPLM) module further\ndistinguishes valuable outlier samples from each modality, enhancing the\ncreation of more reliable clusters by mining implicit relationships between\nimage-text pairs. Experimental results demonstrate that our proposed CPCL\nattains state-of-the-art performance on all three public datasets, with a\nsignificant improvement of 11.58%, 8.77% and 5.25% in Rank@1 accuracy on\nCUHK-PEDES, ICFG-PEDES and RSTPReid datasets, respectively. The code is\navailable at https://github.com/codeGallery24/CPCL.",
        "date": "Not Found"
    },
    {
        "title": "Title:Optimizing Medication Decisions for Patients with Atrial Fibrillation  through Path Development Network",
        "authors": [
            "",
            "Authors:",
            "",
            "Tian Xie",
            ""
        ],
        "abstract": "Atrial fibrillation (AF) is a common cardiac arrhythmia characterized by\nrapid and irregular contractions of the atria. It significantly elevates the\nrisk of strokes due to slowed blood flow in the atria, especially in the left\natrial appendage, which is prone to blood clot formation. Such clots can\nmigrate into cerebral arteries, leading to ischemic stroke. To assess whether\nAF patients should be prescribed anticoagulants, doctors often use the\nCHA2DS2-VASc scoring system. However, anticoagulant use must be approached with\ncaution as it can impact clotting functions. This study introduces a machine\nlearning algorithm that predicts whether patients with AF should be recommended\nanticoagulant therapy using 12-lead ECG data. In this model, we use STOME to\nenhance time-series data and then process it through a Convolutional Neural\nNetwork (CNN). By incorporating a path development layer, the model achieves a\nspecificity of 30.6% under the condition of an NPV of 1. In contrast, LSTM\nalgorithms without path development yield a specificity of only 2.7% under the\nsame NPV condition.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Hierarchical Spoken Language Dysfluency Modeling",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiachen Lian",
            ",",
            "Gopala Anumanchipalli",
            ""
        ],
        "abstract": "Speech dysfluency modeling is the bottleneck for both speech therapy and\nlanguage learning. However, there is no AI solution to systematically tackle\nthis problem. We first propose to define the concept of dysfluent speech and\ndysfluent speech modeling. We then present Hierarchical Unconstrained\nDysfluency Modeling (H-UDM) approach that addresses both dysfluency\ntranscription and detection to eliminate the need for extensive manual\nannotation. Furthermore, we introduce a simulated dysfluent dataset called\nVCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our\nexperimental results demonstrate the effectiveness and robustness of our\nproposed methods in both transcription and detection tasks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Gender Bias in Machine Translation and The Era of Large Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Eva Vanmassenhove",
            ""
        ],
        "abstract": "This chapter examines the role of Machine Translation in perpetuating gender\nbias, highlighting the challenges posed by cross-linguistic settings and\nstatistical dependencies. A comprehensive overview of relevant existing work\nrelated to gender bias in both conventional Neural Machine Translation\napproaches and Generative Pretrained Transformer models employed as Machine\nTranslation systems is provided. Through an experiment using ChatGPT (based on\nGPT-3.5) in an English-Italian translation context, we further assess ChatGPT's\ncurrent capacity to address gender bias. The findings emphasize the ongoing\nneed for advancements in mitigating bias in Machine Translation systems and\nunderscore the importance of fostering fairness and inclusivity in language\ntechnologies.",
        "date": "Not Found"
    },
    {
        "title": "Title:Text Region Multiple Information Perception Network for Scene Text  Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Jinzhi Zheng",
            ",",
            "Libo Zhang",
            ",",
            "Yanjun Wu",
            ",",
            "Chen Zhao",
            ""
        ],
        "abstract": "Segmentation-based scene text detection algorithms can handle arbitrary shape\nscene texts and have strong robustness and adaptability, so it has attracted\nwide attention. Existing segmentation-based scene text detection algorithms\nusually only segment the pixels in the center region of the text, while\nignoring other information of the text region, such as edge information,\ndistance information, etc., thus limiting the detection accuracy of the\nalgorithm for scene text. This paper proposes a plug-and-play module called the\nRegion Multiple Information Perception Module (RMIPM) to enhance the detection\nperformance of segmentation-based algorithms. Specifically, we design an\nimproved module that can perceive various types of information about scene text\nregions, such as text foreground classification maps, distance maps, direction\nmaps, etc. Experiments on MSRA-TD500 and TotalText datasets show that our\nmethod achieves comparable performance with current state-of-the-art\nalgorithms.",
        "date": "Not Found"
    },
    {
        "title": "Title:R-Judge: Benchmarking Safety Risk Awareness for LLM Agents",
        "authors": [
            "",
            "Authors:",
            "",
            "Tongxin Yuan",
            ",",
            "Zhiwei He",
            ",",
            "Lingzhong Dong",
            ",",
            "Yiming Wang",
            ",",
            "Ruijie Zhao",
            ",",
            "Tian Xia",
            ",",
            "Lizhen Xu",
            ",",
            "Binglin Zhou",
            ",",
            "Fangqi Li",
            ",",
            "Zhuosheng Zhang",
            ",",
            "Rui Wang",
            ",",
            "Gongshen Liu",
            ""
        ],
        "abstract": "Large language models (LLMs) have exhibited great potential in autonomously\ncompleting tasks across real-world applications. Despite this, these LLM agents\nintroduce unexpected safety risks when operating in interactive environments.\nInstead of centering on LLM-generated content safety in most prior studies,\nthis work addresses the imperative need for benchmarking the behavioral safety\nof LLM agents within diverse environments. We introduce R-Judge, a benchmark\ncrafted to evaluate the proficiency of LLMs in judging safety risks given agent\ninteraction records. R-Judge comprises 162 agent interaction records,\nencompassing 27 key risk scenarios among 7 application categories and 10 risk\ntypes. It incorporates human consensus on safety with annotated safety risk\nlabels and high-quality risk descriptions. Utilizing R-Judge, we conduct a\ncomprehensive evaluation of 8 prominent LLMs commonly employed as the backbone\nfor agents. The best-performing model, GPT-4, achieves 72.29% in contrast to\nthe human score of 89.38%, showing considerable room for enhancing the risk\nawareness of LLMs. Notably, leveraging risk descriptions as environment\nfeedback significantly improves model performance, revealing the importance of\nsalient safety risk feedback. Furthermore, we design an effective chain of\nsafety analysis technique to help the judgment of safety risks and conduct an\nin-depth case study to facilitate future research. R-Judge is publicly\navailable at https://github.com/Lordog/R-Judge.",
        "date": "Not Found"
    },
    {
        "title": "Title:Self-Rewarding Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Weizhe Yuan",
            ",",
            "Richard Yuanzhe Pang",
            ",",
            "Kyunghyun Cho",
            ",",
            "Sainbayar Sukhbaatar",
            ",",
            "Jing Xu",
            ",",
            "Jason Weston",
            ""
        ],
        "abstract": "We posit that to achieve superhuman agents, future models require superhuman\nfeedback in order to provide an adequate training signal. Current approaches\ncommonly train reward models from human preferences, which may then be\nbottlenecked by human performance level, and secondly these separate frozen\nreward models cannot then learn to improve during LLM training. In this work,\nwe study Self-Rewarding Language Models, where the language model itself is\nused via LLM-as-a-Judge prompting to provide its own rewards during training.\nWe show that during Iterative DPO training that not only does instruction\nfollowing ability improve, but also the ability to provide high-quality rewards\nto itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a\nmodel that outperforms many existing systems on the AlpacaEval 2.0 leaderboard,\nincluding Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study,\nthis work opens the door to the possibility of models that can continually\nimprove in both axes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "",
            "Authors:",
            "",
            "Julia Camps",
            ",",
            "Zhinuo Jenny Wang",
            ",",
            "Ruben Doste",
            ",",
            "Maxx Holmes",
            ",",
            "Brodie Lawson",
            ",",
            "Jakub Tomek",
            ",",
            "Kevin Burrage",
            ",",
            "Alfonso Bueno-Orovio",
            ",",
            "Blanca Rodriguez",
            ""
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and\nanatomical characteristics of patient hearts for investigating disease\nphenotypes and predicting responses to therapy. When paired with large-scale\ncomputational resources and large clinical datasets, digital twin technology\ncan enable virtual clinical trials on virtual cohorts to fast-track therapy\ndevelopment. Here, we present an automated pipeline for personalising\nventricular anatomy and electrophysiological function based on routinely\nacquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead\nelectrocardiogram (ECG). Using CMR-based anatomical models, a sequential\nMonte-Carlo approximate Bayesian computational inference method is extended to\ninfer electrical activation and repolarisation characteristics from the ECG.\nFast simulations are conducted with a reaction-Eikonal model, including the\nPurkinje network and biophysically-detailed subcellular ionic current dynamics\nfor repolarisation. For each patient, parameter uncertainty is represented by\ninferring a population of ventricular models rather than a single one, which\nmeans that parameter uncertainty can be propagated to therapy evaluation.\nFurthermore, we have developed techniques for translating from reaction-Eikonal\nto monodomain simulations, which allows more realistic simulations of cardiac\nelectrophysiology. The pipeline is demonstrated in a healthy female subject,\nwhere our inferred reaction-Eikonal models reproduced the patient's ECG with a\nPearson's correlation coefficient of 0.93, and the translated monodomain\nsimulations have a correlation coefficient of 0.89. We then apply the effect of\nDofetilide to the monodomain population of models for this subject and show\ndose-dependent QT and T-peak to T-end prolongations that are in keeping with\nlarge population drug response data.",
        "date": "Not Found"
    },
    {
        "title": "Title:Framing Analysis of Health-Related Narratives: Conspiracy versus  Mainstream Media",
        "authors": [
            "",
            "Authors:",
            "",
            "Markus Reiter-Haas",
            ",",
            "Beate Kl\u00f6sch",
            ",",
            "Markus Hadler",
            ",",
            "Elisabeth Lex",
            ""
        ],
        "abstract": "Understanding how online media frame issues is crucial due to their impact on\npublic opinion. Research on framing using natural language processing\ntechniques mainly focuses on specific content features in messages and neglects\ntheir narrative elements. Also, the distinction between framing in different\nsources remains an understudied problem. We address those issues and\ninvestigate how the framing of health-related topics, such as COVID-19 and\nother diseases, differs between conspiracy and mainstream websites. We\nincorporate narrative information into the framing analysis by introducing a\nnovel frame extraction approach based on semantic graphs. We find that\nhealth-related narratives in conspiracy media are predominantly framed in terms\nof beliefs, while mainstream media tend to present them in terms of science. We\nhope our work offers new ways for a more nuanced frame analysis.",
        "date": "Not Found"
    },
    {
        "title": "Title:Evolutionary Computation in the Era of Large Language Model: Survey and  Roadmap",
        "authors": [
            "",
            "Authors:",
            "",
            "Xingyu Wu",
            ",",
            "Sheng-hao Wu",
            ",",
            "Jibin Wu",
            ",",
            "Liang Feng",
            ",",
            "Kay Chen Tan",
            ""
        ],
        "abstract": "Large Language Models (LLMs), built upon Transformer-based architectures with\nmassive pretraining on diverse data, have not only revolutionized natural\nlanguage processing but also extended their prowess to various domains, marking\na significant stride towards artificial general intelligence. The interplay\nbetween LLMs and Evolutionary Algorithms (EAs), despite differing in objectives\nand methodologies, reveals intriguing parallels, especially in their shared\noptimization nature, black-box characteristics, and proficiency in handling\ncomplex problems. Meanwhile, EA can not only provide an optimization framework\nfor LLM's further enhancement under black-box settings but also empower LLM\nwith flexible global search and iterative mechanism in applications. On the\nother hand, LLM's abundant domain knowledge enables EA to perform smarter\nsearches, while its text processing capability assist in deploying EA across\nvarious tasks. Based on their complementary advantages, this paper presents a\ncomprehensive review and forward-looking roadmap, categorizing their mutual\ninspiration into LLM-enhanced evolutionary optimization and EA-enhanced LLM.\nSome integrated synergy methods are further introduced to exemplify the\namalgamation of LLMs and EAs in various application scenarios, including neural\narchitecture search, code generation, software engineering, and text\ngeneration. As the first comprehensive review specifically focused on the EA\nresearch in the era of LLMs, this paper provides a foundational stepping stone\nfor understanding and harnessing the collaborative potential of LLMs and EAs.\nBy presenting a comprehensive review, categorization, and critical analysis, we\ncontribute to the ongoing discourse on the cross-disciplinary study of these\ntwo powerful paradigms. The identified challenges and future directions offer\nguidance to unlock the full potential of this innovative collaboration.",
        "date": "Not Found"
    },
    {
        "title": "Title:LOCALINTEL: Generating Organizational Threat Intelligence from Global  and Local Cyber Knowledge",
        "authors": [
            "",
            "Authors:",
            "",
            "Shaswata Mitra",
            ",",
            "Subash Neupane",
            ",",
            "Trisha Chakraborty",
            ",",
            "Sudip Mittal",
            ",",
            "Aritran Piplai",
            ",",
            "Manas Gaur",
            ",",
            "Shahram Rahimi",
            ""
        ],
        "abstract": "Security Operations Center (SoC) analysts gather threat reports from openly\naccessible global threat databases and customize them manually to suit a\nparticular organization's needs. These analysts also depend on internal\nrepositories, which act as private local knowledge database for an\norganization. Credible cyber intelligence, critical operational details, and\nrelevant organizational information are all stored in these local knowledge\ndatabases. Analysts undertake a labor intensive task utilizing these global and\nlocal knowledge databases to manually create organization's unique threat\nresponse and mitigation strategies. Recently, Large Language Models (LLMs) have\nshown the capability to efficiently process large diverse knowledge sources. We\nleverage this ability to process global and local knowledge databases to\nautomate the generation of organization-specific threat intelligence.\nIn this work, we present LOCALINTEL, a novel automated knowledge\ncontextualization system that, upon prompting, retrieves threat reports from\nthe global threat repositories and uses its local knowledge database to\ncontextualize them for a specific organization. LOCALINTEL comprises of three\nkey phases: global threat intelligence retrieval, local knowledge retrieval,\nand contextualized completion generation. The former retrieves intelligence\nfrom global threat repositories, while the second retrieves pertinent knowledge\nfrom the local knowledge database. Finally, the fusion of these knowledge\nsources is orchestrated through a generator to produce a contextualized\ncompletion.",
        "date": "Not Found"
    },
    {
        "title": "Title:Depth Over RGB: Automatic Evaluation of Open Surgery Skills Using Depth  Camera",
        "authors": [
            "",
            "Authors:",
            "",
            "Ido Zuckerman",
            ",",
            "Nicole Werner",
            ",",
            "Jonathan Kouchly",
            ",",
            "Emma Huston",
            ",",
            "Shannon DiMarco",
            ",",
            "Paul DiMusto",
            ",",
            "Shlomi Laufer",
            ""
        ],
        "abstract": "Purpose: In this paper, we present a novel approach to the automatic\nevaluation of open surgery skills using depth cameras. This work is intended to\nshow that depth cameras achieve similar results to RGB cameras, which is the\ncommon method in the automatic evaluation of open surgery skills. Moreover,\ndepth cameras offer advantages such as robustness to lighting variations,\ncamera positioning, simplified data compression, and enhanced privacy, making\nthem a promising alternative to RGB cameras.\nMethods: Experts and novice surgeons completed two simulators of open\nsuturing. We focused on hand and tool detection, and action segmentation in\nsuturing procedures. YOLOv8 was used for tool detection in RGB and depth\nvideos. Furthermore, UVAST and MSTCN++ were used for action segmentation. Our\nstudy includes the collection and annotation of a dataset recorded with Azure\nKinect.\nResults: We demonstrated that using depth cameras in object detection and\naction segmentation achieves comparable results to RGB cameras. Furthermore, we\nanalyzed 3D hand path length, revealing significant differences between experts\nand novice surgeons, emphasizing the potential of depth cameras in capturing\nsurgical skills. We also investigated the influence of camera angles on\nmeasurement accuracy, highlighting the advantages of 3D cameras in providing a\nmore accurate representation of hand movements.\nConclusion: Our research contributes to advancing the field of surgical skill\nassessment by leveraging depth cameras for more reliable and privacy\nevaluations. The findings suggest that depth cameras can be valuable in\nassessing surgical skills and provide a foundation for future research in this\narea.",
        "date": "Not Found"
    },
    {
        "title": "Title:GPT4Ego: Unleashing the Potential of Pre-trained Models for Zero-Shot  Egocentric Action Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Guangzhao Dai",
            ",",
            "Xiangbo Shu",
            ",",
            "Wenhao Wu",
            ""
        ],
        "abstract": "Vision-Language Models (VLMs), pre-trained on large-scale datasets, have\nshown impressive performance in various visual recognition tasks. This\nadvancement paves the way for notable performance in Zero-Shot Egocentric\nAction Recognition (ZS-EAR). Typically, VLMs handle ZS-EAR as a global\nvideo-text matching task, which often leads to suboptimal alignment of vision\nand linguistic knowledge. We propose a refined approach for ZS-EAR using VLMs,\nemphasizing fine-grained concept-description alignment that capitalizes on the\nrich semantic and contextual details in egocentric videos. In this paper, we\nintroduce GPT4Ego, a straightforward yet remarkably potent VLM framework for\nZS-EAR, designed to enhance the fine-grained alignment of concept and\ndescription between vision and language. Extensive experiments demonstrate\nGPT4Ego significantly outperforms existing VLMs on three large-scale egocentric\nvideo benchmarks, i.e., EPIC-KITCHENS-100 (33.2%, +9.4%), EGTEA (39.6%, +5.5%),\nand CharadesEgo (31.5%, +2.6%).",
        "date": "Not Found"
    },
    {
        "title": "Title:Large Language Models for Scientific Information Extraction: An  Empirical Study for Virology",
        "authors": [
            "",
            "Authors:",
            "",
            "Mahsa Shamsabadi",
            ",",
            "Jennifer D'Souza",
            ",",
            "S\u00f6ren Auer",
            ""
        ],
        "abstract": "In this paper, we champion the use of structured and semantic content\nrepresentation of discourse-based scholarly communication, inspired by tools\nlike Wikipedia infoboxes or structured Amazon product descriptions. These\nrepresentations provide users with a concise overview, aiding scientists in\nnavigating the dense academic landscape. Our novel automated approach leverages\nthe robust text generation capabilities of LLMs to produce structured scholarly\ncontribution summaries, offering both a practical solution and insights into\nLLMs' emergent abilities.\nFor LLMs, the prime focus is on improving their general intelligence as\nconversational agents. We argue that these models can also be applied\neffectively in information extraction (IE), specifically in complex IE tasks\nwithin terse domains like Science. This paradigm shift replaces the traditional\nmodular, pipelined machine learning approach with a simpler objective expressed\nthrough instructions. Our results show that finetuned FLAN-T5 with 1000x fewer\nparameters than the state-of-the-art GPT-davinci is competitive for the task.",
        "date": "Not Found"
    },
    {
        "title": "Title:CMFN: Cross-Modal Fusion Network for Irregular Scene Text Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Jinzhi Zheng",
            ",",
            "Ruyi Ji",
            ",",
            "Libo Zhang",
            ",",
            "Yanjun Wu",
            ",",
            "Chen Zhao",
            ""
        ],
        "abstract": "Scene text recognition, as a cross-modal task involving vision and text, is\nan important research topic in computer vision. Most existing methods use\nlanguage models to extract semantic information for optimizing visual\nrecognition. However, the guidance of visual cues is ignored in the process of\nsemantic mining, which limits the performance of the algorithm in recognizing\nirregular scene text. To tackle this issue, we propose a novel cross-modal\nfusion network (CMFN) for irregular scene text recognition, which incorporates\nvisual cues into the semantic mining process. Specifically, CMFN consists of a\nposition self-enhanced encoder, a visual recognition branch and an iterative\nsemantic recognition branch. The position self-enhanced encoder provides\ncharacter sequence position encoding for both the visual recognition branch and\nthe iterative semantic recognition branch. The visual recognition branch\ncarries out visual recognition based on the visual features extracted by CNN\nand the position encoding information provided by the position self-enhanced\nencoder. The iterative semantic recognition branch, which consists of a\nlanguage recognition module and a cross-modal fusion gate, simulates the way\nthat human recognizes scene text and integrates cross-modal visual cues for\ntext recognition. The experiments demonstrate that the proposed CMFN algorithm\nachieves comparable performance to state-of-the-art algorithms, indicating its\neffectiveness.",
        "date": "Not Found"
    },
    {
        "title": "Title:BlockAMC: Scalable In-Memory Analog Matrix Computing for Solving Linear  Systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Lunshuai Pan",
            ",",
            "Pushen Zuo",
            ",",
            "Yubiao Luo",
            ",",
            "Zhong Sun",
            ",",
            "Ru Huang",
            ""
        ],
        "abstract": "Recently, in-memory analog matrix computing (AMC) with nonvolatile resistive\nmemory has been developed for solving matrix problems in one step, e.g., matrix\ninversion of solving linear systems. However, the analog nature sets up a\nbarrier to the scalability of AMC, due to the limits on the manufacturability\nand yield of resistive memory arrays, non-idealities of device and circuit, and\ncost of hardware implementations. Aiming to deliver a scalable AMC approach for\nsolving linear systems, this work presents BlockAMC, which partitions a large\noriginal matrix into smaller ones on different memory arrays. A macro is\ndesigned to perform matrix inversion and matrix-vector multiplication with the\nblock matrices, obtaining the partial solutions to recover the original\nsolution. The size of block matrices can be exponentially reduced by performing\nmultiple stages of divide-and-conquer, resulting in a two-stage solver design\nthat enhances the scalability of this approach. BlockAMC is also advantageous\nin alleviating the accuracy issue of AMC, especially in the presence of device\nand circuit non-idealities, such as conductance variations and interconnect\nresistances. Compared to a single AMC circuit solving the same problem,\nBlockAMC improves the area and energy efficiency by 48.83% and 40%,\nrespectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Deep spatial context: when attention-based models meet spatial  regression",
        "authors": [
            "",
            "Authors:",
            "",
            "Paulina Tomaszewska",
            ",",
            "El\u017cbieta Sienkiewicz",
            ",",
            "Mai P. Hoang",
            ",",
            "Przemys\u0142aw Biecek",
            ""
        ],
        "abstract": "We propose 'Deep spatial context' (DSCon) method, which serves for\ninvestigation of the attention-based vision models using the concept of spatial\ncontext. It was inspired by histopathologists, however, the method can be\napplied to various domains. The DSCon allows for a quantitative measure of the\nspatial context's role using three Spatial Context Measures: $SCM_{features}$,\n$SCM_{targets}$, $SCM_{residuals}$ to distinguish whether the spatial context\nis observable within the features of neighboring regions, their target values\n(attention scores) or residuals, respectively. It is achieved by integrating\nspatial regression into the pipeline. The DSCon helps to verify research\nquestions. The experiments reveal that spatial relationships are much bigger in\nthe case of the classification of tumor lesions than normal tissues. Moreover,\nit turns out that the larger the size of the neighborhood taken into account\nwithin spatial regression, the less valuable contextual information is.\nFurthermore, it is observed that the spatial context measure is the largest\nwhen considered within the feature space as opposed to the targets and\nresiduals.",
        "date": "Not Found"
    },
    {
        "title": "Title:Antonym vs Synonym Distinction using InterlaCed Encoder NETworks  (ICE-NET)",
        "authors": [
            "",
            "Authors:",
            "",
            "Muhammad Asif Ali",
            ",",
            "Yan Hu",
            ",",
            "Jianbin Qin",
            ",",
            "Di Wang",
            ""
        ],
        "abstract": "Antonyms vs synonyms distinction is a core challenge in lexico-semantic\nanalysis and automated lexical resource construction. These pairs share a\nsimilar distributional context which makes it harder to distinguish them.\nLeading research in this regard attempts to capture the properties of the\nrelation pairs, i.e., symmetry, transitivity, and trans-transitivity. However,\nthe inability of existing research to appropriately model the relation-specific\nproperties limits their end performance. In this paper, we propose InterlaCed\nEncoder NETworks (i.e., ICE-NET) for antonym vs synonym distinction, that aim\nto capture and model the relation-specific properties of the antonyms and\nsynonyms pairs in order to perform the classification task in a\nperformance-enhanced manner. Experimental evaluation using the benchmark\ndatasets shows that ICE-NET outperforms the existing research by a relative\nscore of upto 1.8% in F1-measure. We release the codes for ICE-NET at\nhttps://github.com/asif6827/ICENET.",
        "date": "Not Found"
    },
    {
        "title": "Title:ContextMix: A context-aware data augmentation method for industrial  visual inspection systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Hyungmin Kim",
            ",",
            "Donghun Kim",
            ",",
            "Pyunghwan Ahn",
            ",",
            "Sungho Suh",
            ",",
            "Hansang Cho",
            ",",
            "Junmo Kim",
            ""
        ],
        "abstract": "While deep neural networks have achieved remarkable performance, data\naugmentation has emerged as a crucial strategy to mitigate overfitting and\nenhance network performance. These techniques hold particular significance in\nindustrial manufacturing contexts. Recently, image mixing-based methods have\nbeen introduced, exhibiting improved performance on public benchmark datasets.\nHowever, their application to industrial tasks remains challenging. The\nmanufacturing environment generates massive amounts of unlabeled data on a\ndaily basis, with only a few instances of abnormal data occurrences. This leads\nto severe data imbalance. Thus, creating well-balanced datasets is not\nstraightforward due to the high costs associated with labeling. Nonetheless,\nthis is a crucial step for enhancing productivity. For this reason, we\nintroduce ContextMix, a method tailored for industrial applications and\nbenchmark datasets. ContextMix generates novel data by resizing entire images\nand integrating them into other images within the batch. This approach enables\nour method to learn discriminative features based on varying sizes from resized\nimages and train informative secondary features for object recognition using\noccluded images. With the minimal additional computation cost of image\nresizing, ContextMix enhances performance compared to existing augmentation\ntechniques. We evaluate its effectiveness across classification, detection, and\nsegmentation tasks using various network architectures on public benchmark\ndatasets. Our proposed method demonstrates improved results across a range of\nrobustness tasks. Its efficacy in real industrial environments is particularly\nnoteworthy, as demonstrated using the passive component dataset.",
        "date": "Not Found"
    },
    {
        "title": "Title:Unconstrained Parameterization of Stable LPV Input-Output Models: with  Application to System Identification",
        "authors": [
            "",
            "Authors:",
            "",
            "Johan Kon",
            ",",
            "Jeroen van de Wijdeven",
            ",",
            "Dennis Bruijnen",
            ",",
            "Roland T\u00f3th",
            ",",
            "Marcel Heertjes",
            ",",
            "Tom Oomen",
            ""
        ],
        "abstract": "Ensuring stability of discrete-time (DT) linear parameter-varying (LPV)\ninput-output (IO) models estimated via system identification methods is a\nchallenging problem as known stability constraints can only be numerically\nverified, e.g., through solving Linear Matrix Inequalities. In this paper, an\nunconstrained DT-LPV-IO parameterization is developed which gives a stable\nmodel for any choice of model parameters. To achieve this, it is shown that\n\\textit{all} quadratically stable DT-LPV-IO models can be generated by a\nmapping of transformed coefficient functions that are constrained to the unit\nball, i.e., a small-gain condition. The unit ball is then reparameterized\nthrough a Cayley transformation, resulting in an unconstrained parameterization\nof all quadratically stable DT-LPV-IO models. As a special case, an\nunconstrained parameterization of all stable DT linear time-invariant transfer\nfunctions is obtained. Identification using the stable DT-LPV-IO model with\nneural network coefficient functions is demonstrated on a simulation example of\na position-varying mass-damper-spring system.",
        "date": "Not Found"
    },
    {
        "title": "Title:DiffusionGPT: LLM-Driven Text-to-Image Generation System",
        "authors": [
            "",
            "Authors:",
            "",
            "Jie Qin",
            ",",
            "Jie Wu",
            ",",
            "Weifeng Chen",
            ",",
            "Yuxi Ren",
            ",",
            "Huixia Li",
            ",",
            "Hefeng Wu",
            ",",
            "Xuefeng Xiao",
            ",",
            "Rui Wang",
            ",",
            "Shilei Wen",
            ""
        ],
        "abstract": "Diffusion models have opened up new avenues for the field of image\ngeneration, resulting in the proliferation of high-quality models shared on\nopen-source platforms. However, a major challenge persists in current\ntext-to-image systems are often unable to handle diverse inputs, or are limited\nto single model results. Current unified attempts often fall into two\northogonal aspects: i) parse Diverse Prompts in input stage; ii) activate\nexpert model to output. To combine the best of both worlds, we propose\nDiffusionGPT, which leverages Large Language Models (LLM) to offer a unified\ngeneration system capable of seamlessly accommodating various types of prompts\nand integrating domain-expert models. DiffusionGPT constructs domain-specific\nTrees for various generative models based on prior knowledge. When provided\nwith an input, the LLM parses the prompt and employs the Trees-of-Thought to\nguide the selection of an appropriate model, thereby relaxing input constraints\nand ensuring exceptional performance across diverse domains. Moreover, we\nintroduce Advantage Databases, where the Tree-of-Thought is enriched with human\nfeedback, aligning the model selection process with human preferences. Through\nextensive experiments and comparisons, we demonstrate the effectiveness of\nDiffusionGPT, showcasing its potential for pushing the boundaries of image\nsynthesis in diverse domains.",
        "date": "Not Found"
    },
    {
        "title": "Title:Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs",
        "authors": [
            "",
            "Authors:",
            "",
            "Haritz Puerto",
            ",",
            "Martin Tutek",
            ",",
            "Somak Aditya",
            ",",
            "Xiaodan Zhu",
            ",",
            "Iryna Gurevych",
            ""
        ],
        "abstract": "Reasoning is a fundamental component for achieving language understanding.\nAmong the multiple types of reasoning, conditional reasoning, the ability to\ndraw different conclusions depending on some condition, has been understudied\nin large language models (LLMs). Recent prompting methods, such as chain of\nthought, have significantly improved LLMs on reasoning tasks. Nevertheless,\nthere is still little understanding of what triggers reasoning abilities in\nLLMs. We hypothesize that code prompts can trigger conditional reasoning in\nLLMs trained on text and code. We propose a chain of prompts that transforms a\nnatural language problem into code and prompts the LLM with the generated code.\nOur experiments find that code prompts exhibit a performance boost between 2.6\nand 7.7 points on GPT 3.5 across multiple datasets requiring conditional\nreasoning. We then conduct experiments to discover how code prompts elicit\nconditional reasoning abilities and through which features. We observe that\nprompts need to contain natural language text accompanied by high-quality code\nthat closely represents the semantics of the instance text. Furthermore, we\nshow that code prompts are more efficient, requiring fewer demonstrations, and\nthat they trigger superior state tracking of variables or key entities.",
        "date": "Not Found"
    },
    {
        "title": "Title:GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue  Heterogeneity",
        "authors": [
            "",
            "Authors:",
            "",
            "Anik Chaudhuri",
            ",",
            "Anwoy Mohanty",
            ",",
            "Manoranjan Satpathy",
            ""
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges\nin cancer diagnosis and treatment. Studying the heterogeneity in cell\npopulations from gene expression measurement data in the context of cancer\nresearch is a problem of paramount importance. In addition, reducing the\ncomputation time of the algorithms that deal with high volumes of data has its\nobvious merits. Parallelizable models using Markov chain Monte Carlo methods\nare typically slow. This paper shows a novel, computationally efficient, and\nparallelizable model to analyze heterogeneity in cancer tissues using GPUs.\nBecause our model is parallelizable, the input data size does not affect the\ncomputation time much, provided the hardware resources are not exhausted. Our\nmodel uses qPCR (quantitative polymerase chain reaction) gene expression\nmeasurements to study heterogeneity in cancer tissue. We compute the cell\nproportion breakup by accelerating variational methods on a GPU. We test this\nmodel on synthetic and real-world gene expression data collected from\nfibroblasts and compare the performance of our algorithm with those of MCMC and\nExpectation Maximization. Our new model is computationally less complex and\nfaster than existing Bayesian models for cancer tissue heterogeneity.",
        "date": "Not Found"
    },
    {
        "title": "Title:Communication-Efficient Personalized Federated Learning for  Speech-to-Text Tasks",
        "authors": [
            "",
            "Authors:",
            "",
            "Yichao Du",
            ",",
            "Zhirui Zhang",
            ",",
            "Linan Yue",
            ",",
            "Xu Huang",
            ",",
            "Yuqing Zhang",
            ",",
            "Tong Xu",
            ",",
            "Linli Xu",
            ",",
            "Enhong Chen",
            ""
        ],
        "abstract": "To protect privacy and meet legal regulations, federated learning (FL) has\ngained significant attention for training speech-to-text (S2T) systems,\nincluding automatic speech recognition (ASR) and speech translation (ST).\nHowever, the commonly used FL approach (i.e., \\textsc{FedAvg}) in S2T tasks\ntypically suffers from extensive communication overhead due to multi-round\ninteractions based on the whole model and performance degradation caused by\ndata heterogeneity among clients.To address these issues, we propose a\npersonalized federated S2T framework that introduces \\textsc{FedLoRA}, a\nlightweight LoRA module for client-side tuning and interaction with the server\nto minimize communication overhead, and \\textsc{FedMem}, a global model\nequipped with a $k$-nearest-neighbor ($k$NN) classifier that captures\nclient-specific distributional shifts to achieve personalization and overcome\ndata heterogeneity. Extensive experiments based on Conformer and Whisper\nbackbone models on CoVoST and GigaSpeech benchmarks show that our approach\nsignificantly reduces the communication overhead on all S2T tasks and\neffectively personalizes the global model to overcome data heterogeneity.",
        "date": "Not Found"
    },
    {
        "title": "Title:Analyzing and Improving Hardware Modeling of Accel-Sim",
        "authors": [
            "",
            "Authors:",
            "",
            "Rodrigo Huerta",
            ",",
            "Mojtaba Abaie Shoushtary",
            ",",
            "Antonio Gonz\u00e1lez",
            ""
        ],
        "abstract": "GPU architectures have become popular for executing general-purpose programs.\nTheir many-core architecture supports a large number of threads that run\nconcurrently to hide the latency among dependent instructions. In modern GPU\narchitectures, each SM/core is typically composed of several sub-cores, where\neach sub-core has its own independent pipeline.\nSimulators are a key tool for investigating novel concepts in computer\narchitecture. They must be performance-accurate and have a proper model related\nto the target hardware to explore the different bottlenecks properly.\nThis paper presents a wide analysis of different parts of Accel-sim, a\npopular GPGPU simulator, and some improvements of its model. First, we focus on\nthe front-end and developed a more realistic model. Then, we analyze the way\nthe result bus works and develop a more realistic one. Next, we describe the\ncurrent memory pipeline model and propose a model for a more cost-effective\ndesign. Finally, we discuss other areas of improvement of the simulator.",
        "date": "Not Found"
    },
    {
        "title": "Title:A locally statistical active contour model for SAR image segmentation  can be solved by denoising algorithms",
        "authors": [
            "",
            "Authors:",
            "",
            "Guangming Liu",
            ",",
            "Quanying Sun",
            ",",
            "Jing Liang",
            ",",
            "Qi Liu",
            ""
        ],
        "abstract": "In this paper, we propose a novel locally statistical variational active\ncontour model based on I-divergence-TV denoising model, which hybrides geodesic\nactive contour (GAC) model with active contours without edges (ACWE) model, and\ncan be used to segment images corrupted by multiplicative gamma noise. By\nadding a diffusion term into the level set evolution (LSE) equation of the\nproposed model, we construct a reaction-diffusion (RD) equation, which can\ngradually regularize the level set function (LSF) to be piecewise constant in\neach segment domain and gain the stable solution. We further transform the\nproposed model into classic ROF model by adding a proximity term. Inspired by a\nfast denoising algorithm proposed by Jia-Zhao recently, we propose two fast\nfixed point algorithms to solve SAR image segmentation question. Experimental\nresults for real SAR images show that the proposed image segmentation model can\nefficiently stop the contours at weak or blurred edges, and can automatically\ndetect the exterior and interior boundaries of images with multiplicative gamma\nnoise. The proposed FPRD1/FPRD2 models are about 1/2 (or less than) of the time\nrequired for the SBRD model based on the Split Bregman technique.",
        "date": "Not Found"
    },
    {
        "title": "Title:CLIP feature-based randomized control using images and text for multiple  tasks and robots",
        "authors": [
            "",
            "Authors:",
            "",
            "Kazuki Shibata",
            ",",
            "Hideki Deguchi",
            ",",
            "Shun Taguchi",
            ""
        ],
        "abstract": "This study presents a control framework leveraging vision language models\n(VLMs) for multiple tasks and robots. Notably, existing control methods using\nVLMs have achieved high performance in various tasks and robots in the training\nenvironment. However, these methods incur high costs for learning control\npolicies for tasks and robots other than those in the training environment.\nConsidering the application of industrial and household robots, learning in\nnovel environments where robots are introduced is challenging. To address this\nissue, we propose a control framework that does not require learning control\npolicies. Our framework combines the vision-language CLIP model with a\nrandomized control. CLIP computes the similarity between images and texts by\nembedding them in the feature space. This study employs CLIP to compute the\nsimilarity between camera images and text representing the target state. In our\nmethod, the robot is controlled by a randomized controller that simultaneously\nexplores and increases the similarity gradients. Moreover, we fine-tune the\nCLIP to improve the performance of the proposed method. Consequently, we\nconfirm the effectiveness of our approach through a multitask simulation and a\nreal robot experiment using a two-wheeled robot and robot arm.",
        "date": "Not Found"
    },
    {
        "title": "Title:Stability theory of TASE-Runge-Kutta methods with inexact Jacobian",
        "authors": [
            "",
            "Authors:",
            "",
            "D. Conte",
            ",",
            "J. Martin-Vaquero",
            ",",
            "G. Pagano",
            ",",
            "B. Paternoster",
            ""
        ],
        "abstract": "This paper analyzes the stability of the class of Time-Accurate and\nHighly-Stable Explicit Runge-Kutta (TASE-RK) methods, introduced in 2021 by\nBassenne et al. (J. Comput. Phys.) for the numerical solution of stiff Initial\nValue Problems (IVPs). Such numerical methods are easy to implement and require\nthe solution of a limited number of linear systems per step, whose coefficient\nmatrices involve the exact Jacobian $J$ of the problem. To significantly reduce\nthe computational cost of TASE-RK methods without altering their consistency\nproperties, it is possible to replace $J$ with a matrix $A$ (not necessarily\ntied to $J$) in their formulation, for instance fixed for a certain number of\nconsecutive steps or even constant. However, the stability properties of\nTASE-RK methods strongly depend on this choice, and so far have been studied\nassuming $A=J$.\nIn this manuscript, we theoretically investigate the conditional and\nunconditional stability of TASE-RK methods by considering arbitrary $A$. To\nthis end, we first split the Jacobian as $J=A+B$. Then, through the use of\nstability diagrams and their connections with the field of values, we analyze\nboth the case in which $A$ and $B$ are simultaneously diagonalizable and not.\nNumerical experiments, conducted on Partial Differential Equations (PDEs)\narising from applications, show the correctness and utility of the theoretical\nresults derived in the paper, as well as the good stability and efficiency of\nTASE-RK methods when $A$ is suitably chosen.",
        "date": "Not Found"
    },
    {
        "title": "Title:Polynomial approximations for the matrix logarithm with computation  graphs",
        "authors": [
            "",
            "Authors:",
            "",
            "Elias Jarlebring",
            ",",
            "Jorge Sastre",
            ",",
            "J. Javier Ib\u00e1\u00f1ez Gonz\u00e1lez",
            ""
        ],
        "abstract": "The most popular method for computing the matrix logarithm is a combination\nof the inverse scaling and squaring method in conjunction with a Pad\\'e\napproximation, sometimes accompanied by the Schur decomposition. The main\ncomputational effort lies in matrix-matrix multiplications and left matrix\ndivision. In this work we illustrate that the number of such operations can be\nsubstantially reduced, by using a graph based representation of an efficient\npolynomial evaluation scheme. A technique to analyze the rounding error is\nproposed, and backward error analysis is adapted. We provide substantial\nsimulations illustrating competitiveness both in terms of computation time and\nrounding errors.",
        "date": "Not Found"
    },
    {
        "title": "Title:Cross-Modality Perturbation Synergy Attack for Person Re-identification",
        "authors": [
            "",
            "Authors:",
            "",
            "Yunpeng Gong",
            ",",
            "others",
            ""
        ],
        "abstract": "In recent years, there has been significant research focusing on addressing\nsecurity concerns in single-modal person re-identification (ReID) systems that\nare based on RGB images. However, the safety of cross-modality scenarios, which\nare more commonly encountered in practical applications involving images\ncaptured by infrared cameras, has not received adequate attention. The main\nchallenge in cross-modality ReID lies in effectively dealing with visual\ndifferences between different modalities. For instance, infrared images are\ntypically grayscale, unlike visible images that contain color information.\nExisting attack methods have primarily focused on the characteristics of the\nvisible image modality, overlooking the features of other modalities and the\nvariations in data distribution among different modalities. This oversight can\npotentially undermine the effectiveness of these methods in image retrieval\nacross diverse modalities. This study represents the first exploration into the\nsecurity of cross-modality ReID models and proposes a universal perturbation\nattack specifically designed for cross-modality ReID. This attack optimizes\nperturbations by leveraging gradients from diverse modality data, thereby\ndisrupting the discriminator and reinforcing the differences between\nmodalities. We conducted experiments on two widely used cross-modality\ndatasets, namely RegDB and SYSU, which not only demonstrated the effectiveness\nof our method but also provided insights for future enhancements in the\nrobustness of cross-modality ReID systems.",
        "date": "Not Found"
    },
    {
        "title": "Title:Power in Numbers: Robust reading comprehension by finetuning with four  adversarial sentences per example",
        "authors": [
            "",
            "Authors:",
            "",
            "Ariel Marcus",
            ""
        ],
        "abstract": "Recent models have achieved human level performance on the Stanford Question\nAnswering Dataset when using F1 scores to evaluate the reading comprehension\ntask. Yet, teaching machines to comprehend text has not been solved in the\ngeneral case. By appending one adversarial sentence to the context paragraph,\npast research has shown that the F1 scores from reading comprehension models\ndrop almost in half. In this paper, I replicate past adversarial research with\na new model, ELECTRA-Small, and demonstrate that the new model's F1 score drops\nfrom 83.9% to 29.2%. To improve ELECTRA-Small's resistance to this attack, I\nfinetune the model on SQuAD v1.1 training examples with one to five adversarial\nsentences appended to the context paragraph. Like past research, I find that\nthe finetuned model on one adversarial sentence does not generalize well across\nevaluation datasets. However, when finetuned on four or five adversarial\nsentences the model attains an F1 score of more than 70% on most evaluation\ndatasets with multiple appended and prepended adversarial sentences. The\nresults suggest that with enough examples we can make models robust to\nadversarial attacks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Counterfactual Reasoning with Probabilistic Graphical Models for  Analyzing Socioecological Systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Rafael Caba\u00f1as",
            ",",
            "Ana D. Maldonado",
            ",",
            "Mar\u00eda Morales",
            ",",
            "Pedro A. Aguilera",
            ",",
            "Antonio Salmer\u00f3n",
            ""
        ],
        "abstract": "Causal and counterfactual reasoning are emerging directions in data science\nthat allow us to reason about hypothetical scenarios. This is particularly\nuseful in domains where experimental data are usually not available. In the\ncontext of environmental and ecological sciences, causality enables us, for\nexample, to predict how an ecosystem would respond to hypothetical\ninterventions. A structural causal model is a class of probabilistic graphical\nmodels for causality, which, due to its intuitive nature, can be easily\nunderstood by experts in multiple fields. However, certain queries, called\nunidentifiable, cannot be calculated in an exact and precise manner. This paper\nproposes applying a novel and recent technique for bounding unidentifiable\nqueries within the domain of socioecological systems. Our findings indicate\nthat traditional statistical analysis, including probabilistic graphical\nmodels, can identify the influence between variables. However, such methods do\nnot offer insights into the nature of the relationship, specifically whether it\ninvolves necessity or sufficiency. This is where counterfactual reasoning\nbecomes valuable.",
        "date": "Not Found"
    },
    {
        "title": "Title:Information sets from defining sets for Reed-Muller codes of first and  second order",
        "authors": [
            "",
            "Authors:",
            "",
            "Jos\u00e9 Joaqu\u00edn Bernal",
            ",",
            "Juan Jacobo Sim\u00f3n",
            ""
        ],
        "abstract": "Reed-Muller codes belong to the family of affine-invariant codes. As such\ncodes they have a defining set that determines them uniquely, and they are\nextensions of cyclic group codes. In this paper we identify those cyclic codes\nwith multidimensional abelian codes and we use the techniques introduced in\n\\cite{BS} to construct information sets for them from their defining set. For\nfirst and second order Reed-Muller codes, we describe a direct method to\nconstruct information sets in terms of their basic parameters.",
        "date": "Not Found"
    },
    {
        "title": "Title:VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text  Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Xianfu Cheng",
            ",",
            "Weixiao Zhou",
            ",",
            "Xiang Li",
            ",",
            "Xiaoming Chen",
            ",",
            "Jian Yang",
            ",",
            "Tongliang Li",
            ",",
            "Zhoujun Li",
            ""
        ],
        "abstract": "Scene Text Recognition (STR) is a challenging task that involves recognizing\ntext within images of natural scenes. Although current state-of-the-art models\nfor STR exhibit high performance, they typically suffer from low inference\nefficiency due to their reliance on hybrid architectures comprised of visual\nencoders and sequence decoders. In this work, we propose the VIsion Permutable\nextractor for fast and efficient scene Text Recognition (VIPTR), which achieves\nan impressive balance between high performance and rapid inference speeds in\nthe domain of STR. Specifically, VIPTR leverages a visual-semantic extractor\nwith a pyramid structure, characterized by multiple self-attention layers,\nwhile eschewing the traditional sequence decoder. This design choice results in\na lightweight and efficient model capable of handling inputs of varying sizes.\nExtensive experimental results on various standard datasets for both Chinese\nand English scene text recognition validate the superiority of VIPTR. Notably,\nthe VIPTR-T (Tiny) variant delivers highly competitive accuracy on par with\nother lightweight models and achieves SOTA inference speeds. Meanwhile, the\nVIPTR-L (Large) variant attains greater recognition accuracy, while maintaining\na low parameter count and favorable inference speed. Our proposed method\nprovides a compelling solution for the STR challenge, which blends high\naccuracy with efficiency and greatly benefits real-world applications requiring\nfast and reliable text recognition. The code is publicly available at\nhttps://github.com/cxfyxl/VIPTR.",
        "date": "Not Found"
    },
    {
        "title": "Title:Marrying Adapters and Mixup to Efficiently Enhance the Adversarial  Robustness of Pre-Trained Language Models for Text Classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Tuc Nguyen",
            ",",
            "Thai Le",
            ""
        ],
        "abstract": "Existing works show that augmenting training data of neural networks using\nboth clean and adversarial examples can enhance their generalizability under\nadversarial attacks. However, this training approach often leads to performance\ndegradation on clean inputs. Additionally, it requires frequent re-training of\nthe entire model to account for new attack types, resulting in significant and\ncostly computations. Such limitations make adversarial training mechanisms less\npractical, particularly for complex Pre-trained Language Models (PLMs) with\nmillions or even billions of parameters. To overcome these challenges while\nstill harnessing the theoretical benefits of adversarial training, this study\ncombines two concepts: (1) adapters, which enable parameter-efficient\nfine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs\ndata pairs. Intuitively, we propose to fine-tune PLMs through convex\ncombinations of non-data pairs of fine-tuned adapters, one trained with clean\nand another trained with adversarial examples. Our experiments show that the\nproposed method achieves the best trade-off between training efficiency and\npredictive performance, both with and without attacks compared to other\nbaselines on a variety of downstream tasks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Exposing Lip-syncing Deepfakes from Mouth Inconsistencies",
        "authors": [
            "",
            "Authors:",
            "",
            "Soumyya Kanti Datta",
            ",",
            "Shan Jia",
            ",",
            "Siwei Lyu",
            ""
        ],
        "abstract": "A lip-syncing deepfake is a digitally manipulated video in which a person's\nlip movements are created convincingly using AI models to match altered or\nentirely new audio. Lip-syncing deepfakes are a dangerous type of deepfakes as\nthe artifacts are limited to the lip region and more difficult to discern. In\nthis paper, we describe a novel approach, LIP-syncing detection based on mouth\nINConsistency (LIPINC), for lip-syncing deepfake detection by identifying\ntemporal inconsistencies in the mouth region. These inconsistencies are seen in\nthe adjacent frames and throughout the video. Our model can successfully\ncapture these irregularities and outperforms the state-of-the-art methods on\nseveral benchmark deepfake datasets.",
        "date": "Not Found"
    },
    {
        "title": "Title:Techniques for Authenticating Quantile Digests",
        "authors": [
            "",
            "Authors:",
            "",
            "Alessandro Scala",
            ""
        ],
        "abstract": "We investigate two possible techniques to authenticate the q-digest data\nstructure, along with a worst-case study of the computational complexity both\nin time and space of the proposed solutions, and considerations on the\nfeasibility of the presented approaches in real-world scenarios. We conclude\nthe discussion by presenting some considerations on the information complexity\nof the queries in the two proposed approaches, and by presenting some\ninteresting ideas that could be the subject of future studies on the topic.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Principled Graph Transformers",
        "authors": [
            "",
            "Authors:",
            "",
            "Luis M\u00fcller",
            ",",
            "Christopher Morris",
            ""
        ],
        "abstract": "Graph learning architectures based on the k-dimensional Weisfeiler-Leman\n(k-WL) hierarchy offer a theoretically well-understood expressive power.\nHowever, such architectures often fail to deliver solid predictive performance\non real-world tasks, limiting their practical impact. In contrast, global\nattention-based models such as graph transformers demonstrate strong\nperformance in practice, but comparing their expressive power with the k-WL\nhierarchy remains challenging, particularly since these architectures rely on\npositional or structural encodings for their expressivity and predictive\nperformance. To address this, we show that the recently proposed Edge\nTransformer, a global attention model operating on node pairs instead of nodes,\nhas at least 3-WL expressive power. Empirically, we demonstrate that the Edge\nTransformer surpasses other theoretically aligned architectures regarding\npredictive performance while not relying on positional or structural encodings.",
        "date": "Not Found"
    },
    {
        "title": "Title:Differentially Private Approval-Based Committee Voting",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhechen Li",
            ",",
            "Zimai Guo",
            ",",
            "Lirong Xia",
            ",",
            "Yongzhi Cao",
            ",",
            "Hanpin Wang",
            ""
        ],
        "abstract": "In this paper, we investigate tradeoffs between differential privacy (DP) and\nseveral voting axioms for approval-based committee voting, including\nproportionality, Pareto efficiency, Condorcet criterion, and strategyproofness.\nFor all the axioms except strategyproofness, we show their incompatibility with\nDP, and provide both upper and lower bounds for their tradeoffs with DP.\nFurthermore, we show that any $\\epsilon$-DP mechanism satisfies\n$e^{-\\epsilon}$-cardinality strategyproofness, and the satisfaction can be\nfurther improved if the mechanism satisfies monotonicity.",
        "date": "Not Found"
    },
    {
        "title": "Title:Interplay between Sensing and Communication in Cell-Free Massive MIMO  with URLLC Users",
        "authors": [
            "",
            "Authors:",
            "",
            "Zinat Behdad",
            ",",
            "\u00d6zlem Tu\u011ffe Demir",
            ",",
            "Ki Won Sung",
            ",",
            "Cicek Cavdar",
            ""
        ],
        "abstract": "This paper studies integrated sensing and communication (ISAC) in the\ndownlink of a cell-free massive multiple-input multiple-output (MIMO) system\nwith multi-static sensing and ultra-reliable low-latency communication (URLLC)\nusers. We propose a successive convex approximation-based power allocation\nalgorithm that maximizes energy efficiency while satisfying the sensing and\nURLLC requirements. In addition, we provide a new definition for network\navailability, which accounts for both sensing and URLLC requirements. The\nimpact of blocklength, sensing requirement, and required reliability as a\nfunction of decoding error probability on network availability and energy\nefficiency is investigated. The proposed power allocation algorithm is compared\nto a communication-centric approach where only the URLLC requirement is\nconsidered. It is shown that the URLLC-only approach is incapable of meeting\nsensing requirements, while the proposed ISAC algorithm fulfills both sensing\nand URLLC requirements, albeit with an associated increase in energy\nconsumption. This increment can be reduced up to 75% by utilizing additional\nsymbols for sensing. It is also demonstrated that larger blocklengths enhance\nnetwork availability and offer greater robustness against stringent reliability\nrequirements.",
        "date": "Not Found"
    },
    {
        "title": "Title:Spatial-Temporal Large Language Model for Traffic Prediction",
        "authors": [
            "",
            "Authors:",
            "",
            "Chenxi Liu",
            ",",
            "Sun Yang",
            ",",
            "Qianxiong Xu",
            ",",
            "Zhishuai Li",
            ",",
            "Cheng Long",
            ",",
            "Ziyue Li",
            ",",
            "Rui Zhao",
            ""
        ],
        "abstract": "Traffic prediction, a critical component for intelligent transportation\nsystems, endeavors to foresee future traffic at specific locations using\nhistorical data. Although existing traffic prediction models often emphasize\ndeveloping complex neural network structures, their accuracy has not seen\nimprovements accordingly. Recently, Large Language Models (LLMs) have shown\noutstanding capabilities in time series analysis. Differing from existing\nmodels, LLMs progress mainly through parameter expansion and extensive\npre-training while maintaining their fundamental structures. In this paper, we\npropose a Spatial-Temporal Large Language Model (ST-LLM) for traffic\nprediction. Specifically, ST-LLM redefines the timesteps at each location as\ntokens and incorporates a spatial-temporal embedding module to learn the\nspatial location and global temporal representations of tokens. Then these\nrepresentations are fused to provide each token with unified spatial and\ntemporal information. Furthermore, we propose a novel partially frozen\nattention strategy of the LLM, which is designed to capture spatial-temporal\ndependencies for traffic prediction. Comprehensive experiments on real traffic\ndatasets offer evidence that ST-LLM outperforms state-of-the-art models.\nNotably, the ST-LLM also exhibits robust performance in both few-shot and\nzero-shot prediction scenarios.",
        "date": "Not Found"
    },
    {
        "title": "Title:Residual Based Error Estimator for Chemical-Mechanically Coupled Battery  Active Particles",
        "authors": [
            "",
            "Authors:",
            "",
            "Raphael Schoof",
            ",",
            "Lennart Fl\u00fcr",
            ",",
            "Florian Tuschner",
            ",",
            "Willy D\u00f6rfler",
            ""
        ],
        "abstract": "Adaptive finite element methods are a powerful tool to obtain numerical\nsimulation results in a reasonable time. Due to complex chemical and mechanical\ncouplings in lithium-ion batteries, numerical simulations are very helpful to\ninvestigate promising new battery active materials such as amorphous silicon\nfeaturing a higher energy density than graphite. Based on a thermodynamically\nconsistent continuum model with large deformation and chemo-mechanically\ncoupled approach, we compare three different spatial adaptive refinement\nstrategies: Kelly-, gradient recovery- and residual based error estimation. For\nthe residual based case, the strong formulation of the residual is explicitly\nderived. With amorphous silicon as example material, we investigate two 3D\nrepresentative host particle geometries, reduced with symmetry assumptions to a\n1D unit interval and a 2D elliptical domain. Our numerical studies show that\nthe Kelly estimator overestimates the error, whereas the gradient recovery\nestimator leads to lower refinement levels and a good capture of the change of\nthe lithium flux. The residual based error estimator reveals a strong\ndependency on the cell error part which can be improved by a more suitable\nchoice of constants to be more efficient. In a 2D domain, the concentration has\na larger influence on the mesh distribution than the Cauchy stress.",
        "date": "Not Found"
    },
    {
        "title": "Title:The Role of Data Filtering in Open Source Software Ranking and Selection",
        "authors": [
            "",
            "Authors:",
            "",
            "Addi Malviya-Thakur",
            ",",
            "Audris Mockus",
            ""
        ],
        "abstract": "Faced with over 100M open source projects most empirical investigations\nselect a subset. Most research papers in leading venues investigated filtering\nprojects by some measure of popularity with explicit or implicit arguments that\nunpopular projects are not of interest, may not even represent \"real\" software\nprojects, or that less popular projects are not worthy of study. However, such\nfiltering may have enormous effects on the results of the studies if and\nprecisely because the sought-out response or prediction is in any way related\nto the filtering criteria.\nWe exemplify the impact of this practice on research outcomes: how filtering\nof projects listed on GitHub affects the assessment of their popularity. We\nrandomly sample over 100,000 repositories and use multiple regression to model\nthe number of stars (a proxy for popularity) based on the number of commits,\nthe duration of the project, the number of authors, and the number of core\ndevelopers. Comparing control with the entire dataset with a filtered model\nprojects having ten or more authors we find that while certain characteristics\nof the repository consistently predict popularity, the filtering process\nsignificantly alters the relation ships between these characteristics and the\nresponse. The number of commits exhibited a positive correlation with\npopularity in the control sample but showed a negative correlation in the\nfiltered sample. These findings highlight the potential biases introduced by\ndata filtering and emphasize the need for careful sample selection in empirical\nresearch of mining software repositories. We recommend that empirical work\nshould either analyze complete datasets such as World of Code, or employ\nstratified random sampling from a complete dataset to ensure that filtering is\nnot biasing the results.",
        "date": "Not Found"
    },
    {
        "title": "Title:Model Compression Techniques in Biometrics Applications: A Survey",
        "authors": [
            "",
            "Authors:",
            "",
            "Eduarda Caldeira",
            ",",
            "Pedro C. Neto",
            ",",
            "Marco Huber",
            ",",
            "Naser Damer",
            ",",
            "Ana F. Sequeira",
            ""
        ],
        "abstract": "The development of deep learning algorithms has extensively empowered\nhumanity's task automatization capacity. However, the huge improvement in the\nperformance of these models is highly correlated with their increasing level of\ncomplexity, limiting their usefulness in human-oriented applications, which are\nusually deployed in resource-constrained devices. This led to the development\nof compression techniques that drastically reduce the computational and memory\ncosts of deep learning models without significant performance degradation. This\npaper aims to systematize the current literature on this topic by presenting a\ncomprehensive survey of model compression techniques in biometrics\napplications, namely quantization, knowledge distillation and pruning. We\nconduct a critical analysis of the comparative value of these techniques,\nfocusing on their advantages and disadvantages and presenting suggestions for\nfuture work directions that can potentially improve the current methods.\nAdditionally, we discuss and analyze the link between model bias and model\ncompression, highlighting the need to direct compression research toward model\nfairness in future works.",
        "date": "Not Found"
    },
    {
        "title": "Title:Optimally truncated WKB approximation for the 1D stationary  Schr\u00f6dinger equation in the highly oscillatory regime",
        "authors": [
            "",
            "Authors:",
            "",
            "Anton Arnold",
            ",",
            "Christian Klein",
            ",",
            "Jannis K\u00f6rner",
            ",",
            "Jens Markus Melenk",
            ""
        ],
        "abstract": "This paper is dedicated to the efficient numerical computation of solutions\nto the 1D stationary Schr\\\"odinger equation in the highly oscillatory regime.\nWe compute an approximate solution based on the well-known WKB-ansatz, which\nrelies on an asymptotic expansion w.r.t. the small parameter $\\varepsilon$.\nAssuming that the coefficient in the equation is analytic, we derive an\nexplicit error estimate for the truncated WKB series, in terms of $\\varepsilon$\nand the truncation order $N$. For any fixed $\\varepsilon$, this allows to\ndetermine the optimal truncation order $N_{opt}$ which turns out to be\nproportional to $\\varepsilon^{-1}$. When chosen this way, the resulting error\nof the optimally truncated WKB series behaves like\n$\\mathcal{O}(\\varepsilon^{-2}\\exp(-r/\\varepsilon))$, with some parameter $r>0$.\nThe theoretical results established in this paper are confirmed by several\nnumerical examples.",
        "date": "Not Found"
    },
    {
        "title": "Title:Explicitly Disentangled Representations in Object-Centric Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Riccardo Majellaro",
            ",",
            "Jonathan Collu",
            ",",
            "Aske Plaat",
            ",",
            "Thomas M. Moerland",
            ""
        ],
        "abstract": "Extracting structured representations from raw visual data is an important\nand long-standing challenge in machine learning. Recently, techniques for\nunsupervised learning of object-centric representations have raised growing\ninterest. In this context, enhancing the robustness of the latent features can\nimprove the efficiency and effectiveness of the training of downstream tasks. A\npromising step in this direction is to disentangle the factors that cause\nvariation in the data. Previously, Invariant Slot Attention disentangled\nposition, scale, and orientation from the remaining features. Extending this\napproach, we focus on separating the shape and texture components. In\nparticular, we propose a novel architecture that biases object-centric models\ntoward disentangling shape and texture components into two non-overlapping\nsubsets of the latent space dimensions. These subsets are known a priori, hence\nbefore the training process. Experiments on a range of object-centric\nbenchmarks reveal that our approach achieves the desired disentanglement while\nalso numerically improving baseline performance in most cases. In addition, we\nshow that our method can generate novel textures for a specific object or\ntransfer textures between objects with distinct shapes.",
        "date": "Not Found"
    },
    {
        "title": "Title:Multi-Agent Reinforcement Learning for Maritime Operational Technology  Cyber Security",
        "authors": [
            "",
            "Authors:",
            "",
            "Alec Wilson",
            ",",
            "Ryan Menzies",
            ",",
            "Neela Morarji",
            ",",
            "David Foster",
            ",",
            "Marco Casassa Mont",
            ",",
            "Esin Turkbeyler",
            ",",
            "Lisa Gralewski",
            ""
        ],
        "abstract": "This paper demonstrates the potential for autonomous cyber defence to be\napplied on industrial control systems and provides a baseline environment to\nfurther explore Multi-Agent Reinforcement Learning's (MARL) application to this\nproblem domain. It introduces a simulation environment, IPMSRL, of a generic\nIntegrated Platform Management System (IPMS) and explores the use of MARL for\nautonomous cyber defence decision-making on generic maritime based IPMS\nOperational Technology (OT). OT cyber defensive actions are less mature than\nthey are for Enterprise IT. This is due to the relatively brittle nature of OT\ninfrastructure originating from the use of legacy systems, design-time\nengineering assumptions, and lack of full-scale modern security controls. There\nare many obstacles to be tackled across the cyber landscape due to continually\nincreasing cyber-attack sophistication and the limitations of traditional\nIT-centric cyber defence solutions. Traditional IT controls are rarely deployed\non OT infrastructure, and where they are, some threats aren't fully addressed.\nIn our experiments, a shared critic implementation of Multi Agent Proximal\nPolicy Optimisation (MAPPO) outperformed Independent Proximal Policy\nOptimisation (IPPO). MAPPO reached an optimal policy (episode outcome mean of\n1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome\nmean of 0.966 after one million timesteps. Hyperparameter tuning greatly\nimproved training performance. Across one million timesteps the tuned\nhyperparameters reached an optimal policy whereas the default hyperparameters\nonly managed to win sporadically, with most simulations resulting in a draw. We\ntested a real-world constraint, attack detection alert success, and found that\nwhen alert success probability is reduced to 0.75 or 0.9, the MARL defenders\nwere still able to win in over 97.5% or 99.5% of episodes, respectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Motion-Zero: Zero-Shot Moving Object Control Framework for  Diffusion-Based Video Generation",
        "authors": [
            "",
            "Authors:",
            "",
            "Changgu Chen",
            ",",
            "Junwei Shu",
            ",",
            "Lianggangxu Chen",
            ",",
            "Gaoqi He",
            ",",
            "Changbo Wang",
            ",",
            "Yang Li",
            ""
        ],
        "abstract": "Recent large-scale pre-trained diffusion models have demonstrated a powerful\ngenerative ability to produce high-quality videos from detailed text\ndescriptions. However, exerting control over the motion of objects in videos\ngenerated by any video diffusion model is a challenging problem. In this paper,\nwe propose a novel zero-shot moving object trajectory control framework,\nMotion-Zero, to enable a bounding-box-trajectories-controlled text-to-video\ndiffusion model.To this end, an initial noise prior module is designed to\nprovide a position-based prior to improve the stability of the appearance of\nthe moving object and the accuracy of position. In addition, based on the\nattention map of the U-net, spatial constraints are directly applied to the\ndenoising process of diffusion models, which further ensures the positional and\nspatial consistency of moving objects during the inference. Furthermore,\ntemporal consistency is guaranteed with a proposed shift temporal attention\nmechanism. Our method can be flexibly applied to various state-of-the-art video\ndiffusion models without any training process. Extensive experiments\ndemonstrate our proposed method can control the motion trajectories of objects\nand generate high-quality videos.",
        "date": "Not Found"
    },
    {
        "title": "Title:Importance-Aware Image Segmentation-based Semantic Communication for  Autonomous Driving",
        "authors": [
            "",
            "Authors:",
            "",
            "Jie Lv",
            ",",
            "Haonan Tong",
            ",",
            "Qiang Pan",
            ",",
            "Zhilong Zhang",
            ",",
            "Xinxin He",
            ",",
            "Tao Luo",
            ",",
            "Changchuan Yin",
            ""
        ],
        "abstract": "This article studies the problem of image segmentation-based semantic\ncommunication in autonomous driving. In real traffic scenes, detecting the key\nobjects (e.g., vehicles, pedestrians and obstacles) is more crucial than that\nof other objects to guarantee driving safety. Therefore, we propose a vehicular\nimage segmentation-oriented semantic communication system, termed VIS-SemCom,\nwhere image segmentation features of important objects are transmitted to\nreduce transmission redundancy. First, to accurately extract image semantics,\nwe develop a semantic codec based on Swin Transformer architecture, which\nexpands the perceptual field thus improving the segmentation accuracy. Next, we\npropose a multi-scale semantic extraction scheme via assigning the number of\nSwin Transformer blocks for diverse resolution features, thus highlighting the\nimportant objects' accuracy. Furthermore, the importance-aware loss is invoked\nto emphasize the important objects, and an online hard sample mining (OHEM)\nstrategy is proposed to handle small sample issues in the dataset. Experimental\nresults demonstrate that the proposed VIS-SemCom can achieve a coding gain of\nnearly 6 dB with a 60% mean intersection over union (mIoU), reduce the\ntransmitted data amount by up to 70% with a 60% mIoU, and improve the\nsegmentation intersection over union (IoU) of important objects by 4%, compared\nto traditional transmission scheme.",
        "date": "Not Found"
    },
    {
        "title": "Title:A novel hybrid time-varying graph neural network for traffic flow  forecasting",
        "authors": [
            "",
            "Authors:",
            "",
            "Ben Ao Dai",
            ",",
            "Bao-Lin Ye",
            ""
        ],
        "abstract": "Real-time and accurate traffic flow prediction is the foundation for ensuring\nthe efficient operation of intelligent transportation systems.In existing\ntraffic flow prediction methods based on graph neural networks (GNNs),\npre-defined graphs were usually used to describe the spatial correlations of\ndifferent traffic nodes in urban road networks. However, the ability of\npre-defined graphs used to describe spatial correlation was limited by prior\nknowledge and graph generation methods. Although time-varying graphs based on\ndata-driven learning can partially overcome the drawbacks of pre-defined\ngraphs, the learning ability of existing adaptive graphs was limited. For\nexample, time-varying graphs cannot adequately capture the inherent spatial\ncorrelations in traffic flow data.In order to solve these problems, we have\nproposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow\nprediction.",
        "date": "Not Found"
    },
    {
        "title": "Title:Model-Assisted Learning for Adaptive Cooperative Perception of Connected  Autonomous Vehicles",
        "authors": [
            "",
            "Authors:",
            "",
            "Kaige Qu",
            ",",
            "Weihua Zhuang",
            ",",
            "Qiang Ye",
            ",",
            "Wen Wu",
            ",",
            "Xuemin Shen",
            ""
        ],
        "abstract": "Cooperative perception (CP) is a key technology to facilitate consistent and\naccurate situational awareness for connected and autonomous vehicles (CAVs). To\ntackle the network resource inefficiency issue in traditional broadcast-based\nCP, unicast-based CP has been proposed to associate CAV pairs for cooperative\nperception via vehicle-to-vehicle transmission. In this paper, we investigate\nunicast-based CP among CAV pairs. With the consideration of dynamic perception\nworkloads and channel conditions due to vehicle mobility and dynamic radio\nresource availability, we propose an adaptive cooperative perception scheme for\nCAV pairs in a mixed-traffic autonomous driving scenario with both CAVs and\nhuman-driven vehicles. We aim to determine when to switch between cooperative\nperception and stand-alone perception for each CAV pair, and allocate\ncommunication and computing resources to cooperative CAV pairs for maximizing\nthe computing efficiency gain under perception task delay requirements. A\nmodel-assisted multi-agent reinforcement learning (MARL) solution is developed,\nwhich integrates MARL for an adaptive CAV cooperation decision and an\noptimization model for communication and computing resource allocation.\nSimulation results demonstrate the effectiveness of the proposed scheme in\nachieving high computing efficiency gain, as compared with benchmark schemes.",
        "date": "Not Found"
    },
    {
        "title": "Title:DISTINQT: A Distributed Privacy Aware Learning Framework for QoS  Prediction for Future Mobile and Wireless Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Nikolaos Koursioumpas",
            ",",
            "Lina Magoula",
            ",",
            "Ioannis Stavrakakis",
            ",",
            "Nancy Alonistioti",
            ",",
            "M. A. Gutierrez-Estevez",
            ",",
            "Ramin Khalili",
            ""
        ],
        "abstract": "Beyond 5G and 6G networks are expected to support new and challenging use\ncases and applications that depend on a certain level of Quality of Service\n(QoS) to operate smoothly. Predicting the QoS in a timely manner is of high\nimportance, especially for safety-critical applications as in the case of\nvehicular communications. Although until recent years the QoS prediction has\nbeen carried out by centralized Artificial Intelligence (AI) solutions, a\nnumber of privacy, computational, and operational concerns have emerged.\nAlternative solutions have been surfaced (e.g. Split Learning, Federated\nLearning), distributing AI tasks of reduced complexity across nodes, while\npreserving the privacy of the data. However, new challenges rise when it comes\nto scalable distributed learning approaches, taking into account the\nheterogeneous nature of future wireless networks. The current work proposes\nDISTINQT, a privacy-aware distributed learning framework for QoS prediction.\nOur framework supports multiple heterogeneous nodes, in terms of data types and\nmodel architectures, by sharing computations across them. This, enables the\nincorporation of diverse knowledge into a sole learning process that will\nenhance the robustness and generalization capabilities of the final QoS\nprediction model. DISTINQT also contributes to data privacy preservation by\nencoding any raw input data into a non-linear latent representation before any\ntransmission. Evaluation results showcase that our framework achieves a\nstatistically identical performance compared to its centralized version and an\naverage performance improvement of up to 65% against six state-of-the-art\ncentralized baseline solutions in the Tele-Operated Driving use case.",
        "date": "Not Found"
    },
    {
        "title": "Title:VMamba: Visual State Space Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Yue Liu",
            ",",
            "Yunjie Tian",
            ",",
            "Yuzhong Zhao",
            ",",
            "Hongtian Yu",
            ",",
            "Lingxi Xie",
            ",",
            "Yaowei Wang",
            ",",
            "Qixiang Ye",
            ",",
            "Yunfan Liu",
            ""
        ],
        "abstract": "Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as\nthe two most popular foundation models for visual representation learning.\nWhile CNNs exhibit remarkable scalability with linear complexity w.r.t. image\nresolution, ViTs surpass them in fitting capabilities despite contending with\nquadratic complexity. A closer inspection reveals that ViTs achieve superior\nvisual modeling performance through the incorporation of global receptive\nfields and dynamic weights. This observation motivates us to propose a novel\narchitecture that inherits these components while enhancing computational\nefficiency. To this end, we draw inspiration from the recently introduced state\nspace model and propose the Visual State Space Model (VMamba), which achieves\nlinear complexity without sacrificing global receptive fields. To address the\nencountered direction-sensitive issue, we introduce the Cross-Scan Module (CSM)\nto traverse the spatial domain and convert any non-causal visual image into\norder patch sequences. Extensive experimental results substantiate that VMamba\nnot only demonstrates promising capabilities across various visual perception\ntasks, but also exhibits more pronounced advantages over established benchmarks\nas the image resolution increases. Source code has been available at\nhttps://github.com/MzeroMiko/VMamba.",
        "date": "Not Found"
    },
    {
        "title": "Title:SHINOBI: Shape and Illumination using Neural Object Decomposition via  BRDF Optimization In-the-wild",
        "authors": [
            "",
            "Authors:",
            "",
            "Andreas Engelhardt",
            ",",
            "Amit Raj",
            ",",
            "Mark Boss",
            ",",
            "Yunzhi Zhang",
            ",",
            "Abhishek Kar",
            ",",
            "Yuanzhen Li",
            ",",
            "Deqing Sun",
            ",",
            "Ricardo Martin Brualla",
            ",",
            "Jonathan T. Barron",
            ",",
            "Hendrik P. A. Lensch",
            ",",
            "Varun Jampani",
            ""
        ],
        "abstract": "We present SHINOBI, an end-to-end framework for the reconstruction of shape,\nmaterial, and illumination from object images captured with varying lighting,\npose, and background. Inverse rendering of an object based on unconstrained\nimage collections is a long-standing challenge in computer vision and graphics\nand requires a joint optimization over shape, radiance, and pose. We show that\nan implicit shape representation based on a multi-resolution hash encoding\nenables faster and robust shape reconstruction with joint camera alignment\noptimization that outperforms prior work. Further, to enable the editing of\nillumination and object reflectance (i.e. material) we jointly optimize BRDF\nand illumination together with the object's shape. Our method is class-agnostic\nand works on in-the-wild image collections of objects to produce relightable 3D\nassets for several use cases such as AR/VR, movies, games, etc. Project page:\nhttps://shinobi.aengelhardt.com Video:\nhttps://www.youtube.com/watch?v=iFENQ6AcYd8&feature=youtu.be",
        "date": "Not Found"
    },
    {
        "title": "Title:DualTake: Predicting Takeovers across Mobilities for Future Personalized  Mobility Services",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhaobo Zheng",
            ",",
            "Kumar Akash",
            ",",
            "Teruhisa Misu",
            ""
        ],
        "abstract": "A hybrid society is expected to emerge in the near future, with different\nmobilities interacting together, including cars, micro-mobilities, pedestrians,\nand robots. People may utilize multiple types of mobilities in their daily\nlives. As vehicle automation advances, driver modeling flourishes to provide\npersonalized intelligent services. Thus, modeling drivers across mobilities\nwould pave the road for future society mobility-as-a-service, and it is\nparticularly interesting to predict driver behaviors in newer mobilities with\ntraditional mobility data. In this work, we present takeover prediction on a\nmicro-mobility, with car simulation data.The promising model performance\ndemonstrates the feasibility of driver modeling across mobilities, as the first\nin the field.",
        "date": "Not Found"
    },
    {
        "title": "Title:Comprehensive OOD Detection Improvements",
        "authors": [
            "",
            "Authors:",
            "",
            "Anish Lakkapragada",
            ",",
            "Amol Khanna",
            ",",
            "Edward Raff",
            ",",
            "Nathan Inkawhich",
            ""
        ],
        "abstract": "As machine learning becomes increasingly prevalent in impactful decisions,\nrecognizing when inference data is outside the model's expected input\ndistribution is paramount for giving context to predictions.\nOut-of-distribution (OOD) detection methods have been created for this task.\nSuch methods can be split into representation-based or logit-based methods from\nwhether they respectively utilize the model's embeddings or predictions for OOD\ndetection. In contrast to most papers which solely focus on one such group, we\naddress both. We employ dimensionality reduction on feature embeddings in\nrepresentation-based methods for both time speedups and improved performance.\nAdditionally, we propose DICE-COL, a modification of the popular logit-based\nmethod Directed Sparsification (DICE) that resolves an unnoticed flaw. We\ndemonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark\nframework, where they significantly improve performance and set\nstate-of-the-art results.",
        "date": "Not Found"
    },
    {
        "title": "Title:Neural Echos: Depthwise Convolutional Filters Replicate Biological  Receptive Fields",
        "authors": [
            "",
            "Authors:",
            "",
            "Zahra Babaiee",
            ",",
            "Peyman M. Kiasari",
            ",",
            "Daniela Rus",
            ",",
            "Radu Grosu",
            ""
        ],
        "abstract": "In this study, we present evidence suggesting that depthwise convolutional\nkernels are effectively replicating the structural intricacies of the\nbiological receptive fields observed in the mammalian retina. We provide\nanalytics of trained kernels from various state-of-the-art models\nsubstantiating this evidence. Inspired by this intriguing discovery, we propose\nan initialization scheme that draws inspiration from the biological receptive\nfields. Experimental analysis of the ImageNet dataset with multiple CNN\narchitectures featuring depthwise convolutions reveals a marked enhancement in\nthe accuracy of the learned model when initialized with biologically derived\nweights. This underlies the potential for biologically inspired computational\nmodels to further our understanding of vision processing systems and to improve\nthe efficacy of convolutional networks.",
        "date": "Not Found"
    },
    {
        "title": "Title:Comparing Traditional and LLM-based Search for Image Geolocation",
        "authors": [
            "",
            "Authors:",
            "",
            "Albatool Wazzan",
            ",",
            "Stephen MacNeil",
            ",",
            "Richard Souvenir",
            ""
        ],
        "abstract": "Web search engines have long served as indispensable tools for information\nretrieval; user behavior and query formulation strategies have been well\nstudied. The introduction of search engines powered by large language models\n(LLMs) suggested more conversational search and new types of query strategies.\nIn this paper, we compare traditional and LLM-based search for the task of\nimage geolocation, i.e., determining the location where an image was captured.\nOur work examines user interactions, with a particular focus on query\nformulation strategies. In our study, 60 participants were assigned either\ntraditional or LLM-based search engines as assistants for geolocation.\nParticipants using traditional search more accurately predicted the location of\nthe image compared to those using the LLM-based search. Distinct strategies\nemerged between users depending on the type of assistant. Participants using\nthe LLM-based search issued longer, more natural language queries, but had\nshorter search sessions. When reformulating their search queries, traditional\nsearch participants tended to add more terms to their initial queries, whereas\nparticipants using the LLM-based search consistently rephrased their initial\nqueries.",
        "date": "Not Found"
    },
    {
        "title": "Title:Transfer Learning in Human Activity Recognition: A Survey",
        "authors": [
            "",
            "Authors:",
            "",
            "Sourish Gunesh Dhekane",
            ",",
            "Thomas Ploetz",
            ""
        ],
        "abstract": "Sensor-based human activity recognition (HAR) has been an active research\narea, owing to its applications in smart environments, assisted living,\nfitness, healthcare, etc. Recently, deep learning based end-to-end training has\nresulted in state-of-the-art performance in domains such as computer vision and\nnatural language, where large amounts of annotated data are available. However,\nlarge quantities of annotated data are not available for sensor-based HAR.\nMoreover, the real-world settings on which the HAR is performed differ in terms\nof sensor modalities, classification tasks, and target users. To address this\nproblem, transfer learning has been employed extensively. In this survey, we\nfocus on these transfer learning methods in the application domains of smart\nhome and wearables-based HAR. In particular, we provide a problem-solution\nperspective by categorizing and presenting the works in terms of their\ncontributions and the challenges they address. We also present an updated view\nof the state-of-the-art for both application domains. Based on our analysis of\n205 papers, we highlight the gaps in the literature and provide a roadmap for\naddressing them. This survey provides a reference to the HAR community, by\nsummarizing the existing works and providing a promising research agenda.",
        "date": "Not Found"
    },
    {
        "title": "Title:Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on  Data-to-Text Generation",
        "authors": [
            "",
            "Authors:",
            "",
            "Zden\u011bk Kasner",
            ",",
            "Ond\u0159ej Du\u0161ek",
            ""
        ],
        "abstract": "We investigate to which extent open large language models (LLMs) can generate\ncoherent and relevant text from structured data. To prevent bias from\nbenchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc\nbenchmark for five data-to-text (D2T) generation tasks, consisting of\nstructured data records in standard formats gathered from public APIs. We\nleverage reference-free evaluation metrics and LLMs' in-context learning\ncapabilities, allowing us to test the models with no human-written references.\nOur evaluation focuses on annotating semantic accuracy errors on token-level,\ncombining human annotators and a metric based on GPT-4. Our systematic\nexamination of the models' behavior across domains and tasks suggests that\nstate-of-the-art open LLMs with 7B parameters can generate fluent and coherent\ntext from various standard data formats in zero-shot settings. However, we also\nshow that semantic accuracy of the outputs remains a major issue: on our\nbenchmark, 80% of outputs of open LLMs contain a semantic error according to\nhuman annotators (91% according to GPT-4). Our code, data, and model outputs\nare available at https://d2t-llm.github.io.",
        "date": "Not Found"
    },
    {
        "title": "Title:Fast Kronecker Matrix-Matrix Multiplication on GPUs",
        "authors": [
            "",
            "Authors:",
            "",
            "Abhinav Jangda",
            ",",
            "Mohit Yadav",
            ""
        ],
        "abstract": "Kronecker Matrix-Matrix Multiplication (Kron-Matmul) is the multiplication of\na matrix with the Kronecker Product of several smaller matrices. Kron-Matmul is\na core operation for many scientific and machine learning computations.\nState-of-the-art Kron-Matmul implementations utilize existing tensor algebra\noperations, such as matrix multiplication, transpose, and tensor matrix\nmultiplication. However, this design choice prevents several Kron-Matmul\nspecific optimizations, thus, leaving significant performance on the table. To\naddress this issue, we present FastKron, an efficient technique for Kron-Matmul\non single and multiple GPUs. FastKron is independent of linear algebra\noperations enabling several new optimizations for Kron-Matmul. Thus, it\nperforms up to 40.7x and 7.85x faster than existing implementations on 1 and 16\nGPUs respectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through  Text Reconstruction",
        "authors": [
            "",
            "Authors:",
            "",
            "Qingyun Wang",
            ",",
            "Zixuan Zhang",
            ",",
            "Hongxiang Li",
            ",",
            "Xuan Liu",
            ",",
            "Jiawei Han",
            ",",
            "Heng Ji",
            ",",
            "Huimin Zhao",
            ""
        ],
        "abstract": "Fine-grained few-shot entity extraction in the chemical domain faces two\nunique challenges. First, compared with entity extraction tasks in the general\ndomain, sentences from chemical papers usually contain more entities. Moreover,\nentity extraction models usually have difficulty extracting entities of\nlong-tailed types. In this paper, we propose Chem-FINESE, a novel\nsequence-to-sequence (seq2seq) based few-shot entity extraction approach, to\naddress these two challenges. Our Chem-FINESE has two components: a seq2seq\nentity extractor to extract named entities from the input sentence and a\nseq2seq self-validation module to reconstruct the original input sentence from\nextracted entities. Inspired by the fact that a good entity extraction system\nneeds to extract entities faithfully, our new self-validation module leverages\nentity extraction results to reconstruct the original input sentence. Besides,\nwe design a new contrastive loss to reduce excessive copying during the\nextraction process. Finally, we release ChemNER+, a new fine-grained chemical\nentity extraction dataset that is annotated by domain experts with the ChemNER\nschema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets\nshow that our newly proposed framework has contributed up to 8.26% and 6.84%\nabsolute F1-score gains respectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Divide and not forget: Ensemble of selectively trained experts in  Continual Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Grzegorz Rype\u015b\u0107",
            ",",
            "Sebastian Cygert",
            ",",
            "Valeriya Khan",
            ",",
            "Tomasz Trzci\u0144ski",
            ",",
            "Bartosz Zieli\u0144ski",
            ",",
            "Bart\u0142omiej Twardowski",
            ""
        ],
        "abstract": "Class-incremental learning is becoming more popular as it helps models widen\ntheir applicability while not forgetting what they already know. A trend in\nthis area is to use a mixture-of-expert technique, where different models work\ntogether to solve the task. However, the experts are usually trained all at\nonce using whole task data, which makes them all prone to forgetting and\nincreasing computational burden. To address this limitation, we introduce a\nnovel approach named SEED. SEED selects only one, the most optimal expert for a\nconsidered task, and uses data from this task to fine-tune only this expert.\nFor this purpose, each expert represents each class with a Gaussian\ndistribution, and the optimal expert is selected based on the similarity of\nthose distributions. Consequently, SEED increases diversity and heterogeneity\nwithin the experts while maintaining the high stability of this ensemble\nmethod. The extensive experiments demonstrate that SEED achieves\nstate-of-the-art performance in exemplar-free settings across various\nscenarios, showing the potential of expert diversification through data in\ncontinual learning.",
        "date": "Not Found"
    },
    {
        "title": "Title:Impact of Flexible and Bidirectional Charging in Medium- and Heavy-Duty  Trucks on California's Decarbonization Pathway",
        "authors": [
            "",
            "Authors:",
            "",
            "Osten Anderson",
            ",",
            "Wanshi Hong",
            ",",
            "Bin Wang",
            ",",
            "Nanpeng Yu",
            ""
        ],
        "abstract": "California has committed to ambitious decarbonization targets across multiple\nsectors, including decarbonizing the electrical grid by 2045. In addition, the\nmedium- and heavy-duty truck fleets are expected to see rapid electrification\nover the next two decades. Considering these two pathways in tandem is critical\nfor ensuring cost optimality and reliable power system operation. In\nparticular, we examine the potential cost savings of electrical generation\ninfrastructure by enabling flexible charging and bidirectional charging for\nthese trucks. We also examine costs adjacent to enabling these services, such\nas charger upgrades and battery degradation. We deploy a large mixed-integer\ndecarbonization planning model to quantify the costs associated with the\nelectric generation decarbonization pathway. Example scenarios governing truck\ndriving and charging behaviors are implemented to reveal the sensitivity of\ntemporal driving patterns. Our experiments show that cost savings on the order\nof multiple billions of dollars are possible by enabling flexible and\nbidirectional charging in medium- and heavy-duty trucks in California.",
        "date": "Not Found"
    },
    {
        "title": "Title:Maximal-Capacity Discrete Memoryless Channel Identification",
        "authors": [
            "",
            "Authors:",
            "",
            "Maximilian Egger",
            ",",
            "Rawad Bitar",
            ",",
            "Antonia Wachter-Zeh",
            ",",
            "Deniz G\u00fcnd\u00fcz",
            ",",
            "Nir Weinberger",
            ""
        ],
        "abstract": "The problem of identifying the channel with the highest capacity among\nseveral discrete memoryless channels (DMCs) is considered. The problem is cast\nas a pure-exploration multi-armed bandit problem, which follows the practical\nuse of training sequences to sense the communication channel statistics. A\ncapacity estimator is proposed and tight confidence bounds on the estimator\nerror are derived. Based on this capacity estimator, a gap-elimination\nalgorithm termed BestChanID is proposed, which is oblivious to the\ncapacity-achieving input distribution and is guaranteed to output the DMC with\nthe largest capacity, with a desired confidence. Furthermore, two additional\nalgorithms NaiveChanSel and MedianChanEl, that output with certain confidence a\nDMC with capacity close to the maximal, are introduced. Each of those\nalgorithms is beneficial in a different regime and can be used as a subroutine\nin BestChanID. The sample complexity of all algorithms is analyzed as a\nfunction of the desired confidence parameter, the number of channels, and the\nchannels' input and output alphabet sizes. The cost of best channel\nidentification is shown to scale quadratically with the alphabet size, and a\nfundamental lower bound for the required number of channel senses to identify\nthe best channel with a certain confidence is derived.",
        "date": "Not Found"
    },
    {
        "title": "Title:Effective Communication of Scientific Results",
        "authors": [
            "",
            "Authors:",
            "",
            "Jos\u00e9 Nelson Amaral",
            ""
        ],
        "abstract": "Communication is essential for the advancement of Science. Technology\nadvances and the proliferation of personal devices have changed the ways in\nwhich people communicate in all aspects of life. Scientific communication has\nalso been profoundly affected by such changes, and thus it is important to\nreflect on effective ways to communicate scientific results to scientists that\nare flooded with information. This article advocates for receiver-oriented\ncommunication in Science, discusses how effective oral presentations should be\nprepared and delivered, provides advice on the thought process that can lead to\nscientific papers that communicate effectively, discusses suitable methodology\nto produce experimental data that is relevant and offers advice on how to\npresent such data in ways that lead to the formulation of correct claims that\nare supported by the data.",
        "date": "Not Found"
    },
    {
        "title": "Title:Eclectic Rule Extraction for Explainability of Deep Neural Network based  Intrusion Detection Systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Jesse Ables",
            ",",
            "Nathaniel Childers",
            ",",
            "William Anderson",
            ",",
            "Sudip Mittal",
            ",",
            "Shahram Rahimi",
            ",",
            "Ioana Banicescu",
            ",",
            "Maria Seale",
            ""
        ],
        "abstract": "This paper addresses trust issues created from the ubiquity of black box\nalgorithms and surrogate explainers in Explainable Intrusion Detection Systems\n(X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance\ntransparency, black box surrogate explainers, such as Local Interpretable\nModel-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are\ndifficult to trust. The black box nature of these surrogate explainers makes\nthe process behind explanation generation opaque and difficult to understand.\nTo avoid this problem, one can use transparent white box algorithms such as\nRule Extraction (RE). There are three types of RE algorithms: pedagogical,\ndecompositional, and eclectic. Pedagogical methods offer fast but untrustworthy\nwhite-box explanations, while decompositional RE provides trustworthy\nexplanations with poor scalability. This work explores eclectic rule\nextraction, which strikes a balance between scalability and trustworthiness. By\ncombining techniques from pedagogical and decompositional approaches, eclectic\nrule extraction leverages the advantages of both, while mitigating some of\ntheir drawbacks. The proposed Hybrid X-IDS architecture features eclectic RE as\na white box surrogate explainer for black box Deep Neural Networks (DNN). The\npresented eclectic RE algorithm extracts human-readable rules from hidden\nlayers, facilitating explainable and trustworthy rulesets. Evaluations on\nUNSW-NB15 and CIC-IDS-2017 datasets demonstrate the algorithm's ability to\ngenerate rulesets with 99.9% accuracy, mimicking DNN outputs. The contributions\nof this work include the hybrid X-IDS architecture, the eclectic rule\nextraction algorithm applicable to intrusion detection datasets, and a thorough\nanalysis of performance and explainability, demonstrating the trade-offs\ninvolved in rule extraction speed and accuracy.",
        "date": "Not Found"
    },
    {
        "title": "Title:MM-Interleaved: Interleaved Image-Text Generative Modeling via  Multi-modal Feature Synchronizer",
        "authors": [
            "",
            "Authors:",
            "",
            "Changyao Tian",
            ",",
            "Xizhou Zhu",
            ",",
            "Yuwen Xiong",
            ",",
            "Weiyun Wang",
            ",",
            "Zhe Chen",
            ",",
            "Wenhai Wang",
            ",",
            "Yuntao Chen",
            ",",
            "Lewei Lu",
            ",",
            "Tong Lu",
            ",",
            "Jie Zhou",
            ",",
            "Hongsheng Li",
            ",",
            "Yu Qiao",
            ",",
            "Jifeng Dai",
            ""
        ],
        "abstract": "Developing generative models for interleaved image-text data has both\nresearch and practical value. It requires models to understand the interleaved\nsequences and subsequently generate images and text. However, existing attempts\nare limited by the issue that the fixed number of visual tokens cannot\nefficiently capture image details, which is particularly problematic in the\nmulti-image scenarios. To address this, this paper presents MM-Interleaved, an\nend-to-end generative model for interleaved image-text data. It introduces a\nmulti-scale and multi-image feature synchronizer module, allowing direct access\nto fine-grained image features in the previous context during the generation\nprocess. MM-Interleaved is end-to-end pre-trained on both paired and\ninterleaved image-text corpora. It is further enhanced through a supervised\nfine-tuning phase, wherein the model improves its ability to follow complex\nmulti-modal instructions. Experiments demonstrate the versatility of\nMM-Interleaved in recognizing visual details following multi-modal instructions\nand generating consistent images following both textual and visual conditions.\nCode and models are available at\n\\url{https://github.com/OpenGVLab/MM-Interleaved}.",
        "date": "Not Found"
    },
    {
        "title": "Title:Synchronization and Control of Chaotic Spur Gear System Using Type-II  Fuzzy Controller Optimized via Whale Optimization Algorithm",
        "authors": [
            "",
            "Authors:",
            "",
            "Farnaz Rezay Morsagh",
            ",",
            "Mehdi Siahi",
            ",",
            "Soudabeh Soleymani",
            ""
        ],
        "abstract": "Interval type-II Fuzzy Inference System (FIS) assumes a crucial role in\ndetermining the coefficients of the PID controller, thereby augmenting the\ncontroller's flexibility. Controlling chaotic systems presents inherent\nchallenges and difficulties due to their sensitivity to initial conditions and\nthe intricate dynamics that require precise and adaptive control strategies.\nThis paper offers an exhaustive exploration into the coordination and\nregulation of a chaotic spur gear system, employing a Type-II Fuzzy Controller.\nThe initial control parameters of the PID controller undergo optimization using\nthe Whale Optimization Algorithm (WOA) to increase the overall system\nperformance. The adaptability and strength of the suggested control system are\ntested in various scenarios, covering diverse reference inputs and\nuncertainties. The investigation comprehensively assesses the operational\nefficacy of the formulated controller, contrasting its performance with other\nmethodologies. The outcomes highlight the impressive efficiency of the\nsuggested strategy, confirming its supremacy in attaining synchronization and\ncontrol within the turbulent spur gear system under demanding circumstances",
        "date": "Not Found"
    },
    {
        "title": "Title:Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction",
        "authors": [
            "",
            "Authors:",
            "",
            "Anup Shakya",
            ",",
            "Vasile Rus",
            ",",
            "Deepak Venugopal",
            ""
        ],
        "abstract": "Predicting the strategy (sequence of concepts) that a student is likely to\nuse in problem-solving helps Adaptive Instructional Systems (AISs) better adapt\nthemselves to different types of learners based on their learning abilities.\nThis can lead to a more dynamic, engaging, and personalized experience for\nstudents. To scale up training a prediction model (such as LSTMs) over\nlarge-scale education datasets, we develop a non-parametric approach to cluster\nsymmetric instances in the data. Specifically, we learn a representation based\non Node2Vec that encodes symmetries over mastery or skill level since, to solve\na problem, it is natural that a student's strategy is likely to involve\nconcepts in which they have gained mastery. Using this representation, we use\nDP-Means to group symmetric instances through a coarse-to-fine refinement of\nthe clusters. We apply our model to learn strategies for Math learning from\nlarge-scale datasets from MATHia, a leading AIS for middle-school math\nlearning. Our results illustrate that our approach can consistently achieve\nhigh accuracy using a small sample that is representative of the full dataset.\nFurther, we show that this approach helps us learn strategies with high\naccuracy for students at different skill levels, i.e., leveraging symmetries\nimproves fairness in the prediction model.",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving automatic detection of driver fatigue and distraction using  machine learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Dongjiang Wu",
            ""
        ],
        "abstract": "Changes and advances in information technology have played an important role\nin the development of intelligent vehicle systems in recent years. Driver\nfatigue and distracted driving are important factors in traffic accidents.\nThus, onboard monitoring of driving behavior has become a crucial component of\nadvanced driver assistance systems for intelligent vehicles. In this article,\nwe present techniques for simultaneously detecting fatigue and distracted\ndriving behaviors using vision-based and machine learning-based approaches. In\ndriving fatigue detection, we use facial alignment networks to identify facial\nfeature points in the images, and calculate the distance of the facial feature\npoints to detect the opening and closing of the eyes and mouth. Furthermore, we\nuse a convolutional neural network (CNN) based on the MobileNet architecture to\nidentify various distracted driving behaviors. Experiments are performed on a\nPC based setup with a webcam and results are demonstrated using public datasets\nas well as custom datasets created for training and testing. Compared to\nprevious approaches, we build our own datasets and provide better results in\nterms of accuracy and computation time.",
        "date": "Not Found"
    },
    {
        "title": "Title:Tailoring Semantic Communication at Network Edge: A Novel Approach Using  Dynamic Knowledge Distillation",
        "authors": [
            "",
            "Authors:",
            "",
            "Abdullatif Albaseer",
            ",",
            "Mohamed Abdallah",
            ""
        ],
        "abstract": "Semantic Communication (SemCom) systems, empowered by deep learning (DL),\nrepresent a paradigm shift in data transmission. These systems prioritize the\nsignificance of content over sheer data volume. However, existing SemCom\ndesigns face challenges when applied to diverse computational capabilities and\nnetwork conditions, particularly in time-sensitive applications. A key\nchallenge is the assumption that diverse devices can uniformly benefit from a\nstandard, large DL model in SemCom systems. This assumption becomes\nincreasingly impractical, especially in high-speed, high-reliability\napplications such as industrial automation or critical healthcare. Therefore,\nthis paper introduces a novel SemCom framework tailored for heterogeneous,\nresource-constrained edge devices and computation-intensive servers. Our\napproach employs dynamic knowledge distillation (KD) to customize semantic\nmodels for each device, balancing computational and communication constraints\nwhile ensuring Quality of Service (QoS). We formulate an optimization problem\nand develop an adaptive algorithm that iteratively refines semantic knowledge\non edge devices, resulting in better models tailored to their resource\nprofiles. This algorithm strategically adjusts the granularity of distilled\nknowledge, enabling devices to maintain high semantic accuracy for precise\ninference tasks, even under unstable network conditions. Extensive simulations\ndemonstrate that our approach significantly reduces model complexity for edge\ndevices, leading to better semantic extraction and achieving the desired QoS.",
        "date": "Not Found"
    },
    {
        "title": "Title:GPAvatar: Generalizable and Precise Head Avatar from Image(s)",
        "authors": [
            "",
            "Authors:",
            "",
            "Xuangeng Chu",
            ",",
            "Yu Li",
            ",",
            "Ailing Zeng",
            ",",
            "Tianyu Yang",
            ",",
            "Lijian Lin",
            ",",
            "Yunfei Liu",
            ",",
            "Tatsuya Harada",
            ""
        ],
        "abstract": "Head avatar reconstruction, crucial for applications in virtual reality,\nonline meetings, gaming, and film industries, has garnered substantial\nattention within the computer vision community. The fundamental objective of\nthis field is to faithfully recreate the head avatar and precisely control\nexpressions and postures. Existing methods, categorized into 2D-based warping,\nmesh-based, and neural rendering approaches, present challenges in maintaining\nmulti-view consistency, incorporating non-facial information, and generalizing\nto new identities. In this paper, we propose a framework named GPAvatar that\nreconstructs 3D head avatars from one or several images in a single forward\npass. The key idea of this work is to introduce a dynamic point-based\nexpression field driven by a point cloud to precisely and effectively capture\nexpressions. Furthermore, we use a Multi Tri-planes Attention (MTA) fusion\nmodule in the tri-planes canonical field to leverage information from multiple\ninput images. The proposed method achieves faithful identity reconstruction,\nprecise expression control, and multi-view consistency, demonstrating promising\nresults for free-viewpoint rendering and novel view synthesis.",
        "date": "Not Found"
    },
    {
        "title": "Title:Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt  Tensor Products",
        "authors": [
            "",
            "Authors:",
            "",
            "Shengjie Luo",
            ",",
            "Tianlang Chen",
            ",",
            "Aditi S. Krishnapriyan",
            ""
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important\nrole in modeling 3D data across real-world applications. Enforcing this\nequivariance primarily involves the tensor products of irreducible\nrepresentations (irreps). However, the computational complexity of such\noperations increases significantly as higher-order tensors are used. In this\nwork, we propose a systematic approach to substantially accelerate the\ncomputation of the tensor products of irreps. We mathematically connect the\ncommonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are\nintegrals of products of three spherical harmonics. Through Gaunt coefficients,\nthe tensor product of irreps becomes equivalent to the multiplication between\nspherical functions represented by spherical harmonics. This perspective\nfurther allows us to change the basis for the equivariant operations from\nspherical harmonics to a 2D Fourier basis. Consequently, the multiplication\nbetween spherical functions represented by a 2D Fourier basis can be\nefficiently computed via the convolution theorem and Fast Fourier Transforms.\nThis transformation reduces the complexity of full tensor products of irreps\nfrom $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of\nirreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which\nserves as a new method to construct efficient equivariant operations across\ndifferent model architectures. Our experiments on the Open Catalyst Project and\n3BPA datasets demonstrate both the increased efficiency and improved\nperformance of our approach.",
        "date": "Not Found"
    },
    {
        "title": "Title:Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by  Tracing their Contributions",
        "authors": [
            "",
            "Authors:",
            "",
            "Namitha Padmanabhan",
            ",",
            "Matthew Gwilliam",
            ",",
            "Pulkit Kumar",
            ",",
            "Shishira R Maiya",
            ",",
            "Max Ehrlich",
            ",",
            "Abhinav Shrivastava",
            ""
        ],
        "abstract": "The many variations of Implicit Neural Representations (INRs), where a neural\nnetwork is trained as a continuous representation of a signal, have tremendous\npractical utility for downstream tasks including novel view synthesis, video\ncompression, and image superresolution. Unfortunately, the inner workings of\nthese networks are seriously under-studied. Our work, eXplaining the Implicit\nNeural Canvas (XINC), is a unified framework for explaining properties of INRs\nby examining the strength of each neuron's contribution to each output pixel.\nWe call the aggregate of these contribution maps the Implicit Neural Canvas and\nwe use this concept to demonstrate that the INRs which we study learn to\n''see'' the frames they represent in surprising ways. For example, INRs tend to\nhave highly distributed representations. While lacking high-level object\nsemantics, they have a significant bias for color and edges, and are almost\nentirely space-agnostic. We arrive at our conclusions by examining how objects\nare represented across time in video INRs, using clustering to visualize\nsimilar neurons across layers and architectures, and show that this is\ndominated by motion. These insights demonstrate the general usefulness of our\nanalysis framework. Our project page is available at\nhttps://namithap10.github.io/xinc.",
        "date": "Not Found"
    },
    {
        "title": "Title:Edit One for All: Interactive Batch Image Editing",
        "authors": [
            "",
            "Authors:",
            "",
            "Thao Nguyen",
            ",",
            "Utkarsh Ojha",
            ",",
            "Yuheng Li",
            ",",
            "Haotian Liu",
            ",",
            "Yong Jae Lee",
            ""
        ],
        "abstract": "In recent years, image editing has advanced remarkably. With increased human\ncontrol, it is now possible to edit an image in a plethora of ways; from\nspecifying in text what we want to change, to straight up dragging the contents\nof the image in an interactive point-based manner. However, most of the focus\nhas remained on editing single images at a time. Whether and how we can\nsimultaneously edit large batches of images has remained understudied. With the\ngoal of minimizing human supervision in the editing process, this paper\npresents a novel method for interactive batch image editing using StyleGAN as\nthe medium. Given an edit specified by users in an example image (e.g., make\nthe face frontal), our method can automatically transfer that edit to other\ntest images, so that regardless of their initial state (pose), they all arrive\nat the same final state (e.g., all facing front). Extensive experiments\ndemonstrate that edits performed using our method have similar visual quality\nto existing single-image-editing methods, while having more visual consistency\nand saving significant time and human effort.",
        "date": "Not Found"
    },
    {
        "title": "Title:AutoFT: Robust Fine-Tuning by Optimizing Hyperparameters on OOD Data",
        "authors": [
            "",
            "Authors:",
            "",
            "Caroline Choi",
            ",",
            "Yoonho Lee",
            ",",
            "Annie Chen",
            ",",
            "Allan Zhou",
            ",",
            "Aditi Raghunathan",
            ",",
            "Chelsea Finn",
            ""
        ],
        "abstract": "Foundation models encode rich representations that can be adapted to a\ndesired task by fine-tuning on task-specific data. However, fine-tuning a model\non one particular data distribution often compromises the model's original\nperformance on other distributions. Current methods for robust fine-tuning\nutilize hand-crafted regularization techniques to constrain the fine-tuning\nprocess towards the base foundation model. Yet, it is hard to precisely specify\nwhat characteristics of the foundation model to retain during fine-tuning, as\nthis depends on how the pre-training, fine-tuning, and evaluation data\ndistributions relate to each other. We propose AutoFT, a data-driven approach\nfor guiding foundation model fine-tuning. AutoFT optimizes fine-tuning\nhyperparameters to maximize performance on a small out-of-distribution (OOD)\nvalidation set. To guide fine-tuning in a granular way, AutoFT searches a\nhighly expressive hyperparameter space that includes weight coefficients for\nmany different losses, in addition to learning rate and weight decay values. We\nevaluate AutoFT on nine natural distribution shifts which include domain shifts\nand subpopulation shifts. Our experiments show that AutoFT significantly\nimproves generalization to new OOD data, outperforming existing robust\nfine-tuning methods. Notably, AutoFT achieves new state-of-the-art performance\non the WILDS-iWildCam and WILDS-FMoW benchmarks, outperforming the previous\nbest methods by $6.0\\%$ and $1.5\\%$, respectively.",
        "date": "Not Found"
    },
    {
        "title": "Title:Supervised Fine-tuning in turn Improves Visual Foundation Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiaohu Jiang",
            ",",
            "Yixiao Ge",
            ",",
            "Yuying Ge",
            ",",
            "Chun Yuan",
            ",",
            "Ying Shan",
            ""
        ],
        "abstract": "Image-text training like CLIP has dominated the pretraining of vision\nfoundation models in recent years. Subsequent efforts have been made to\nintroduce region-level visual learning into CLIP's pretraining but face\nscalability challenges due to the lack of large-scale region-level datasets.\nDrawing inspiration from supervised fine-tuning (SFT) in natural language\nprocessing such as instruction tuning, we explore the potential of fine-grained\nSFT in enhancing the generation of vision foundation models after their\npretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash\nthe fine-grained knowledge of vision foundation models. In ViSFT, the vision\nfoundation model is enhanced by performing visual joint learning on some\nin-domain tasks and then tested on out-of-domain benchmarks. With updating\nusing ViSFT on 8 V100 GPUs in less than 2 days, a vision transformer with over\n4.4B parameters shows improvements across various out-of-domain benchmarks\nincluding vision and vision-linguistic scenarios.",
        "date": "Not Found"
    },
    {
        "title": "Title:The Manga Whisperer: Automatically Generating Transcriptions for Comics",
        "authors": [
            "",
            "Authors:",
            "",
            "Ragav Sachdeva",
            ",",
            "Andrew Zisserman",
            ""
        ],
        "abstract": "In the past few decades, Japanese comics, commonly referred to as Manga, have\ntranscended both cultural and linguistic boundaries to become a true worldwide\nsensation. Yet, the inherent reliance on visual cues and illustration within\nmanga renders it largely inaccessible to individuals with visual impairments.\nIn this work, we seek to address this substantial barrier, with the aim of\nensuring that manga can be appreciated and actively engaged by everyone.\nSpecifically, we tackle the problem of diarisation i.e. generating a\ntranscription of who said what and when, in a fully automatic way.\nTo this end, we make the following contributions: (1) we present a unified\nmodel, Magi, that is able to (a) detect panels, text boxes and character boxes,\n(b) cluster characters by identity (without knowing the number of clusters\napriori), and (c) associate dialogues to their speakers; (2) we propose a novel\napproach that is able to sort the detected text boxes in their reading order\nand generate a dialogue transcript; (3) we annotate an evaluation benchmark for\nthis task using publicly available [English] manga pages. The code, evaluation\ndatasets and the pre-trained model can be found at:\nhttps://github.com/ragavsachdeva/magi.",
        "date": "Not Found"
    },
    {
        "title": "Title:ChatQA: Building GPT-4 Level Conversational QA Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Zihan Liu",
            ",",
            "Wei Ping",
            ",",
            "Rajarshi Roy",
            ",",
            "Peng Xu",
            ",",
            "Mohammad Shoeybi",
            ",",
            "Bryan Catanzaro",
            ""
        ],
        "abstract": "In this work, we introduce ChatQA, a family of conversational question\nanswering (QA) models, that obtain GPT-4 level accuracies. Specifically, we\npropose a two-stage instruction tuning method that can significantly improve\nthe zero-shot conversational QA results from large language models (LLMs). To\nhandle retrieval in conversational QA, we fine-tune a dense retriever on a\nmulti-turn QA dataset, which provides comparable results to using the\nstate-of-the-art query rewriting model while largely reducing deployment cost.\nNotably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10\nconversational QA datasets (54.14 vs. 53.90), without relying on any synthetic\ndata from OpenAI GPT models.",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Language-Driven Video Inpainting via Multimodal Large Language  Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jianzong Wu",
            ",",
            "Xiangtai Li",
            ",",
            "Chenyang Si",
            ",",
            "Shangchen Zhou",
            ",",
            "Jingkang Yang",
            ",",
            "Jiangning Zhang",
            ",",
            "Yining Li",
            ",",
            "Kai Chen",
            ",",
            "Yunhai Tong",
            ",",
            "Ziwei Liu",
            ",",
            "Chen Change Loy",
            ""
        ],
        "abstract": "We introduce a new task -- language-driven video inpainting, which uses\nnatural language instructions to guide the inpainting process. This approach\novercomes the limitations of traditional video inpainting methods that depend\non manually labeled binary masks, a process often tedious and labor-intensive.\nWe present the Remove Objects from Videos by Instructions (ROVI) dataset,\ncontaining 5,650 videos and 9,091 inpainting results, to support training and\nevaluation for this task. We also propose a novel diffusion-based\nlanguage-driven video inpainting framework, the first end-to-end baseline for\nthis task, integrating Multimodal Large Language Models to understand and\nexecute complex language-based inpainting requests effectively. Our\ncomprehensive results showcase the dataset's versatility and the model's\neffectiveness in various language-instructed inpainting scenarios. We will make\ndatasets, code, and models publicly available.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask  Inpainting",
        "authors": [
            "",
            "Authors:",
            "",
            "Wouter Van Gansbeke",
            ",",
            "Bert De Brabandere",
            ""
        ],
        "abstract": "Panoptic and instance segmentation networks are often trained with\nspecialized object detection modules, complex loss functions, and ad-hoc\npost-processing steps to handle the permutation-invariance of the instance\nmasks. This work builds upon Stable Diffusion and proposes a latent diffusion\napproach for panoptic segmentation, resulting in a simple architecture which\nomits these complexities. Our training process consists of two steps: (1)\ntraining a shallow autoencoder to project the segmentation masks to latent\nspace; (2) training a diffusion model to allow image-conditioned sampling in\nlatent space. The use of a generative model unlocks the exploration of mask\ncompletion or inpainting, which has applications in interactive segmentation.\nThe experimental validation yields promising results for both panoptic\nsegmentation and mask inpainting. While not setting a new state-of-the-art, our\nmodel's simplicity, generality, and mask completion capability are desirable\nproperties.",
        "date": "Not Found"
    },
    {
        "title": "Title:RAP-SAM: Towards Real-Time All-Purpose Segment Anything",
        "authors": [
            "",
            "Authors:",
            "",
            "Shilin Xu",
            ",",
            "Haobo Yuan",
            ",",
            "Qingyu Shi",
            ",",
            "Lu Qi",
            ",",
            "Jingbo Wang",
            ",",
            "Yibo Yang",
            ",",
            "Yining Li",
            ",",
            "Kai Chen",
            ",",
            "Yunhai Tong",
            ",",
            "Bernard Ghanem",
            ",",
            "Xiangtai Li",
            ",",
            "Ming-Hsuan Yang",
            ""
        ],
        "abstract": "Advanced by transformer architecture, vision foundation models (VFMs) achieve\nremarkable progress in performance and generalization ability. Segment Anything\nModel (SAM) is one remarkable model that can achieve generalized segmentation.\nHowever, most VFMs cannot run in realtime, which makes it difficult to transfer\nthem into several products. On the other hand, current real-time segmentation\nmainly has one purpose, such as semantic segmentation on the driving scene. We\nargue that diverse outputs are needed for real applications. Thus, this work\nexplores a new real-time segmentation setting, named all-purpose segmentation\nin real-time, to transfer VFMs in real-time deployment. It contains three\ndifferent tasks, including interactive segmentation, panoptic segmentation, and\nvideo segmentation. We aim to use one model to achieve the above tasks in\nreal-time. We first benchmark several strong baselines. Then, we present\nReal-Time All Purpose SAM (RAP-SAM). It contains an efficient encoder and an\nefficient decoupled decoder to perform prompt-driven decoding. Moreover, we\nfurther explore different training strategies and tuning methods to boost\nco-training performance further. Our code and model are available at\nhttps://github.com/xushilin1/RAP-SAM/.",
        "date": "Not Found"
    },
    {
        "title": "Title:OMG-Seg: Is One Model Good Enough For All Segmentation?",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiangtai Li",
            ",",
            "Haobo Yuan",
            ",",
            "Wei Li",
            ",",
            "Henghui Ding",
            ",",
            "Size Wu",
            ",",
            "Wenwei Zhang",
            ",",
            "Yining Li",
            ",",
            "Kai Chen",
            ",",
            "Chen Change Loy",
            ""
        ],
        "abstract": "In this work, we address various segmentation tasks, each traditionally\ntackled by distinct or partially unified models. We propose OMG-Seg, One Model\nthat is Good enough to efficiently and effectively handle all the segmentation\ntasks, including image semantic, instance, and panoptic segmentation, as well\nas their video counterparts, open vocabulary settings, prompt-driven,\ninteractive segmentation like SAM, and video object segmentation. To our\nknowledge, this is the first model to handle all these tasks in one model and\nachieve satisfactory performance. We show that OMG-Seg, a transformer-based\nencoder-decoder architecture with task-specific queries and outputs, can\nsupport over ten distinct segmentation tasks and yet significantly reduce\ncomputational and parameter overhead across various tasks and datasets. We\nrigorously evaluate the inter-task influences and correlations during\nco-training. Code and models are available at https://github.com/lxtGH/OMG-Seg.",
        "date": "Not Found"
    },
    {
        "title": "Title:Simultaneous Tactile Estimation and Control for Extrinsic Dexterity",
        "authors": [
            "",
            "Authors:",
            "",
            "Antonia Bronars",
            ",",
            "Sangwoon Kim",
            ",",
            "Parag Patre",
            ",",
            "Alberto Rodriguez",
            ""
        ],
        "abstract": "We introduce a novel approach that combines tactile estimation and control\nfor in-hand object manipulation. By integrating measurements from robot\nkinematics and an image-based tactile sensor, our framework estimates and\ntracks object pose while simultaneously generating motion plans to control the\npose of a grasped object. This approach consists of a discrete pose estimator\nthat uses the Viterbi decoding algorithm to find the most likely sequence of\nobject poses in a coarsely discretized grid, and a continuous pose\nestimator-controller to refine the pose estimate and accurately manipulate the\npose of the grasped object. Our method is tested on diverse objects and\nconfigurations, achieving desired manipulation objectives and outperforming\nsingle-shot methods in estimation accuracy. The proposed approach holds\npotential for tasks requiring precise manipulation in scenarios where visual\nperception is limited, laying the foundation for closed-loop behavior\napplications such as assembly and tool use. Please see supplementary videos for\nreal-world demonstration at https://sites.google.com/view/texterity.",
        "date": "Not Found"
    },
    {
        "title": "Title:ParaHome: Parameterizing Everyday Home Activities Towards 3D Generative  Modeling of Human-Object Interactions",
        "authors": [
            "",
            "Authors:",
            "",
            "Jeonghwan Kim",
            ",",
            "Jisoo Kim",
            ",",
            "Jeonghyeon Na",
            ",",
            "Hanbyul Joo",
            ""
        ],
        "abstract": "To enable machines to learn how humans interact with the physical world in\nour daily activities, it is crucial to provide rich data that encompasses the\n3D motion of humans as well as the motion of objects in a learnable 3D\nrepresentation. Ideally, this data should be collected in a natural setup,\ncapturing the authentic dynamic 3D signals during human-object interactions. To\naddress this challenge, we introduce the ParaHome system, designed to capture\nand parameterize dynamic 3D movements of humans and objects within a common\nhome environment. Our system consists of a multi-view setup with 70\nsynchronized RGB cameras, as well as wearable motion capture devices equipped\nwith an IMU-based body suit and hand motion capture gloves. By leveraging the\nParaHome system, we collect a novel large-scale dataset of human-object\ninteraction. Notably, our dataset offers key advancement over existing datasets\nin three main aspects: (1) capturing 3D body and dexterous hand manipulation\nmotion alongside 3D object movement within a contextual home environment during\nnatural activities; (2) encompassing human interaction with multiple objects in\nvarious episodic scenarios with corresponding descriptions in texts; (3)\nincluding articulated objects with multiple parts expressed with parameterized\narticulations. Building upon our dataset, we introduce new research tasks aimed\nat building a generative model for learning and synthesizing human-object\ninteractions in a real-world room setting.",
        "date": "Not Found"
    },
    {
        "title": "Title:Polyander visualization of quantum walks",
        "authors": [
            "",
            "Authors:",
            "",
            "Steven Duplij",
            ",",
            "Raimund Vogl",
            ""
        ],
        "abstract": "We investigate quantum walks which play an important role in the modelling of\nmany phenomena. The detailed and thorough description is given to the discrete\nquantum walks on a line, where the total quantum state consists of quantum\nstates of the walker and the coin. In addition to the standard walker\nprobability distribution, we introduce the coin probability distribution which\ngives more complete quantum walk description and novel visualization in terms\nof the so called polyanders (analogs of trianders in DNA visualization). The\nmethods of final states computation and the Fourier transform are presented for\nthe Hadamard quantum walk.",
        "date": "Not Found"
    },
    {
        "title": "Title:Barcodes for the topological analysis of gradient-like vector fields",
        "authors": [
            "",
            "Authors:",
            "",
            "Clemens Bannwart",
            ",",
            "Claudia Landi",
            ""
        ],
        "abstract": "Intending to introduce a method for the topological analysis of fields, we\npresent a pipeline that takes as an input a weighted and based chain complex,\nproduces a tame epimorphic parametrized chain complex, and encodes it as a\nbarcode of tagged intervals. We show how to apply this pipeline to the weighted\nand based chain complex of a gradient-like Morse-Smale vector field on a\ncompact Riemannian manifold in both the smooth and discrete settings.\nInterestingly for computations, it turns out that there is an isometry between\ntame epimorphic parametrized chain complexes endowed with the interleaving\ndistance and barcodes of tagged intervals endowed with the bottleneck distance.\nConcerning stability, we show that the map taking a generic enough\ngradient-like vector field to its barcode of tagged intervals is continuous.\nFinally, we prove that the barcode of any such vector field can be approximated\nby the barcode of a combinatorial version of it with arbitrary precision.",
        "date": "Not Found"
    },
    {
        "title": "Title:Precipitation Prediction Using an Ensemble of Lightweight Learners",
        "authors": [
            "",
            "Authors:",
            "",
            "Xinzhe Li",
            ",",
            "Sun Rui",
            ",",
            "Yiming Niu",
            ",",
            "Yao Liu",
            ""
        ],
        "abstract": "Precipitation prediction plays a crucial role in modern agriculture and\nindustry. However, it poses significant challenges due to the diverse patterns\nand dynamics in time and space, as well as the scarcity of high precipitation\nevents.\nTo address this challenge, we propose an ensemble learning framework that\nleverages multiple learners to capture the diverse patterns of precipitation\ndistribution. Specifically, the framework consists of a precipitation predictor\nwith multiple lightweight heads (learners) and a controller that combines the\noutputs from these heads. The learners and the controller are separately\noptimized with a proposed 3-stage training scheme.\nBy utilizing provided satellite images, the proposed approach can effectively\nmodel the intricate rainfall patterns, especially for high precipitation\nevents. It achieved 1st place on the core test as well as the nowcasting\nleaderboards of the Weather4Cast 2023 competition. For detailed implementation,\nplease refer to our GitHub repository at:\nhttps://github.com/lxz1217/weather4cast-2023-lxz.",
        "date": "Not Found"
    },
    {
        "title": "Title:Multispectral Stereo-Image Fusion for 3D Hyperspectral Scene  Reconstruction",
        "authors": [
            "",
            "Authors:",
            "",
            "Eric L. Wisotzky",
            ",",
            "Jost Triller",
            ",",
            "Anna Hilsmann",
            ",",
            "Peter Eisert",
            ""
        ],
        "abstract": "Spectral imaging enables the analysis of optical material properties that are\ninvisible to the human eye. Different spectral capturing setups, e.g., based on\nfilter-wheel, push-broom, line-scanning, or mosaic cameras, have been\nintroduced in the last years to support a wide range of applications in\nagriculture, medicine, and industrial surveillance. However, these systems\noften suffer from different disadvantages, such as lack of real-time\ncapability, limited spectral coverage or low spatial resolution. To address\nthese drawbacks, we present a novel approach combining two calibrated\nmultispectral real-time capable snapshot cameras, covering different spectral\nranges, into a stereo-system. Therefore, a hyperspectral data-cube can be\ncontinuously captured. The combined use of different multispectral snapshot\ncameras enables both 3D reconstruction and spectral analysis. Both captured\nimages are demosaicked avoiding spatial resolution loss. We fuse the spectral\ndata from one camera into the other to receive a spatially and spectrally high\nresolution video stream. Experiments demonstrate the feasibility of this\napproach and the system is investigated with regard to its applicability for\nsurgical assistance monitoring.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Smoothing Algorithm for l1 Support Vector Machines",
        "authors": [
            "",
            "Authors:",
            "",
            "Ibrahim Emirahmetoglu",
            ",",
            "Jeffrey Hajewski",
            ",",
            "Suely Oliveira",
            ",",
            "David E. Stewart",
            ""
        ],
        "abstract": "A smoothing algorithm is presented for solving the soft-margin Support Vector\nMachine (SVM) optimization problem with an $\\ell^{1}$ penalty. This algorithm\nis designed to require a modest number of passes over the data, which is an\nimportant measure of its cost for very large datasets. The algorithm uses\nsmoothing for the hinge-loss function, and an active set approach for the\n$\\ell^{1}$ penalty. The smoothing parameter $\\alpha$ is initially large, but\ntypically halved when the smoothed problem is solved to sufficient accuracy.\nConvergence theory is presented that shows\n$\\mathcal{O}(1+\\log(1+\\log_+(1/\\alpha)))$ guarded Newton steps for each value\nof $\\alpha$ except for asymptotic bands $\\alpha=\\Theta(1)$ and\n$\\alpha=\\Theta(1/N)$, with only one Newton step provided $\\eta\\alpha\\gg1/N$,\nwhere $N$ is the number of data points and the stopping criterion that the\npredicted reduction is less than $\\eta\\alpha$. The experimental results show\nthat our algorithm is capable of strong test accuracy without sacrificing\ntraining speed.",
        "date": "Not Found"
    },
    {
        "title": "Title:Reasoning with random sets: An agenda for the future",
        "authors": [
            "",
            "Authors:",
            "",
            "Fabio Cuzzolin",
            ""
        ],
        "abstract": "In this paper, we discuss a potential agenda for future work in the theory of\nrandom sets and belief functions, touching upon a number of focal issues: the\ndevelopment of a fully-fledged theory of statistical reasoning with random\nsets, including the generalisation of logistic regression and of the classical\nlaws of probability; the further development of the geometric approach to\nuncertainty, to include general random sets, a wider range of uncertainty\nmeasures and alternative geometric representations; the application of this new\ntheory to high-impact areas such as climate change, machine learning and\nstatistical learning theory.",
        "date": "Not Found"
    },
    {
        "title": "Title:Diffusion-Driven Generative Framework for Molecular Conformation  Prediction",
        "authors": [
            "",
            "Authors:",
            "",
            "Bobin Yang",
            ",",
            "Zhenghan Chen",
            ""
        ],
        "abstract": "The task of inferring three-dimensional molecular configurations from their\ntwo-dimensional graph representations is of critical significance in the\ndomains of computational chemistry and the development of pharmaceuticals. It\ncontributes fundamentally to our grasp of molecular mechanisms and\ninteractions. The rapid evolution of machine learning, especially in the realm\nof deep generative networks, has catalyzed breakthroughs in the precision of\nsuch predictive modeling. Traditional methodologies typically employ a\nbifurcated strategy: initially estimating interatomic distances followed by\nsculpting the spatial molecular structure via solving a distance geometry\nproblem. This sequential approach, however, occasionally fails to capture the\nintricacies of local atomic arrangements accurately, thus compromising the\nintegrity of the resultant structural models. Addressing these deficiencies,\nthis work introduces an avant-garde generative framework: \\method{}, which is\npredicated on the diffusion principles found in classical non-equilibrium\nthermodynamics. \\method{} envisages atoms as discrete entities and is adept at\nguiding the reversal of diffusion morphing a distribution of stochastic noise\nback into coherent molecular forms through a process akin to a Markov chain.\nThis transformation begins with the initial representation of a molecular graph\nin an abstract latent space, progressing to the realization of the\nthree-dimensional forms via an elaborate bilevel optimization scheme, tailored\nto respect the task's specific requirements.",
        "date": "Not Found"
    },
    {
        "title": "Title:Image Restoration: A Comparative Analysis of Image De noising Using  Different Spatial Filtering Techniques",
        "authors": [
            "",
            "Authors:",
            "",
            "E. G. Onyedinma",
            ",",
            "I. E. Onyenwe",
            ""
        ],
        "abstract": "Acquired images for medical and other purposes can be affected by noise from\nboth the equipment used in the capturing or the environment. This can have\nadverse effect on the information therein. Thus, the need to restore the image\nto its original state by removing the noise. To effectively remove such noise,\npre knowledge of the type of noise model present is necessary. This work\nexplores different noise removal filters by first introducing noise to an image\nand then applying different spatial domain filtering techniques to the image to\nget rid of the noise. Different evaluation techniques such as Peak to Signal\nNoise Ratio(PSNR) and Root Mean Square Error(RMSE) were adopted to determine\nhow effective each filter is on a given image noise. Result showed that some\nfilters are more effective on some noise models than others.",
        "date": "Not Found"
    },
    {
        "title": "Title:Quest for a solution to drift in phase change memory devices",
        "authors": [
            "",
            "Authors:",
            "",
            "Benedikt Kersting",
            ""
        ],
        "abstract": "The goal of this thesis is to gain new insights into the drift phenomenon and\nidentify strategies to mitigate it. An extensive experimental characterization\nof PCM devices and in particular drift forms the foundation of each chapter.\nWith respect to time-scales, ambient temperature, device dimensions, and\ncombinations thereof, drift is studied under unprecedented conditions. In three\nstudies, different aspects of drift are examined.\n(1) The origin of structural relaxation: Drift measurements over 9 orders of\nmagnitude in time reveal the onset of relaxation in a melt-quenched state. The\ndata is used to appraise two models, the Gibbs relaxation model and the\ncollective relaxation model. Additionally, a refined version of the collective\nrelaxation model is introduced and the consequences of a limited number of\nstructural defects are discussed.\n(2) Exploiting nanoscale effects in phase change memories: Scaling devices to\never-smaller dimensions is incentivized by the requirement to achieve higher\nstorage densities and less power consumption. Eventually, confinement and\ninterfacial effects will govern the device characteristics. Anticipating these\nconsequences, the feasibility to use a single element, Antimony, is assessed\nfor the first time. The power efficiency, stability against crystallization,\nand drift are characterized under different degrees of confinement.\n(3) State-dependent drift in a projected memory cell: New device concepts are\naiming to reduce drift by decoupling the cell resistance from the electronic\nproperties of the amorphous phase. A shunt resistor scaling with the amount of\namorphous material is added. Simulations and the drift characteristics of a\nprojected device put the idealized concept to the test. The contact resistance\nbetween the phase change material and the shunt resistor is identified as a\ndecisive parameter to achieve the desired device properties.",
        "date": "Not Found"
    },
    {
        "title": "Title:Self Supervised Vision for Climate Downscaling",
        "authors": [
            "",
            "Authors:",
            "",
            "Karandeep Singh",
            ",",
            "Chaeyoon Jeong",
            ",",
            "Naufal Shidqi",
            ",",
            "Sungwon Park",
            ",",
            "Arjun Nellikkattil",
            ",",
            "Elke Zeller",
            ",",
            "Meeyoung Cha",
            ""
        ],
        "abstract": "Climate change is one of the most critical challenges that our planet is\nfacing today. Rising global temperatures are already bringing noticeable\nchanges to Earth's weather and climate patterns with an increased frequency of\nunpredictable and extreme weather events. Future projections for climate change\nresearch are based on Earth System Models (ESMs), the computer models that\nsimulate the Earth's climate system. ESMs provide a framework to integrate\nvarious physical systems, but their output is bound by the enormous\ncomputational resources required for running and archiving higher-resolution\nsimulations. For a given resource budget, the ESMs are generally run on a\ncoarser grid, followed by a computationally lighter $downscaling$ process to\nobtain a finer-resolution output. In this work, we present a deep-learning\nmodel for downscaling ESM simulation data that does not require high-resolution\nground truth data for model optimization. This is realized by leveraging\nsalient data distribution patterns and the hidden dependencies between weather\nvariables for an $\\textit{individual}$ data point at $\\textit{runtime}$.\nExtensive evaluation with $2$x, $3$x, and $4$x scaling factors demonstrates\nthat the proposed model consistently obtains superior performance over that of\nvarious baselines. The improved downscaling performance and no dependence on\nhigh-resolution ground truth data make the proposed method a valuable tool for\nclimate research and mark it as a promising direction for future research.",
        "date": "Not Found"
    },
    {
        "title": "Title:Brain Tumor Radiogenomic Classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Amr Mohamed",
            ",",
            "Mahmoud Rabea",
            ",",
            "Aya Sameh",
            ",",
            "Ehab Kamal",
            ""
        ],
        "abstract": "The RSNA-MICCAI brain tumor radiogenomic classification challenge aimed to\npredict MGMT biomarker status in glioblastoma through binary classification on\nMulti parameter mpMRI scans: T1w, T1wCE, T2w and FLAIR. The dataset is splitted\ninto three main cohorts: training set, validation set which were used during\ntraining, and the testing were only used during final evaluation. Images were\neither in a DICOM format or in Png format. different architectures were used to\ninvestigate the problem including the 3D version of Vision Transformer (ViT3D),\nResNet50, Xception and EfficientNet-B3. AUC was used as the main evaluation\nmetric and the results showed an advantage for both the ViT3D and the Xception\nmodels achieving 0.6015 and 0.61745 respectively on the testing set. compared\nto other results, our results proved to be valid given the complexity of the\ntask. further improvements can be made through exploring different strategies,\ndifferent architectures and more diverse datasets.",
        "date": "Not Found"
    },
    {
        "title": "Title:Gene-associated Disease Discovery Powered by Large Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiayu Chang",
            ",",
            "Shiyu Wang",
            ",",
            "Chen Ling",
            ",",
            "Zhaohui Qin",
            ",",
            "Liang Zhao",
            ""
        ],
        "abstract": "The intricate relationship between genetic variation and human diseases has\nbeen a focal point of medical research, evidenced by the identification of risk\ngenes regarding specific diseases. The advent of advanced genome sequencing\ntechniques has significantly improved the efficiency and cost-effectiveness of\ndetecting these genetic markers, playing a crucial role in disease diagnosis\nand forming the basis for clinical decision-making and early risk assessment.\nTo overcome the limitations of existing databases that record disease-gene\nassociations from existing literature, which often lack real-time updates, we\npropose a novel framework employing Large Language Models (LLMs) for the\ndiscovery of diseases associated with specific genes. This framework aims to\nautomate the labor-intensive process of sifting through medical literature for\nevidence linking genetic variations to diseases, thereby enhancing the\nefficiency of disease identification. Our approach involves using LLMs to\nconduct literature searches, summarize relevant findings, and pinpoint diseases\nrelated to specific genes. This paper details the development and application\nof our LLM-powered framework, demonstrating its potential in streamlining the\ncomplex process of literature retrieval and summarization to identify diseases\nassociated with specific genetic variations.",
        "date": "Not Found"
    },
    {
        "title": "Title:Identifying Three-Dimensional Radiative Patterns Associated with Early  Tropical Cyclone Intensification",
        "authors": [
            "",
            "Authors:",
            "",
            "Frederick Iat-Hin Tam",
            ",",
            "Tom Beucler",
            ",",
            "James H. Ruppert Jr",
            ""
        ],
        "abstract": "Cloud radiative feedback impacts early tropical cyclone (TC) intensification,\nbut limitations in existing diagnostic frameworks make them unsuitable for\nstudying asymmetric or transient radiative heating. We propose a linear\nVariational Encoder-Decoder (VED) to learn the hidden relationship between\nradiation and the surface intensification of realistic simulated TCs. Limiting\nVED model inputs enables using its uncertainty to identify periods when\nradiation has more importance for intensification. A close examination of the\nextracted 3D radiative structures suggests that longwave radiative forcing from\ninner core deep convection and shallow clouds both contribute to\nintensification, with the deep convection having the most impact overall. We\nfind that deep convection downwind of the shallow clouds is critical to the\nintensification of Haiyan. Our work demonstrates that machine learning can\ndiscover thermodynamic-kinematic relationships without relying on axisymmetric\nor deterministic assumptions, paving the way towards the objective discovery of\nprocesses leading to TC intensification in realistic conditions.",
        "date": "Not Found"
    },
    {
        "title": "Title:Reservoir computing with logistic map",
        "authors": [
            "",
            "Authors:",
            "",
            "R. Arun",
            ",",
            "M. Sathish Aravindh",
            ",",
            "A. Venkatesan",
            ",",
            "M. Lakshmanan",
            ""
        ],
        "abstract": "Recent studies on reservoir computing essentially involve a high dimensional\ndynamical system as the reservoir, which transforms and stores the input as a\nhigher dimensional state, for temporal and nontemporal data processing. We\ndemonstrate here a method to predict temporal and nontemporal tasks by\nconstructing virtual nodes as constituting a reservoir in reservoir computing\nusing a nonlinear map, namely logistic map, and a simple finite trigonometric\nseries. We predict three nonlinear systems, namely Lorenz, R\\\"ossler, and\nHindmarsh-Rose, for temporal tasks and a seventh order polynomial for\nnontemporal tasks with great accuracy. Also, the prediction is made in the\npresence of noise and found to closely agree with the target. Remarkably, the\nlogistic map performs well and predicts close to the actual or target values.\nThe low values of the root mean square error confirm the accuracy of this\nmethod in terms of efficiency. Our approach removes the necessity of continuous\ndynamical systems for constructing the reservoir in reservoir computing.\nMoreover, the accurate prediction for the three different nonlinear systems\nsuggests that this method can be considered a general one and can be applied to\npredict many systems. Finally, we show that the method also accurately\nanticipates the time series for the future (self prediction).",
        "date": "Not Found"
    },
    {
        "title": "Title:Experimental Implementation of A Quantum Zero-Knowledge Proof for User  Authentication",
        "authors": [
            "",
            "Authors:",
            "",
            "Marta I. Garcia-Cid",
            ",",
            "Dileepsai Bodanapu",
            ",",
            "Alberto Gatto",
            ",",
            "Paolo Martelli",
            ",",
            "Vicente Martin",
            ",",
            "Laura Ortiz",
            ""
        ],
        "abstract": "A new interactive quantum zero-knowledge protocol for identity authentication\nimplementable in currently available quantum cryptographic devices is proposed\nand demonstrated. The protocol design involves a verifier and a prover knowing\na pre-shared secret, and the acceptance or rejection of the proof is determined\nby the quantum bit error rate. It has been implemented in modified Quantum Key\nDistribution devices executing two fundamental cases. In the first case, all\nplayers are honest, while in the second case, one of the users is a malicious\nplayer. We demonstrate an increase of the quantum bit error rate around 25% in\nthe latter case compared to the case of honesty. The protocol has also been\nvalidated for distances from a back-to-back setup to more than 60 km between\nverifier and prover. The security and robustness of the protocol has been\nanalysed, demonstrating its completeness, soundness and zero-knowledge\nproperties.",
        "date": "Not Found"
    },
    {
        "title": "Title:Deep learning enhanced mixed integer optimization: Learning to reduce  model dimensionality",
        "authors": [
            "",
            "Authors:",
            "",
            "Niki Triantafyllou",
            ",",
            "Maria M. Papathanasiou",
            ""
        ],
        "abstract": "This work introduces a framework to address the computational complexity\ninherent in Mixed-Integer Programming (MIP) models by harnessing the potential\nof deep learning. We compare the effectiveness of (a) feed-forward neural\nnetworks (ANN) and (b) convolutional neural networks (CNN) in approximating the\nactive dimensions within MIP problems. We utilize multi-label classification to\naccount for more than one active dimension. To enhance the framework's\nperformance, we employ Bayesian optimization for hyperparameter tuning, aiming\nto maximize sample-level accuracy. The primary objective is to train the neural\nnetworks to predict all active dimensions accurately, thereby maximizing the\noccurrence of global optimum solutions. We apply this framework to a flow-based\nfacility location allocation Mixed-Integer Linear Programming (MILP)\nformulation that describes long-term investment planning and medium-term\ntactical planning in a personalized medicine supply chain for cell therapy\nmanufacturing and distribution.",
        "date": "Not Found"
    },
    {
        "title": "Title:Fully-blind Neural Network Based Equalization for Severe Nonlinear  Distortions in 112 Gbit/s Passive Optical Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Vincent Lauinger",
            ",",
            "Patrick Matalla",
            ",",
            "Jonas Ney",
            ",",
            "Norbert Wehn",
            ",",
            "Sebastian Randel",
            ",",
            "Laurent Schmalen",
            ""
        ],
        "abstract": "We demonstrate and evaluate a fully-blind digital signal processing (DSP)\nchain for 100G passive optical networks (PONs), and analyze different equalizer\ntopologies based on neural networks with low hardware complexity.",
        "date": "Not Found"
    },
    {
        "title": "Title:Idempotent cellular automata and their natural order",
        "authors": [
            "",
            "Authors:",
            "",
            "Alonso Castillo-Ramirez",
            ",",
            "Maria G. Maga\u00f1a-Chavez",
            ",",
            "Eduardo Veliz-Quintero",
            ""
        ],
        "abstract": "Motivated by the search for idempotent cellular automata (CA), we study CA\nthat act almost as the identity unless they read a fixed pattern $p$. We show\nthat constant and symmetrical patterns always produce idempotent CA, and we\ncharacterize the quasi-constant patterns that produce idempotent CA. Our\nresults are valid for CA over an arbitrary group $G$. Moreover, we study the\nsemigroup theoretic natural partial order defined on idempotent CA. If $G$ is\ninfinite, we prove that there is an infinite independent set of idempotent CA,\nand if $G$ has an element of infinite order, we prove that there is an infinite\nincreasing chain of idempotent CA.",
        "date": "Not Found"
    },
    {
        "title": "Title:MITS-GAN: Safeguarding Medical Imaging from Tampering with Generative  Adversarial Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Giovanni Pasqualino",
            ",",
            "Luca Guarnera",
            ",",
            "Alessandro Ortis",
            ",",
            "Sebastiano Battiato",
            ""
        ],
        "abstract": "The progress in generative models, particularly Generative Adversarial\nNetworks (GANs), opened new possibilities for image generation but raised\nconcerns about potential malicious uses, especially in sensitive areas like\nmedical imaging. This study introduces MITS-GAN, a novel approach to prevent\ntampering in medical images, with a specific focus on CT scans. The approach\ndisrupts the output of the attacker's CT-GAN architecture by introducing\nimperceptible but yet precise perturbations. Specifically, the proposed\napproach involves the introduction of appropriate Gaussian noise to the input\nas a protective measure against various attacks. Our method aims to enhance\ntamper resistance, comparing favorably to existing techniques. Experimental\nresults on a CT scan dataset demonstrate MITS-GAN's superior performance,\nemphasizing its ability to generate tamper-resistant images with negligible\nartifacts. As image tampering in medical domains poses life-threatening risks,\nour proactive approach contributes to the responsible and ethical use of\ngenerative models. This work provides a foundation for future research in\ncountering cyber threats in medical imaging. Models and codes are publicly\navailable at the following link\n\\url{https://iplab.dmi.unict.it/MITS-GAN-2024/}.",
        "date": "Not Found"
    },
    {
        "title": "Title:SymTC: A Symbiotic Transformer-CNN Net for Instance Segmentation of  Lumbar Spine MRI",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiasong Chen",
            ",",
            "Linchen Qian",
            ",",
            "Linhai Ma",
            ",",
            "Timur Urakov",
            ",",
            "Weiyong Gu",
            ",",
            "Liang Liang",
            ""
        ],
        "abstract": "Intervertebral disc disease, a prevalent ailment, frequently leads to\nintermittent or persistent low back pain, and diagnosing and assessing of this\ndisease rely on accurate measurement of vertebral bone and intervertebral disc\ngeometries from lumbar MR images. Deep neural network (DNN) models may assist\nclinicians with more efficient image segmentation of individual instances\n(disks and vertebrae) of the lumbar spine in an automated way, which is termed\nas instance image segmentation. In this work, we proposed SymTC, an innovative\nlumbar spine MR image segmentation model that combines the strengths of\nTransformer and Convolutional Neural Network (CNN). Specifically, we designed a\nparallel dual-path architecture to merge CNN layers and Transformer layers, and\nwe integrated a novel position embedding into the self-attention module of\nTransformer, enhancing the utilization of positional information for more\naccurate segmentation. To further improves model performance, we introduced a\nnew data augmentation technique to create synthetic yet realistic MR image\ndataset, named SSMSpine, which is made publicly available. We evaluated our\nSymTC and the other 15 existing image segmentation models on our private\nin-house dataset and the public SSMSpine dataset, using two metrics, Dice\nSimilarity Coefficient and 95% Hausdorff Distance. The results show that our\nSymTC has the best performance for segmenting vertebral bones and\nintervertebral discs in lumbar spine MR images. The SymTC code and SSMSpine\ndataset are available at https://github.com/jiasongchen/SymTC.",
        "date": "Not Found"
    },
    {
        "title": "Title:CT Liver Segmentation via PVT-based Encoding and Refined Decoding",
        "authors": [
            "",
            "Authors:",
            "",
            "Debesh Jha",
            ",",
            "Nikhil Kumar Tomar",
            ",",
            "Koushik Biswas",
            ",",
            "Gorkem Durak",
            ",",
            "Alpay Medetalibeyoglu",
            ",",
            "Matthew Antalek",
            ",",
            "Yury Velichko",
            ",",
            "Daniela Ladner",
            ",",
            "Amir Borhani",
            ",",
            "Ulas Bagci",
            ""
        ],
        "abstract": "Accurate liver segmentation from CT scans is essential for computer-aided\ndiagnosis and treatment planning. Recently, Vision Transformers achieved a\ncompetitive performance in computer vision tasks compared to convolutional\nneural networks due to their exceptional ability to learn global\nrepresentations. However, they often struggle with scalability, memory\nconstraints, and computational inefficiency, particularly in handling\nhigh-resolution medical images. To overcome scalability and efficiency issues,\nwe propose a novel deep learning approach, \\textit{\\textbf{PVTFormer}}, that is\nbuilt upon a pretrained pyramid vision transformer (PVT v2) combined with\nadvanced residual upsampling and decoder block. By integrating a refined\nfeature channel approach with hierarchical decoding strategy, PVTFormer\ngenerates high quality segmentation masks by enhancing semantic features.\nRigorous evaluation of the proposed method on Liver Tumor Segmentation\nBenchmark (LiTS) 2017 demonstrates that our proposed architecture not only\nachieves a high dice coefficient of 86.78\\%, mIoU of 78.46\\%, but also obtains\na low HD of 3.50. The results underscore PVTFormer's efficacy in setting a new\nbenchmark for state-of-the-art liver segmentation methods. The source code of\nthe proposed PVTFormer is available at\n\\url{https://github.com/DebeshJha/PVTFormer}.",
        "date": "Not Found"
    },
    {
        "title": "Title:Automatic 3D Multi-modal Ultrasound Segmentation of Human Placenta using  Fusion Strategies and Deep Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Sonit Singh",
            ",",
            "Gordon Stevenson",
            ",",
            "Brendan Mein",
            ",",
            "Alec Welsh",
            ",",
            "Arcot Sowmya",
            ""
        ],
        "abstract": "Purpose: Ultrasound is the most commonly used medical imaging modality for\ndiagnosis and screening in clinical practice. Due to its safety profile,\nnoninvasive nature and portability, ultrasound is the primary imaging modality\nfor fetal assessment in pregnancy. Current ultrasound processing methods are\neither manual or semi-automatic and are therefore laborious, time-consuming and\nprone to errors, and automation would go a long way in addressing these\nchallenges. Automated identification of placental changes at earlier gestation\ncould facilitate potential therapies for conditions such as fetal growth\nrestriction and pre-eclampsia that are currently detected only at late\ngestational age, potentially preventing perinatal morbidity and mortality.\nMethods: We propose an automatic three-dimensional multi-modal (B-mode and\npower Doppler) ultrasound segmentation of the human placenta using deep\nlearning combined with different fusion strategies.We collected data containing\nBmode and power Doppler ultrasound scans for 400 studies.\nResults: We evaluated different fusion strategies and state-of-the-art image\nsegmentation networks for placenta segmentation based on standard overlap- and\nboundary-based metrics. We found that multimodal information in the form of\nB-mode and power Doppler scans outperform any single modality. Furthermore, we\nfound that B-mode and power Doppler input scans fused at the data level provide\nthe best results with a mean Dice Similarity Coefficient (DSC) of 0.849.\nConclusion: We conclude that the multi-modal approach of combining B-mode and\npower Doppler scans is effective in segmenting the placenta from 3D ultrasound\nscans in a fully automated manner and is robust to quality variation of the\ndatasets.",
        "date": "Not Found"
    },
    {
        "title": "Title:Uncertainty Modeling in Ultrasound Image Segmentation for Precise Fetal  Biometric Measurements",
        "authors": [
            "",
            "Authors:",
            "",
            "Shuge Lei",
            ""
        ],
        "abstract": "Medical image segmentation, particularly in the context of ultrasound data,\nis a crucial aspect of computer vision and medical imaging. This paper delves\ninto the complexities of uncertainty in the segmentation process, focusing on\nfetal head and femur ultrasound images. The proposed methodology involves\nextracting target contours and exploring techniques for precise parameter\nmeasurement. Uncertainty modeling methods are employed to enhance the training\nand testing processes of the segmentation network. The study reveals that the\naverage absolute error in fetal head circumference measurement is 8.0833mm,\nwith a relative error of 4.7347%. Similarly, the average absolute error in\nfetal femur measurement is 2.6163mm, with a relative error of 6.3336%.\nUncertainty modeling experiments employing Test-Time Augmentation (TTA)\ndemonstrate effective interpretability of data uncertainty on both datasets.\nThis suggests that incorporating data uncertainty based on the TTA method can\nsupport clinical practitioners in making informed decisions and obtaining more\nreliable measurement results in practical clinical applications. The paper\ncontributes to the advancement of ultrasound image segmentation, addressing\ncritical challenges and improving the reliability of biometric measurements.",
        "date": "Not Found"
    },
    {
        "title": "Title:Generalized Reference Signals Design for Integrated Communication and  Sensing with High-Resolution Algorithms",
        "authors": [
            "",
            "Authors:",
            "",
            "Rui Zhang",
            ",",
            "Shawn Tsai",
            ",",
            "Jiaying Ren",
            ",",
            "Oliver Sun",
            ""
        ],
        "abstract": "Delay and Doppler ambiguities of comb reference signal patterns are\ninvestigated through time delay and Doppler shift detection using\nhigh-resolution sensing algorithms. Necessary conditions of designing comb RS\npatterns and synthesizing different reference signal patterns in general are\nderived under the goal of eliminating side peaks and preserving the best\nachievable ambiguity performance of OFDM signals for target detection.",
        "date": "Not Found"
    },
    {
        "title": "Title:Comb Reference Signal Pattern Design for Integrated Communication and  Sensing",
        "authors": [
            "",
            "Authors:",
            "",
            "Rui Zhang",
            ",",
            "Shawn Tsai",
            ",",
            "Tzu-Han Chou",
            ",",
            "Jiaying Ren",
            ""
        ],
        "abstract": "Ambiguity performances of reference signal patterns for integrated\ncommunication and sensing are studied via time delay and Doppler shift\ndetection. A reference signal pattern with a staggering offset of a linear\nslope relatively prime to the transmission comb is suggested for\nlow-complexity, standard-resolution sensing algorithms. We also propose an\nextended guard interval design to extend the maximum time delay for post-FFT\nsensing algorithms.",
        "date": "Not Found"
    },
    {
        "title": "Title:The role of shared randomness in quantum state certification with  unentangled measurements",
        "authors": [
            "",
            "Authors:",
            "",
            "Yuhan Liu",
            ",",
            "Jayadev Acharya",
            ""
        ],
        "abstract": "Given $n$ copies of an unknown quantum state $\\rho\\in\\mathbb{C}^{d\\times d}$,\nquantum state certification is the task of determining whether $\\rho=\\rho_0$ or\n$\\|\\rho-\\rho_0\\|_1>\\varepsilon$, where $\\rho_0$ is a known reference state. We\nstudy quantum state certification using unentangled quantum measurements,\nnamely measurements which operate only on one copy of $\\rho$ at a time. When\nthere is a common source of shared randomness available and the unentangled\nmeasurements are chosen based on this randomness, prior work has shown that\n$\\Theta(d^{3/2}/\\varepsilon^2)$ copies are necessary and sufficient. This holds\neven when the measurements are allowed to be chosen adaptively. We consider\ndeterministic measurement schemes (as opposed to randomized) and demonstrate\nthat ${\\Theta}(d^2/\\varepsilon^2)$ copies are necessary and sufficient for\nstate certification. This shows a separation between algorithms with and\nwithout shared randomness.\nWe develop a unified lower bound framework for both fixed and randomized\nmeasurements, under the same theoretical framework that relates the hardness of\ntesting to the well-established L\\\"uders rule. More precisely, we obtain lower\nbounds for randomized and fixed schemes as a function of the eigenvalues of the\nL\\\"uders channel which characterizes one possible post-measurement state\ntransformation.",
        "date": "Not Found"
    },
    {
        "title": "Title:Accelerating Distributed Stochastic Optimization via Self-Repellent  Random Walks",
        "authors": [
            "",
            "Authors:",
            "",
            "Jie Hu",
            ",",
            "Vishwaraj Doshi",
            ",",
            "Do Young Eun",
            ""
        ],
        "abstract": "We study a family of distributed stochastic optimization algorithms where\ngradients are sampled by a token traversing a network of agents in random-walk\nfashion. Typically, these random-walks are chosen to be Markov chains that\nasymptotically sample from a desired target distribution, and play a critical\nrole in the convergence of the optimization iterates. In this paper, we take a\nnovel approach by replacing the standard linear Markovian token by one which\nfollows a nonlinear Markov chain - namely the Self-Repellent Radom Walk (SRRW).\nDefined for any given 'base' Markov chain, the SRRW, parameterized by a\npositive scalar {\\alpha}, is less likely to transition to states that were\nhighly visited in the past, thus the name. In the context of MCMC sampling on a\ngraph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW\nachieves O(1/{\\alpha}) decrease in the asymptotic variance for sampling. We\npropose the use of a 'generalized' version of the SRRW to drive token\nalgorithms for distributed stochastic optimization in the form of stochastic\napproximation, termed SA-SRRW. We prove that the optimization iterate errors of\nthe resulting SA-SRRW converge to zero almost surely and prove a central limit\ntheorem, deriving the explicit form of the resulting asymptotic covariance\nmatrix corresponding to iterate errors. This asymptotic covariance is always\nsmaller than that of an algorithm driven by the base Markov chain and decreases\nat rate O(1/{\\alpha}^2) - the performance benefit of using SRRW thereby\namplified in the stochastic optimization context. Empirical results support our\ntheoretical findings.",
        "date": "Not Found"
    },
    {
        "title": "Title:Decades of Transformation: Evolution of the NASA Astrophysics Data  System's Infrastructure",
        "authors": [
            "",
            "Authors:",
            "",
            "Alberto Accomazzi",
            ""
        ],
        "abstract": "The NASA Astrophysics Data System (ADS) is the primary Digital Library portal\nfor researchers in astronomy and astrophysics. Over the past 30 years, the ADS\nhas gone from being an astronomy-focused bibliographic database to an open\ndigital library system supporting research in space and (soon) earth sciences.\nThis paper describes the evolution of the ADS system, its capabilities, and the\ntechnological infrastructure underpinning it.\nWe give an overview of the ADS's original architecture, constructed primarily\naround simple database models. This bespoke system allowed for the efficient\nindexing of metadata and citations, the digitization and archival of full-text\narticles, and the rapid development of discipline-specific capabilities running\non commodity hardware. The move towards a cloud-based microservices\narchitecture and an open-source search engine in the late 2010s marked a\nsignificant shift, bringing full-text search capabilities, a modern API, higher\nuptime, more reliable data retrieval, and integration of advanced\nvisualizations and analytics.\nAnother crucial evolution came with the gradual and ongoing incorporation of\nMachine Learning and Natural Language Processing algorithms in our data\npipelines. Originally used for information extraction and classification tasks,\nNLP and ML techniques are now being developed to improve metadata enrichment,\nsearch, notifications, and recommendations. we describe how these computational\ntechniques are being embedded into our software infrastructure, the challenges\nfaced, and the benefits reaped.\nFinally, we conclude by describing the future prospects of ADS and its\nongoing expansion, discussing the challenges of managing an interdisciplinary\ninformation system in the era of AI and Open Science, where information is\nabundant, technology is transformative, but their trustworthiness can be\nelusive.",
        "date": "Not Found"
    },
    {
        "title": "Title:An Empirical Study on the Impact of Positional Encoding in  Transformer-based Monaural Speech Enhancement",
        "authors": [
            "",
            "Authors:",
            "",
            "Qiquan Zhang",
            ",",
            "Meng Ge",
            ",",
            "Hongxu Zhu",
            ",",
            "Eliathamby Ambikairajah",
            ",",
            "Qi Song",
            ",",
            "Zhaoheng Ni",
            ",",
            "Haizhou Li",
            ""
        ],
        "abstract": "Transformer architecture has enabled recent progress in speech enhancement.\nSince Transformers are position-agostic, positional encoding is the de facto\nstandard component used to enable Transformers to distinguish the order of\nelements in a sequence. However, it remains unclear how positional encoding\nexactly impacts speech enhancement based on Transformer architectures. In this\npaper, we perform a comprehensive empirical study evaluating five positional\nencoding methods, i.e., Sinusoidal and learned absolute position embedding\n(APE), T5-RPE, KERPLE, as well as the Transformer without positional encoding\n(No-Pos), across both causal and noncausal configurations. We conduct extensive\nspeech enhancement experiments, involving spectral mapping and masking methods.\nOur findings establish that positional encoding is not quite helpful for the\nmodels in a causal configuration, which indicates that causal attention may\nimplicitly incorporate position information. In a noncausal configuration, the\nmodels significantly benefit from the use of positional encoding. In addition,\nwe find that among the four position embeddings, relative position embeddings\noutperform APEs.",
        "date": "Not Found"
    },
    {
        "title": "Title:Parameter Selection for Analyzing Conversations with Autism Spectrum  Disorder",
        "authors": [
            "",
            "Authors:",
            "",
            "Tahiya Chowdhury",
            ",",
            "Veronica Romero",
            ",",
            "Amanda Stent",
            ""
        ],
        "abstract": "The diagnosis of autism spectrum disorder (ASD) is a complex, challenging\ntask as it depends on the analysis of interactional behaviors by psychologists\nrather than the use of biochemical diagnostics. In this paper, we present a\nmodeling approach to ASD diagnosis by analyzing acoustic/prosodic and\nlinguistic features extracted from diagnostic conversations between a\npsychologist and children who either are typically developing (TD) or have ASD.\nWe compare the contributions of different features across a range of\nconversation tasks. We focus on finding a minimal set of parameters that\ncharacterize conversational behaviors of children with ASD. Because ASD is\ndiagnosed through conversational interaction, in addition to analyzing the\nbehavior of the children, we also investigate whether the psychologist's\nconversational behaviors vary across diagnostic groups. Our results can\nfacilitate fine-grained analysis of conversation data for children with ASD to\nsupport diagnosis and intervention.",
        "date": "Not Found"
    },
    {
        "title": "Title:ISAC with Backscattering RFID Tags: Joint Beamforming Design",
        "authors": [
            "",
            "Authors:",
            "",
            "Hao Luo",
            ",",
            "Umut Demirhan",
            ",",
            "Ahmed Alkhateeb",
            ""
        ],
        "abstract": "In this paper, we explore an integrated sensing and communication (ISAC)\nsystem with backscattering RFID tags. In this setup, an access point employs a\ncommunication beam to serve a user while leveraging a sensing beam to detect an\nRFID tag. Under the total transmit power constraint of the system, our\nobjective is to design sensing and communication beams by considering the tag\ndetection and communication requirements. First, we adopt zero-forcing to\ndesign the beamforming vectors, followed by solving a convex optimization\nproblem to determine the power allocation between sensing and communication.\nThen, we study a joint beamforming design problem with the goal of minimizing\nthe total transmit power while satisfying the tag detection and communication\nrequirements. To resolve this, we re-formulate the non-convex constraints into\nconvex second-order cone constraints. The simulation results demonstrate that,\nunder different communication SINR requirements, joint beamforming optimization\noutperforms the zero-forcing-based method in terms of achievable detection\ndistance, offering a promising approach for the ISAC-backscattering systems.",
        "date": "Not Found"
    },
    {
        "title": "Title:BreastRegNet: A Deep Learning Framework for Registration of Breast  Faxitron and Histopathology Images",
        "authors": [
            "",
            "Authors:",
            "",
            "Negar Golestani",
            ",",
            "Aihui Wang",
            ",",
            "Gregory R Bean",
            ",",
            "Mirabela Rusu",
            ""
        ],
        "abstract": "A standard treatment protocol for breast cancer entails administering\nneoadjuvant therapy followed by surgical removal of the tumor and surrounding\ntissue. Pathologists typically rely on cabinet X-ray radiographs, known as\nFaxitron, to examine the excised breast tissue and diagnose the extent of\nresidual disease. However, accurately determining the location, size, and\nfocality of residual cancer can be challenging, and incorrect assessments can\nlead to clinical consequences. The utilization of automated methods can improve\nthe histopathology process, allowing pathologists to choose regions for\nsampling more effectively and precisely. Despite the recognized necessity,\nthere are currently no such methods available. Training such automated\ndetection models require accurate ground truth labels on ex-vivo radiology\nimages, which can be acquired through registering Faxitron and histopathology\nimages and mapping the extent of cancer from histopathology to x-ray images.\nThis study introduces a deep learning-based image registration approach trained\non mono-modal synthetic image pairs. The models were trained using data from 50\nwomen who received neoadjuvant chemotherapy and underwent surgery. The results\ndemonstrate that our method is faster and yields significantly lower average\nlandmark error ($2.1\\pm1.96$ mm) over the state-of-the-art iterative\n($4.43\\pm4.1$ mm) and deep learning ($4.02\\pm3.15$ mm) approaches. Improved\nperformance of our approach in integrating radiology and pathology information\nfacilitates generating large datasets, which allows training models for more\naccurate breast cancer detection.",
        "date": "Not Found"
    },
    {
        "title": "Title:Multilingual Visual Speech Recognition with a Single Model by Learning  with Discrete Visual Speech Units",
        "authors": [
            "",
            "Authors:",
            "",
            "Minsu Kim",
            ",",
            "Jeong Hun Yeo",
            ",",
            "Jeongsoo Choi",
            ",",
            "Se Jin Park",
            ",",
            "Yong Man Ro",
            ""
        ],
        "abstract": "This paper explores sentence-level Multilingual Visual Speech Recognition\nwith a single model for the first time. As the massive multilingual modeling of\nvisual data requires huge computational costs, we propose a novel strategy,\nprocessing with visual speech units. Motivated by the recent success of the\naudio speech unit, the proposed visual speech unit is obtained by discretizing\nthe visual speech features extracted from the self-supervised visual speech\nmodel. To correctly capture multilingual visual speech, we first train the\nself-supervised visual speech model on 5,512 hours of multilingual audio-visual\ndata. Through analysis, we verify that the visual speech units mainly contain\nviseme information while suppressing non-linguistic information. By using the\nvisual speech units as the inputs of our system, we pre-train the model to\npredict corresponding text outputs on massive multilingual data constructed by\nmerging several VSR databases. As both the inputs and outputs are discrete, we\ncan greatly improve the training efficiency compared to the standard VSR\ntraining. Specifically, the input data size is reduced to 0.016% of the\noriginal video inputs. In order to complement the insufficient visual\ninformation in speech recognition, we apply curriculum learning where the\ninputs of the system begin with audio-visual speech units and gradually change\nto visual speech units. After pre-training, the model is finetuned on\ncontinuous features. We set new state-of-the-art multilingual VSR performances\nby achieving comparable performances to the previous language-specific VSR\nmodels, with a single trained model.",
        "date": "Not Found"
    },
    {
        "title": "Title:Slicer Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Hang Zhang",
            ",",
            "Xiang Chen",
            ",",
            "Rongguang Wang",
            ",",
            "Renjiu Hu",
            ",",
            "Dongdong Liu",
            ",",
            "Gaolei Li",
            ""
        ],
        "abstract": "In medical imaging, scans often reveal objects with varied contrasts but\nconsistent internal intensities or textures. This characteristic enables the\nuse of low-frequency approximations for tasks such as segmentation and\ndeformation field estimation. Yet, integrating this concept into neural network\narchitectures for medical image analysis remains underexplored. In this paper,\nwe propose the Slicer Network, a novel architecture designed to leverage these\ntraits. Comprising an encoder utilizing models like vision transformers for\nfeature extraction and a slicer employing a learnable bilateral grid, the\nSlicer Network strategically refines and upsamples feature maps via a\nsplatting-blurring-slicing process. This introduces an edge-preserving\nlow-frequency approximation for the network outcome, effectively enlarging the\neffective receptive field. The enhancement not only reduces computational\ncomplexity but also boosts overall performance. Experiments across different\nmedical imaging applications, including unsupervised and keypoints-based image\nregistration and lesion segmentation, have verified the Slicer Network's\nimproved accuracy and efficiency.",
        "date": "Not Found"
    },
    {
        "title": "Title:FREED++: Improving RL Agents for Fragment-Based Molecule Generation by  Thorough Reproduction",
        "authors": [
            "",
            "Authors:",
            "",
            "Alexander Telepov",
            ",",
            "Artem Tsypin",
            ",",
            "Kuzma Khrabrov",
            ",",
            "Sergey Yakukhnov",
            ",",
            "Pavel Strashnov",
            ",",
            "Petr Zhilyaev",
            ",",
            "Egor Rumiantsev",
            ",",
            "Daniel Ezhov",
            ",",
            "Manvel Avetisian",
            ",",
            "Olga Popova",
            ",",
            "Artur Kadurin",
            ""
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure\nwith desired biological functionality, e.g., an ability to activate or suppress\na specific protein via binding to it. Molecular docking is a common technique\nfor evaluating protein-molecule interactions. Recently, Reinforcement Learning\n(RL) has emerged as a promising approach to generating molecules with the\ndocking score (DS) as a reward. In this work, we reproduce, scrutinize and\nimprove the recent RL model for molecule generation called FREED\n(arXiv:2110.01219). Extensive evaluation of the proposed method reveals several\nlimitations and challenges despite the outstanding results reported for three\ntarget proteins. Our contributions include fixing numerous implementation bugs\nand simplifying the model while increasing its quality, significantly extending\nexperiments, and conducting an accurate comparison with current\nstate-of-the-art methods for protein-conditioned molecule generation. We show\nthat the resulting fixed model is capable of producing molecules with superior\ndocking scores compared to alternative approaches.",
        "date": "Not Found"
    },
    {
        "title": "Title:Interplay between depth and width for interpolation in neural ODEs",
        "authors": [
            "",
            "Authors:",
            "",
            "Antonio \u00c1lvarez-L\u00f3pez",
            ",",
            "Arselane Hadj Slimane",
            ",",
            "Enrique Zuazua Iriondo",
            ""
        ],
        "abstract": "Neural ordinary differential equations (neural ODEs) have emerged as a\nnatural tool for supervised learning from a control perspective, yet a complete\nunderstanding of their optimal architecture remains elusive. In this work, we\nexamine the interplay between their width $p$ and number of layer transitions\n$L$ (effectively the depth $L+1$). Specifically, we assess the model\nexpressivity in terms of its capacity to interpolate either a finite dataset\n$D$ comprising $N$ pairs of points or two probability measures in\n$\\mathbb{R}^d$ within a Wasserstein error margin $\\varepsilon>0$. Our findings\nreveal a balancing trade-off between $p$ and $L$, with $L$ scaling as\n$O(1+N/p)$ for dataset interpolation, and\n$L=O\\left(1+(p\\varepsilon^d)^{-1}\\right)$ for measure interpolation.\nIn the autonomous case, where $L=0$, a separate study is required, which we\nundertake focusing on dataset interpolation. We address the relaxed problem of\n$\\varepsilon$-approximate controllability and establish an error decay of\n$\\varepsilon\\sim O(\\log(p)p^{-1/d})$. This decay rate is a consequence of\napplying a universal approximation theorem to a custom-built Lipschitz vector\nfield that interpolates $D$. In the high-dimensional setting, we further\ndemonstrate that $p=O(N)$ neurons are likely sufficient to achieve exact\ncontrol.",
        "date": "Not Found"
    },
    {
        "title": "Title:Qadence: a differentiable interface for digital-analog programs",
        "authors": [
            "",
            "Authors:",
            "",
            "Dominik Seitz",
            ",",
            "Niklas Heim",
            ",",
            "Jo\u00e3o P. Moutinho",
            ",",
            "Roland Guichard",
            ",",
            "Vytautas Abramavicius",
            ",",
            "Aleksander Wennersteen",
            ",",
            "Gert-Jan Both",
            ",",
            "Anton Quelle",
            ",",
            "Caroline de Groot",
            ",",
            "Gergana V. Velikova",
            ",",
            "Vincent E. Elfving",
            ",",
            "Mario Dagrada",
            ""
        ],
        "abstract": "Digital-analog quantum computing (DAQC) is an alternative paradigm for\nuniversal quantum computation combining digital single-qubit gates with global\nanalog operations acting on a register of interacting qubits. Currently, no\navailable open-source software is tailored to express, differentiate, and\nexecute programs within the DAQC paradigm. In this work, we address this\nshortfall by presenting Qadence, a high-level programming interface for\nbuilding complex digital-analog quantum programs developed at Pasqal. Thanks to\nits flexible interface, native differentiability, and focus on real-device\nexecution, Qadence aims at advancing research on variational quantum algorithms\nbuilt for native DAQC platforms such as Rydberg atom arrays.",
        "date": "Not Found"
    },
    {
        "title": "Title:Design of Initial Guess Low Thrust Trajectories Using Clohessy-Wiltshire  Equations",
        "authors": [
            "",
            "Authors:",
            "",
            "Madhusudan Vijayakumar",
            ",",
            "William Skamser",
            ",",
            "Ossama Abdelkhalik",
            ""
        ],
        "abstract": "The commercial interest in producing low-cost space missions by exploiting\nthe superior propellant management of low-thrust propulsion technology has\nbecome increasingly popular. Typical to such missions is the design of transfer\ntrajectories between desired targets. This is a complex and computationally\nexpensive process. Additionally, the optimal solvers used to generate these\ntrajectories are extremely sensitive to initial guesses. One way to overcome\nthis challenge is to use a reasonably approximate trajectory as an initial\nguess on optimal solvers. This paper presents a flexible approach to generating\nvery low thrust trajectories. The initial guess is obtained from a flexible\nsemi-analytic approach that can provide both planar and three-dimensional\ninitial guess trajectories for various design scenarios like orbit raising,\norbit insertion, phasing, and rendezvous. NASA's Evolutionary Mission\nTrajectory Generator (EMTG) and General Mission Analysis Tool (GMAT) are used\nas optimal solvers in this analysis. Numerical case studies are presented in\nthis paper.",
        "date": "Not Found"
    },
    {
        "title": "Title:False Discovery Rate Control for Gaussian Graphical Models via  Neighborhood Screening",
        "authors": [
            "",
            "Authors:",
            "",
            "Taulant Koka",
            ",",
            "Jasin Machkour",
            ",",
            "Michael Muma",
            ""
        ],
        "abstract": "Gaussian graphical models emerge in a wide range of fields. They model the\nstatistical relationships between variables as a graph, where an edge between\ntwo variables indicates conditional dependence. Unfortunately, well-established\nestimators, such as the graphical lasso or neighborhood selection, are known to\nbe susceptible to a high prevalence of false edge detections. False detections\nmay encourage inaccurate or even incorrect scientific interpretations, with\nmajor implications in applications, such as biomedicine or healthcare. In this\npaper, we introduce a nodewise variable selection approach to graph learning\nand provably control the false discovery rate of the selected edge set at a\nself-estimated level. A novel fusion method of the individual neighborhoods\noutputs an undirected graph estimate. The proposed method is parameter-free and\ndoes not require tuning by the user. Benchmarks against competing false\ndiscovery rate controlling methods in numerical experiments considering\ndifferent graph topologies show a significant gain in performance.",
        "date": "Not Found"
    },
    {
        "title": "Title:Ventricular Segmentation: A Brief Comparison of U-Net Derivatives",
        "authors": [
            "",
            "Authors:",
            "",
            "Ketan Suhaas Saichandran",
            ""
        ],
        "abstract": "Medical imaging refers to the technologies and methods utilized to view the\nhuman body and its inside, in order to diagnose, monitor, or even treat medical\ndisorders. This paper aims to explore the application of deep learning\ntechniques in the semantic segmentation of Cardiac short-axis MRI (Magnetic\nResonance Imaging) images, aiming to enhance the diagnosis, monitoring, and\ntreatment of medical disorders related to the heart. The focus centers on\nimplementing various architectures that are derivatives of U-Net, to\neffectively isolate specific parts of the heart for comprehensive anatomical\nand functional analysis. Through a combination of images, graphs, and\nquantitative metrics, the efficacy of the models and their predictions are\nshowcased. Additionally, this paper addresses encountered challenges and\noutline strategies for future improvements. This abstract provides a concise\noverview of the efforts in utilizing deep learning for cardiac image\nsegmentation, emphasizing both the accomplishments and areas for further\nrefinement.",
        "date": "Not Found"
    },
    {
        "title": "Title:An optimization-based equilibrium measure describes non-equilibrium  steady state dynamics: application to edge of chaos",
        "authors": [
            "",
            "Authors:",
            "",
            "Junbin Qiu",
            ",",
            "Haiping Huang",
            ""
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning,\nnon-linear physics and neuroscience. However, the dynamics is non-linear,\nstochastic and particularly non-gradient, i.e., the driving force can not be\nwritten as gradient of a potential. These features make analytic studies very\nchallenging. The common tool is to use path integral approach or dynamical\nmean-field theory, but the drawback is one has to solve the\nintegro-differential or dynamical mean-field equations, which is\ncomputationally expensive and has no closed form solutions in general. From the\naspect of associated Fokker-Planck equation, the steady state solution is\ngenerally unknown. Here, we treat searching for the steady state as an\noptimization problem, and construct an approximate potential closely related to\nthe speed of the dynamics, and find that searching for the ground state of this\npotential is equivalent to running a stochastic gradient dynamics. The\nresultant stationary state follows exactly the canonical Boltzmann measure.\nWithin this framework, the quenched disorder intrinsic in the neural networks\ncan be averaged out by applying the replica method. Our theory reproduces the\nwell-known result of edge-of-chaos, and further the order parameters\ncharacterizing the continuous transition are derived, and different scaling\nbehavior with respect to inverse temperature in both sides of the transition is\nalso revealed. Our method opens the door to analytically study the steady state\nlandscape of the deterministic or stochastic high dimensional dynamics.",
        "date": "Not Found"
    },
    {
        "title": "Title:FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder",
        "authors": [
            "",
            "Authors:",
            "",
            "Tan Dat Nguyen",
            ",",
            "Ji-Hoon Kim",
            ",",
            "Youngjoon Jang",
            ",",
            "Jaehun Kim",
            ",",
            "Joon Son Chung",
            ""
        ],
        "abstract": "The goal of this paper is to generate realistic audio with a lightweight and\nfast diffusion-based vocoder, named FreGrad. Our framework consists of the\nfollowing three key components: (1) We employ discrete wavelet transform that\ndecomposes a complicated waveform into sub-band wavelets, which helps FreGrad\nto operate on a simple and concise feature space, (2) We design a\nfrequency-aware dilated convolution that elevates frequency awareness,\nresulting in generating speech with accurate frequency information, and (3) We\nintroduce a bag of tricks that boosts the generation quality of the proposed\nmodel. In our experiments, FreGrad achieves 3.7 times faster training time and\n2.2 times faster inference speed compared to our baseline while reducing the\nmodel size by 0.6 times (only 1.78M parameters) without sacrificing the output\nquality. Audio samples are available at:\nhttps://mm.kaist.ac.kr/projects/FreGrad.",
        "date": "Not Found"
    },
    {
        "title": "Title:Interpolatory Necessary Optimality Conditions for Reduced-order Modeling  of Parametric Linear Time-invariant Systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Petar Mlinari\u0107",
            ",",
            "Peter Benner",
            ",",
            "Serkan Gugercin",
            ""
        ],
        "abstract": "Interpolatory necessary optimality conditions for $\\mathcal{H}_2$-optimal\nreduced-order modeling of non-parametric linear time-invariant (LTI) systems\nare known and well-investigated. In this work, using the general framework of\n$\\mathcal{L}_2$-optimal reduced-order modeling of parametric stationary\nproblems, we derive interpolatory $\\mathcal{H}_2 \\otimes\n\\mathcal{L}_2$-optimality conditions for parametric LTI systems with a general\npole-residue form. We then specialize this result to recover known conditions\nfor systems with parameter-independent poles and develop new conditions for a\ncertain class of systems with parameter-dependent poles.",
        "date": "Not Found"
    },
    {
        "title": "Title:Lower Bounds for Maximum Weight Bisections of Graphs with Bounded  Degrees",
        "authors": [
            "",
            "Authors:",
            "",
            "Stefanie Gerke",
            ",",
            "Gregory Gutin",
            ",",
            "Anders Yeo",
            ",",
            "Yacong Zhou",
            ""
        ],
        "abstract": "A bisection in a graph is a cut in which the number of vertices in the two\nparts differ by at most 1. In this paper, we give lower bounds for the maximum\nweight of bisections of edge-weighted graphs with bounded maximum degree. Our\nresults improve a bound of Lee, Loh, and Sudakov (J. Comb. Th. Ser. B 103\n(2013)) for (unweighted) maximum bisections in graphs whose maximum degree is\neither even or equals 3, and for almost all graphs. We show that a tight lower\nbound for maximum size of bisections in 3-regular graphs obtained by Bollob\\'as\nand Scott (J. Graph Th. 46 (2004)) can be extended to weighted subcubic graphs.\nWe also consider edge-weighted triangle-free subcubic graphs and show that a\nmuch better lower bound (than for edge-weighted subcubic graphs) holds for such\ngraphs especially if we exclude $K_{1,3}$. We pose three conjectures.",
        "date": "Not Found"
    },
    {
        "title": "Title:Learning shallow quantum circuits",
        "authors": [
            "",
            "Authors:",
            "",
            "Hsin-Yuan Huang",
            ",",
            "Yunchao Liu",
            ",",
            "Michael Broughton",
            ",",
            "Isaac Kim",
            ",",
            "Anurag Anshu",
            ",",
            "Zeph Landau",
            ",",
            "Jarrod R. McClean",
            ""
        ],
        "abstract": "Despite fundamental interests in learning quantum circuits, the existence of\na computationally efficient algorithm for learning shallow quantum circuits\nremains an open question. Because shallow quantum circuits can generate\ndistributions that are classically hard to sample from, existing learning\nalgorithms do not apply. In this work, we present a polynomial-time classical\nalgorithm for learning the description of any unknown $n$-qubit shallow quantum\ncircuit $U$ (with arbitrary unknown architecture) within a small diamond\ndistance using single-qubit measurement data on the output states of $U$. We\nalso provide a polynomial-time classical algorithm for learning the description\nof any unknown $n$-qubit state $\\lvert \\psi \\rangle = U \\lvert 0^n \\rangle$\nprepared by a shallow quantum circuit $U$ (on a 2D lattice) within a small\ntrace distance using single-qubit measurements on copies of $\\lvert \\psi\n\\rangle$. Our approach uses a quantum circuit representation based on local\ninversions and a technique to combine these inversions. This circuit\nrepresentation yields an optimization landscape that can be efficiently\nnavigated and enables efficient learning of quantum circuits that are\nclassically hard to simulate.",
        "date": "Not Found"
    },
    {
        "title": "Title:Comparison analysis between standard polysomnographic data and  in-ear-EEG signals: A preliminary study",
        "authors": [
            "",
            "Authors:",
            "",
            "Gianpaolo Palo",
            ",",
            "Luigi Fiorillo",
            ",",
            "Giuliana Monachino",
            ",",
            "Michal Bechny",
            ",",
            "Mark Melnykowycz",
            ",",
            "Athina Tzovara",
            ",",
            "Valentina Agostini",
            ",",
            "Francesca Dalia Faraci",
            ""
        ],
        "abstract": "Study Objectives: Polysomnography (PSG) currently serves as the benchmark for\nevaluating sleep disorders. Its discomfort, impracticality for home-use, and\nintroduction of bias in sleep quality assessment necessitate the exploration of\nless invasive, cost-effective, and portable alternatives. One promising\ncontender is the in-ear-EEG sensor, which offers advantages in terms of\ncomfort, fixed electrode positions, resistance to electromagnetic interference,\nand user-friendliness. This study aims to establish a methodology to assess the\nsimilarity between the in-ear-EEG signal and standard PSG.\nMethods: We assess the agreement between the PSG and in-ear-EEG derived\nhypnograms. We extract features in the time- and frequency- domain from PSG and\nin-ear-EEG 30-second epochs. We only consider the epochs where the PSG-scorers\nand the in-ear-EEG-scorers were in agreement. We introduce a methodology to\nquantify the similarity between PSG derivations and the single-channel\nin-ear-EEG. The approach relies on a comparison of distributions of selected\nfeatures -- extracted for each sleep stage and subject on both PSG and the\nin-ear-EEG signals -- via a Jensen-Shannon Divergence Feature-based Similarity\nIndex (JSD-FSI).\nResults: We found a high intra-scorer variability, mainly due to the\nuncertainty the scorers had in evaluating the in-ear-EEG signals. We show that\nthe similarity between PSG and in-ear-EEG signals is high (JSD-FSI: 0.61 +/-\n0.06 in awake, 0.60 +/- 0.07 in NREM and 0.51 +/- 0.08 in REM), and in line\nwith the similarity values computed independently on standard\nPSG-channel-combinations.\nConclusions: In-ear-EEG is a valuable solution for home-based sleep\nmonitoring, however further studies with a larger and more heterogeneous\ndataset are needed.",
        "date": "Not Found"
    },
    {
        "title": "Title:Lower Ricci Curvature for Efficient Community Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Yun Jin Park",
            ",",
            "Didong Li",
            ""
        ],
        "abstract": "This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and\nscale-free discrete curvature designed to enhance community detection in\nnetworks. Addressing the computational challenges posed by existing\ncurvature-based methods, LRC offers a streamlined approach with linear\ncomputational complexity, making it well-suited for large-scale network\nanalysis. We further develop an LRC-based preprocessing method that effectively\naugments popular community detection algorithms. Through comprehensive\nsimulations and applications on real-world datasets, including the NCAA\nfootball league network, the DBLP collaboration network, the Amazon product\nco-purchasing network, and the YouTube social network, we demonstrate the\nefficacy of our method in significantly improving the performance of various\ncommunity detection algorithms.",
        "date": "Not Found"
    },
    {
        "title": "Title:Sub2Full: split spectrum to boost OCT despeckling without clean data",
        "authors": [
            "",
            "Authors:",
            "",
            "Lingyun Wang",
            ",",
            "Jose A Sahel",
            ",",
            "Shaohua Pi",
            ""
        ],
        "abstract": "Optical coherence tomography (OCT) suffers from speckle noise, causing the\ndeterioration of image quality, especially in high-resolution modalities like\nvisible light OCT (vis-OCT). The potential of conventional supervised deep\nlearning denoising methods is limited by the difficulty of obtaining clean\ndata. Here, we proposed an innovative self-supervised strategy called Sub2Full\n(S2F) for OCT despeckling without clean data. This approach works by acquiring\ntwo repeated B-scans, splitting the spectrum of the first repeat as a\nlow-resolution input, and utilizing the full spectrum of the second repeat as\nthe high-resolution target. The proposed method was validated on vis-OCT\nretinal images visualizing sublaminar structures in outer retina and\ndemonstrated superior performance over conventional Noise2Noise and Noise2Void\nschemes. The code is available at\nhttps://github.com/PittOCT/Sub2Full-OCT-Denoising.",
        "date": "Not Found"
    },
    {
        "title": "Title:Few-shot learning for COVID-19 Chest X-Ray Classification with  Imbalanced Data: An Inter vs. Intra Domain Study",
        "authors": [
            "",
            "Authors:",
            "",
            "Alejandro Gal\u00e1n-Cuenca",
            ",",
            "Antonio Javier Gallego",
            ",",
            "Marcelo Saval-Calvo",
            ",",
            "Antonio Pertusa",
            ""
        ],
        "abstract": "Medical image datasets are essential for training models used in\ncomputer-aided diagnosis, treatment planning, and medical research. However,\nsome challenges are associated with these datasets, including variability in\ndata distribution, data scarcity, and transfer learning issues when using\nmodels pre-trained from generic images. This work studies the effect of these\nchallenges at the intra- and inter-domain level in few-shot learning scenarios\nwith severe data imbalance. For this, we propose a methodology based on Siamese\nneural networks in which a series of techniques are integrated to mitigate the\neffects of data scarcity and distribution imbalance. Specifically, different\ninitialization and data augmentation methods are analyzed, and four adaptations\nto Siamese networks of solutions to deal with imbalanced data are introduced,\nincluding data balancing and weighted loss, both separately and combined, and\nwith a different balance of pairing ratios. Moreover, we also assess the\ninference process considering four classifiers, namely Histogram, $k$NN, SVM,\nand Random Forest. Evaluation is performed on three chest X-ray datasets with\nannotated cases of both positive and negative COVID-19 diagnoses. The accuracy\nof each technique proposed for the Siamese architecture is analyzed separately\nand their results are compared to those obtained using equivalent methods on a\nstate-of-the-art CNN. We conclude that the introduced techniques offer\npromising improvements over the baseline in almost all cases, and that the\nselection of the technique may vary depending on the amount of data available\nand the level of imbalance.",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Yiqun Lin",
            ",",
            "Liang Pan",
            ",",
            "Yi Li",
            ",",
            "Ziwei Liu",
            ",",
            "Xiaomeng Li",
            ""
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet\nchallenging problems in structural bioinformatics. Intrinsically, potential\nfunction sites in protein surfaces are determined by both geometric and\nchemical features. However, existing works only consider handcrafted or\nindividually learned chemical features from the atom type and extract geometric\nfeatures independently. Here, we identify two key properties of effective\nprotein surface learning: 1) relationship among atoms: atoms are linked with\neach other by covalent bonds to form biomolecules instead of appearing alone,\nleading to the significance of modeling the relationship among atoms in\nchemical feature learning. 2) hierarchical feature interaction: the neighboring\nresidue effect validates the significance of hierarchical feature interaction\namong atoms and between surface points and atoms (or residues). In this paper,\nwe present a principled framework based on deep learning techniques, namely\nHierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for\nprotein surface analysis by bridging chemical and geometric features with\nhierarchical interactions. Extensive experiments demonstrate that our method\noutperforms the prior state-of-the-art method by 2.3% in site prediction task\nand 3.2% in interaction matching task, respectively. Our code is available at\nhttps://github.com/xmed-lab/HCGNet.",
        "date": "Not Found"
    },
    {
        "title": "Title:In Memory of Martin Davis",
        "authors": [
            "",
            "Authors:",
            "",
            "Wesley Calvert",
            ",",
            "Valentina Harizanov",
            ",",
            "Eugenio G. Omodeo",
            ",",
            "Alberto Policriti",
            ",",
            "Alexandra Shlapentokh",
            ""
        ],
        "abstract": "The present paper gives an account for the general mathematical reader of the\nlife and work of Martin Davis. Since two rather comprehensive autobiographical\naccounts and two long biographical interviews already exist, the present work\nfocusses on Davis's scientific achievements, including work on computably\nenumerable sets, universal Turing machines, the hyperarithmetical hierarchy,\nneural networks, Hilbert's Tenth Problem, and automated reasoning.",
        "date": "Not Found"
    },
    {
        "title": "Title:A Kaczmarz-inspired approach to accelerate the optimization of neural  network wavefunctions",
        "authors": [
            "",
            "Authors:",
            "",
            "Gil Goldshlager",
            ",",
            "Nilin Abrahamsen",
            ",",
            "Lin Lin",
            ""
        ],
        "abstract": "Neural network wavefunctions optimized using the variational Monte Carlo\nmethod have been shown to produce highly accurate results for the electronic\nstructure of atoms and small molecules, but the high cost of optimizing such\nwavefunctions prevents their application to larger systems. We propose the\nSubsampled Projected-Increment Natural Gradient Descent (SPRING) optimizer to\nreduce this bottleneck. SPRING combines ideas from the recently introduced\nminimum-step stochastic reconfiguration optimizer (MinSR) and the classical\nrandomized Kaczmarz method for solving linear least-squares problems. We\ndemonstrate that SPRING outperforms both MinSR and the popular\nKronecker-Factored Approximate Curvature method (KFAC) across a number of small\natoms and molecules, given that the learning rates of all methods are optimally\ntuned. For example, on the oxygen atom, SPRING attains chemical accuracy after\nforty thousand training iterations, whereas both MinSR and KFAC fail to do so\neven after one hundred thousand iterations.",
        "date": "Not Found"
    },
    {
        "title": "Title:Quantum State Obfuscation from Classical Oracles",
        "authors": [
            "",
            "Authors:",
            "",
            "James Bartusek",
            ",",
            "Zvika Brakerski",
            ",",
            "Vinod Vaikuntanathan",
            ""
        ],
        "abstract": "A major unresolved question in quantum cryptography is whether it is possible\nto obfuscate arbitrary quantum computation. Indeed, there is much yet to\nunderstand about the feasibility of quantum obfuscation even in the classical\noracle model, where one is given for free the ability to obfuscate any\nclassical circuit.\nIn this work, we develop a new array of techniques that we use to construct a\nquantum state obfuscator, a powerful notion formalized recently by Coladangelo\nand Gunn (arXiv:2311.07794) in their pursuit of better software copy-protection\nschemes. Quantum state obfuscation refers to the task of compiling a quantum\nprogram, consisting of a quantum circuit $C$ with a classical description and\nan auxiliary quantum state $\\ket{\\psi}$, into a functionally-equivalent\nobfuscated quantum program that hides as much as possible about $C$ and\n$\\ket{\\psi}$. We prove the security of our obfuscator when applied to any\npseudo-deterministic quantum program, i.e. one that computes a (nearly)\ndeterministic classical input / classical output functionality. Our security\nproof is with respect to an efficient classical oracle, which may be\nheuristically instantiated using quantum-secure indistinguishability\nobfuscation for classical circuits.\nOur result improves upon the recent work of Bartusek, Kitagawa, Nishimaki and\nYamakawa (STOC 2023) who also showed how to obfuscate pseudo-deterministic\nquantum circuits in the classical oracle model, but only ones with a completely\nclassical description. Furthermore, our result answers a question of\nColadangelo and Gunn, who provide a construction of quantum state\nindistinguishability obfuscation with respect to a quantum oracle. Indeed, our\nquantum state obfuscator together with Coladangelo-Gunn gives the first\ncandidate realization of a ``best-possible'' copy-protection scheme for all\npolynomial-time functionalities.",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving PTM Site Prediction by Coupling of Multi-Granularity Structure  and Multi-Scale Sequence Representation",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhengyi Li",
            ",",
            "Menglu Li",
            ",",
            "Lida Zhu",
            ",",
            "Wen Zhang",
            ""
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a\nfundamental task in bioinformatics. Several computational methods have been\ndeveloped to predict PTM sites. However, existing methods ignore the structure\ninformation and merely utilize protein sequences. Furthermore, designing a more\nfine-grained structure representation learning method is urgently needed as PTM\nis a biological event that occurs at the atom granularity. In this paper, we\npropose a PTM site prediction method by Coupling of Multi-Granularity structure\nand Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically,\nmultigranularity structure-aware representation learning is designed to learn\nneighborhood structure representations at the amino acid, atom, and whole\nprotein granularity from AlphaFold predicted structures, followed by utilizing\ncontrastive learning to optimize the structure representations.Additionally,\nmulti-scale sequence representation learning is used to extract context\nsequence information, and motif generated by aligning all context sequences of\nPTM sites assists the prediction. Extensive experiments on three datasets show\nthat PTM-CMGMS outperforms the state-of-the-art methods.",
        "date": "Not Found"
    },
    {
        "title": "Title:PAC Codes: Sequential Decoding vs List Decoding",
        "authors": [
            "",
            "Authors:",
            "",
            "Mohammad Rowshan",
            ",",
            "Andreas Burg",
            ",",
            "Emanuele Viterbo",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Approximate Cross-validated Mean Estimates for Bayesian Hierarchical  Regression Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Amy X. Zhang",
            ",",
            "Le Bao",
            ",",
            "Changcheng Li",
            ",",
            "Michael J. Daniels",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Climate-Invariant Machine Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Tom Beucler",
            ",",
            "Pierre Gentine",
            ",",
            "Janni Yuval",
            ",",
            "Ankitesh Gupta",
            ",",
            "Liran Peng",
            ",",
            "Jerry Lin",
            ",",
            "Sungduk Yu",
            ",",
            "Stephan Rasp",
            ",",
            "Fiaz Ahmed",
            ",",
            "Paul A. O'Gorman",
            ",",
            "J. David Neelin",
            ",",
            "Nicholas J. Lutsko",
            ",",
            "Michael Pritchard",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:From Procedures, Objects, Actors, Components, Services, to Agents -- A  Comparative Analysis of the History and Evolution of Programming Abstractions",
        "authors": [
            "",
            "Authors:",
            "",
            "Jean-Pierre Briot",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Eternal Vertex Cover on Bipartite and Co-Bipartite Graphs",
        "authors": [
            "",
            "Authors:",
            "",
            "Neeldhara Misra",
            ",",
            "Saraswati Nanoti",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Survey on Modern Recommendation System based on Big Data",
        "authors": [
            "",
            "Authors:",
            "",
            "Anchen Sun",
            ",",
            "Yuanzhe Peng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:HaGRID - HAnd Gesture Recognition Image Dataset",
        "authors": [
            "",
            "Authors:",
            "",
            "Alexander Kapitanov",
            ",",
            "Karina Kvanchiani",
            ",",
            "Alexander Nagaev",
            ",",
            "Roman Kraynov",
            ",",
            "Andrei Makhliarchuk",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Study of an entropy dissipating finite volume scheme for a nonlocal  cross-diffusion system",
        "authors": [
            "",
            "Authors:",
            "",
            "Maxime Herda",
            ",",
            "Antoine Zurek",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:The $hp$-FEM applied to the Helmholtz equation with PML truncation does  not suffer from the pollution effect",
        "authors": [
            "",
            "Authors:",
            "",
            "Jeffrey Galkowski",
            ",",
            "David Lafontaine",
            ",",
            "Euan A. Spence",
            ",",
            "Jared Wunsch",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Lightweight Super-Resolution with Dual Regression Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Yong Guo",
            ",",
            "Jingdong Wang",
            ",",
            "Qi Chen",
            ",",
            "Jiezhang Cao",
            ",",
            "Zeshuai Deng",
            ",",
            "Yanwu Xu",
            ",",
            "Jian Chen",
            ",",
            "Mingkui Tan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Normality-Guided Distributional Reinforcement Learning for Continuous  Control",
        "authors": [
            "",
            "Authors:",
            "",
            "Ju-Seung Byun",
            ",",
            "Andrew Perrault",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Language Control Diffusion: Efficiently Scaling through Space, Time, and  Tasks",
        "authors": [
            "",
            "Authors:",
            "",
            "Edwin Zhang",
            ",",
            "Yujie Lu",
            ",",
            "William Wang",
            ",",
            "Amy Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Stochastic Network Calculus with Localized Application of Martingales",
        "authors": [
            "",
            "Authors:",
            "",
            "Anne Bouillard",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Waiting Nets: State Classes and Taxonomy",
        "authors": [
            "",
            "Authors:",
            "",
            "Lo\u00efc H\u00e9lou\u00ebt",
            ",",
            "Pranay Agrawal",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:An Embarrassingly Simple Baseline for Imbalanced Semi-Supervised  Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Hao Chen",
            ",",
            "Yue Fan",
            ",",
            "Yidong Wang",
            ",",
            "Jindong Wang",
            ",",
            "Bernt Schiele",
            ",",
            "Xing Xie",
            ",",
            "Marios Savvides",
            ",",
            "Bhiksha Raj",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Decision Diagram-Based Branch-and-Bound with Caching for Dominance and  Suboptimality Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Vianney Copp\u00e9",
            ",",
            "Xavier Gillard",
            ",",
            "Pierre Schaus",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:DMIS: Dynamic Mesh-based Importance Sampling for Training  Physics-Informed Neural Networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Zijiang Yang",
            ",",
            "Zhongwei Qiu",
            ",",
            "Dongmei Fu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Lower Bound on the Constant in the Fourier Min-Entropy/Influence  Conjecture",
        "authors": [
            "",
            "Authors:",
            "",
            "Aniruddha Biswas",
            ",",
            "Palash Sarkar",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Benchmarking Robustness of Multimodal Image-Text Models under  Distribution Shift",
        "authors": [
            "",
            "Authors:",
            "",
            "Jielin Qiu",
            ",",
            "Yi Zhu",
            ",",
            "Xingjian Shi",
            ",",
            "Florian Wenzel",
            ",",
            "Zhiqiang Tang",
            ",",
            "Ding Zhao",
            ",",
            "Bo Li",
            ",",
            "Mu Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:SUCRe: Leveraging Scene Structure for Underwater Color Restoration",
        "authors": [
            "",
            "Authors:",
            "",
            "Cl\u00e9mentin Boittiaux",
            ",",
            "Ricard Marxer",
            ",",
            "Claire Dune",
            ",",
            "Aur\u00e9lien Arnaubec",
            ",",
            "Maxime Ferrera",
            ",",
            "Vincent Hugel",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Data-Centric Artificial Intelligence",
        "authors": [
            "",
            "Authors:",
            "",
            "Johannes Jakubik",
            ",",
            "Michael V\u00f6ssing",
            ",",
            "Niklas K\u00fchl",
            ",",
            "Jannis Walk",
            ",",
            "Gerhard Satzger",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Detecting Change Intervals with Isolation Distributional Kernel",
        "authors": [
            "",
            "Authors:",
            "",
            "Yang Cao",
            ",",
            "Ye Zhu",
            ",",
            "Kai Ming Ting",
            ",",
            "Flora D. Salim",
            ",",
            "Hong Xian Li",
            ",",
            "Luxing Yang",
            ",",
            "Gang Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Skeletal Video Anomaly Detection using Deep Learning: Survey, Challenges  and Future Directions",
        "authors": [
            "",
            "Authors:",
            "",
            "Pratik K. Mishra",
            ",",
            "Alex Mihailidis",
            ",",
            "Shehroz S. Khan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Increasing biases can be more efficient than increasing weights",
        "authors": [
            "",
            "Authors:",
            "",
            "Carlo Metta",
            ",",
            "Marco Fantozzi",
            ",",
            "Andrea Papini",
            ",",
            "Gianluca Amato",
            ",",
            "Matteo Bergamaschi",
            ",",
            "Silvia Giulia Galfr\u00e8",
            ",",
            "Alessandro Marchetti",
            ",",
            "Michelangelo Vegli\u00f2",
            ",",
            "Maurizio Parton",
            ",",
            "Francesco Morandin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Free Lunch for Generating Effective Outlier Supervision",
        "authors": [
            "",
            "Authors:",
            "",
            "Sen Pei",
            ",",
            "Jiaxi Sun",
            ",",
            "Richard Yi Da Xu",
            ",",
            "Bin Fan",
            ",",
            "Shiming Xiang",
            ",",
            "Gaofeng Meng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Versatile Energy-Based Probabilistic Models for High Energy Physics",
        "authors": [
            "",
            "Authors:",
            "",
            "Taoli Cheng",
            ",",
            "Aaron Courville",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Semantic-Guided Generative Image Augmentation Method with Diffusion  Models for Image Classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Bohan Li",
            ",",
            "Xiao Xu",
            ",",
            "Xinghao Wang",
            ",",
            "Yutai Hou",
            ",",
            "Yunlong Feng",
            ",",
            "Feng Wang",
            ",",
            "Xuanliang Zhang",
            ",",
            "Qingfu Zhu",
            ",",
            "Wanxiang Che",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Unboxing Tree Ensembles for interpretability: a hierarchical  visualization tool and a multivariate optimal re-built tree",
        "authors": [
            "",
            "Authors:",
            "",
            "Giulia Di Teodoro",
            ",",
            "Marta Monaci",
            ",",
            "Laura Palagi",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Easy testability for posets",
        "authors": [
            "",
            "Authors:",
            "",
            "Panna T\u00edmea Fekete",
            ",",
            "G\u00e1bor Kun",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration  Measure",
        "authors": [
            "",
            "Authors:",
            "",
            "Hee Suk Yoon",
            ",",
            "Joshua Tian Jin Tee",
            ",",
            "Eunseop Yoon",
            ",",
            "Sunjae Yoon",
            ",",
            "Gwangsu Kim",
            ",",
            "Yingzhen Li",
            ",",
            "Chang D. Yoo",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Classical vs Quantum Advice and Proofs under Classically-Accessible  Oracle",
        "authors": [
            "",
            "Authors:",
            "",
            "Xingjian Li",
            ",",
            "Qipeng Liu",
            ",",
            "Angelos Pelecanos",
            ",",
            "Takashi Yamakawa",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Optimized Control-Centric Communication in Cooperative Adaptive Cruise  Control Systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Mahdi Razzaghpour",
            ",",
            "Shahriar Shahram",
            ",",
            "Rodolfo Valiente",
            ",",
            "Mahdi Zaman",
            ",",
            "Yaser P. Fallah",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Discovering mesoscopic descriptions of collective movement with neural  stochastic modelling",
        "authors": [
            "",
            "Authors:",
            "",
            "Utkarsh Pratiush",
            ",",
            "Arshed Nabeel",
            ",",
            "Vishwesha Guttal",
            ",",
            "Prathosh AP",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:X-CANIDS: Signal-Aware Explainable Intrusion Detection System for  Controller Area Network-Based In-Vehicle Network",
        "authors": [
            "",
            "Authors:",
            "",
            "Seonghoon Jeong",
            ",",
            "Sangho Lee",
            ",",
            "Hwejae Lee",
            ",",
            "Huy Kang Kim",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Curvature-Balanced Feature Manifold Learning for Long-Tailed  Classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Yanbiao Ma",
            ",",
            "Licheng Jiao",
            ",",
            "Fang Liu",
            ",",
            "Shuyuan Yang",
            ",",
            "Xu Liu",
            ",",
            "Lingling Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Adjusted Wasserstein Distributionally Robust Estimator in Statistical  Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Yiling Xie",
            ",",
            "Xiaoming Huo",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Training Neural Networks is NP-Hard in Fixed Dimension",
        "authors": [
            "",
            "Authors:",
            "",
            "Vincent Froese",
            ",",
            "Christoph Hertrich",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Conservation and stability in a discontinuous Galerkin method for the  vector invariant spherical shallow water equations",
        "authors": [
            "",
            "Authors:",
            "",
            "Kieran Ricardo",
            ",",
            "David Lee",
            ",",
            "Kenneth Duru",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Information Recovery-Driven Deep Incomplete Multiview Clustering Network",
        "authors": [
            "",
            "Authors:",
            "",
            "Chengliang Liu",
            ",",
            "Jie Wen",
            ",",
            "Zhihao Wu",
            ",",
            "Xiaoling Luo",
            ",",
            "Chao Huang",
            ",",
            "Yong Xu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On Mitigating the Utility-Loss in Differentially Private Learning: A new  Perspective by a Geometrically Inspired Kernel Approach",
        "authors": [
            "",
            "Authors:",
            "",
            "Mohit Kumar",
            ",",
            "Bernhard A. Moser",
            ",",
            "Lukas Fischer",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On a family of low-rank algorithms for large-scale algebraic Riccati  equations",
        "authors": [
            "",
            "Authors:",
            "",
            "Christian Bertram",
            ",",
            "Heike Fa\u00dfbender",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:An Optimized Error-controlled MPI Collective Framework Integrated with  Lossy Compression",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiajun Huang",
            ",",
            "Sheng Di",
            ",",
            "Xiaodong Yu",
            ",",
            "Yujia Zhai",
            ",",
            "Zhaorui Zhang",
            ",",
            "Jinyang Liu",
            ",",
            "Xiaoyi Lu",
            ",",
            "Ken Raffenetti",
            ",",
            "Hui Zhou",
            ",",
            "Kai Zhao",
            ",",
            "Zizhong Chen",
            ",",
            "Franck Cappello",
            ",",
            "Yanfei Guo",
            ",",
            "Rajeev Thakur",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:NeuroBench: A Framework for Benchmarking Neuromorphic Computing  Algorithms and Systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Jason Yik",
            ",",
            "Korneel Van den Berghe",
            ",",
            "Douwe den Blanken",
            ",",
            "Younes Bouhadjar",
            ",",
            "Maxime Fabre",
            ",",
            "Paul Hueber",
            ",",
            "Denis Kleyko",
            ",",
            "Noah Pacik-Nelson",
            ",",
            "Pao-Sheng Vincent Sun",
            ",",
            "Guangzhi Tang",
            ",",
            "Shenqi Wang",
            ",",
            "Biyan Zhou",
            ",",
            "Soikat Hasan Ahmed",
            ",",
            "George Vathakkattil Joseph",
            ",",
            "Benedetto Leto",
            ",",
            "Aurora Micheli",
            ",",
            "Anurag Kumar Mishra",
            ",",
            "Gregor Lenz",
            ",",
            "Tao Sun",
            ",",
            "Zergham Ahmed",
            ",",
            "Mahmoud Akl",
            ",",
            "Brian Anderson",
            ",",
            "Andreas G. Andreou",
            ",",
            "Chiara Bartolozzi",
            ",",
            "Arindam Basu",
            ",",
            "Petrut Bogdan",
            ",",
            "Sander Bohte",
            ",",
            "Sonia Buckley",
            ",",
            "Gert Cauwenberghs",
            ",",
            "Elisabetta Chicca",
            ",",
            "Federico Corradi",
            ",",
            "Guido de Croon",
            ",",
            "Andreea Danielescu",
            ",",
            "Anurag Daram",
            ",",
            "Mike Davies",
            ",",
            "Yigit Demirag",
            ",",
            "Jason Eshraghian",
            ",",
            "Tobias Fischer",
            ",",
            "Jeremy Forest",
            ",",
            "Vittorio Fra",
            ",",
            "Steve Furber",
            ",",
            "P. Michael Furlong",
            ",",
            "William Gilpin",
            ",",
            "Aditya Gilra",
            ",",
            "Hector A. Gonzalez",
            ",",
            "Giacomo Indiveri",
            ",",
            "Siddharth Joshi",
            ",",
            "Vedant Karia",
            ",",
            "Lyes Khacef",
            ",  et al. (49 additional authors not shown)"
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Accelerating Globally Optimal Consensus Maximization in Geometric Vision",
        "authors": [
            "",
            "Authors:",
            "",
            "Xinyue Zhang",
            ",",
            "Liangzu Peng",
            ",",
            "Wanting Xu",
            ",",
            "Laurent Kneip",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Black Box Variational Inference with a Deterministic Objective: Faster,  More Accurate, and Even More Black Box",
        "authors": [
            "",
            "Authors:",
            "",
            "Ryan Giordano",
            ",",
            "Martin Ingram",
            ",",
            "Tamara Broderick",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On Fast-Converged Deep Reinforcement Learning for Optimal Dispatch of  Large-Scale Power Systems under Transient Security Constraints",
        "authors": [
            "",
            "Authors:",
            "",
            "Tannan Xiao",
            ",",
            "Ying Chen",
            ",",
            "Han Diao",
            ",",
            "Shaowei Huang",
            ",",
            "Chen Shen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:CodeKGC: Code Language Model for Generative Knowledge Graph Construction",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhen Bi",
            ",",
            "Jing Chen",
            ",",
            "Yinuo Jiang",
            ",",
            "Feiyu Xiong",
            ",",
            "Wei Guo",
            ",",
            "Huajun Chen",
            ",",
            "Ningyu Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Hyperbolic Image-Text Representations",
        "authors": [
            "",
            "Authors:",
            "",
            "Karan Desai",
            ",",
            "Maximilian Nickel",
            ",",
            "Tanmay Rajpurohit",
            ",",
            "Justin Johnson",
            ",",
            "Ramakrishna Vedantam",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Conversational Process Modeling: Can Generative AI Empower Domain  Experts in Creating and Redesigning Process Models?",
        "authors": [
            "",
            "Authors:",
            "",
            "Nataliia Klievtsova",
            ",",
            "Janik-Vasily Benzin",
            ",",
            "Timotheus Kampik",
            ",",
            "Juergen Mangler",
            ",",
            "Stefanie Rinderle-Ma",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhancing Video Super-Resolution via Implicit Resampling-based Alignment",
        "authors": [
            "",
            "Authors:",
            "",
            "Kai Xu",
            ",",
            "Ziwei Yu",
            ",",
            "Xin Wang",
            ",",
            "Michael Bi Mi",
            ",",
            "Angela Yao",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Constrained BA Algorithm for Rate-Distortion and Distortion-Rate  Functions",
        "authors": [
            "",
            "Authors:",
            "",
            "Lingyi Chen",
            ",",
            "Shitong Wu",
            ",",
            "Wenhao Ye",
            ",",
            "Huihui Wu",
            ",",
            "Wenyi Zhang",
            ",",
            "Hao Wu",
            ",",
            "Bo Bai",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Explainable Reinforcement Learning via a Causal World Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhongwei Yu",
            ",",
            "Jingqing Ruan",
            ",",
            "Dengpeng Xing",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Symbolic Regression on FPGAs for Fast Machine Learning Inference",
        "authors": [
            "",
            "Authors:",
            "",
            "Ho Fung Tsoi",
            ",",
            "Adrian Alan Pol",
            ",",
            "Vladimir Loncar",
            ",",
            "Ekaterina Govorkova",
            ",",
            "Miles Cranmer",
            ",",
            "Sridhara Dasu",
            ",",
            "Peter Elmer",
            ",",
            "Philip Harris",
            ",",
            "Isobel Ojalvo",
            ",",
            "Maurizio Pierini",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:CPMA: An Efficient Batch-Parallel Compressed Set Without Pointers",
        "authors": [
            "",
            "Authors:",
            "",
            "Brian Wheatman",
            ",",
            "Randal Burns",
            ",",
            "Ayd\u0131n Bulu\u00e7",
            ",",
            "Helen Xu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Multi-level Temporal-channel Speaker Retrieval for Zero-shot Voice  Conversion",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhichao Wang",
            ",",
            "Liumeng Xue",
            ",",
            "Qiuqiang Kong",
            ",",
            "Lei Xie",
            ",",
            "Yuanzhe Chen",
            ",",
            "Qiao Tian",
            ",",
            "Yuping Wang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:DAISM: Digital Approximate In-SRAM Multiplier-based Accelerator for DNN  Training and Inference",
        "authors": [
            "",
            "Authors:",
            "",
            "Lorenzo Sonnino",
            ",",
            "Shaswot Shresthamali",
            ",",
            "Yuan He",
            ",",
            "Masaaki Kondo",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:GSB: Group Superposition Binarization for Vision Transformer with  Limited Training Samples",
        "authors": [
            "",
            "Authors:",
            "",
            "Tian Gao",
            ",",
            "Cheng-Zhong Xu",
            ",",
            "Le Zhang",
            ",",
            "Hui Kong",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Machine-Made Media: Monitoring the Mobilization of Machine-Generated  Articles on Misinformation and Mainstream News Websites",
        "authors": [
            "",
            "Authors:",
            "",
            "Hans W. A. Hanley",
            ",",
            "Zakir Durumeric",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge  Graphs",
        "authors": [
            "",
            "Authors:",
            "",
            "Pengcheng Jiang",
            ",",
            "Cao Xiao",
            ",",
            "Adam Cross",
            ",",
            "Jimeng Sun",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Modeling and Control of a Novel Variable Stiffness Three DoFs Wrist",
        "authors": [
            "",
            "Authors:",
            "",
            "Giuseppe Milazzo",
            ",",
            "Manuel Giuseppe Catalano",
            ",",
            "Antonio Bicchi",
            ",",
            "Giorgio Grioli",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning  Coordination Problem",
        "authors": [
            "",
            "Authors:",
            "",
            "Paul Barde",
            ",",
            "Jakob Foerster",
            ",",
            "Derek Nowrouzezahrai",
            ",",
            "Amy Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Determinantal Point Process Attention Over Grid Cell Code Supports Out  of Distribution Generalization",
        "authors": [
            "",
            "Authors:",
            "",
            "Shanka Subhra Mondal",
            ",",
            "Steven Frankland",
            ",",
            "Taylor Webb",
            ",",
            "Jonathan D. Cohen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Relaxing the Additivity Constraints in Decentralized No-Regret  High-Dimensional Bayesian Optimization",
        "authors": [
            "",
            "Authors:",
            "",
            "Anthony Bardou",
            ",",
            "Patrick Thiran",
            ",",
            "Thomas Begin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Thought Cloning: Learning to Think while Acting by Imitating Human  Thinking",
        "authors": [
            "",
            "Authors:",
            "",
            "Shengran Hu",
            ",",
            "Jeff Clune",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Understanding Augmentation-based Self-Supervised Representation Learning  via RKHS Approximation and Regression",
        "authors": [
            "",
            "Authors:",
            "",
            "Runtian Zhai",
            ",",
            "Bingbin Liu",
            ",",
            "Andrej Risteski",
            ",",
            "Zico Kolter",
            ",",
            "Pradeep Ravikumar",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Yuanwen Yue",
            ",",
            "Sabarinath Mahadevan",
            ",",
            "Jonas Schult",
            ",",
            "Francis Engelmann",
            ",",
            "Bastian Leibe",
            ",",
            "Konrad Schindler",
            ",",
            "Theodora Kontogianni",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Simulation-Based Counterfactual Causal Discovery on Real World Driver  Behaviour",
        "authors": [
            "",
            "Authors:",
            "",
            "Rhys Howard",
            ",",
            "Lars Kunze",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Recovering Simultaneously Structured Data via Non-Convex Iteratively  Reweighted Least Squares",
        "authors": [
            "",
            "Authors:",
            "",
            "Christian K\u00fcmmerle",
            ",",
            "Johannes Maly",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Yet Another ICU Benchmark: A Flexible Multi-Center Framework for  Clinical ML",
        "authors": [
            "",
            "Authors:",
            "",
            "Robin van de Water",
            ",",
            "Hendrik Schmidt",
            ",",
            "Paul Elbers",
            ",",
            "Patrick Thoral",
            ",",
            "Bert Arnrich",
            ",",
            "Patrick Rockenschaub",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Detecting Check-Worthy Claims in Political Debates, Speeches, and  Interviews Using Audio Data",
        "authors": [
            "",
            "Authors:",
            "",
            "Petar Ivanov",
            ",",
            "Ivan Koychev",
            ",",
            "Momchil Hardalov",
            ",",
            "Preslav Nakov",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:UniCATS: A Unified Context-Aware Text-to-Speech Framework with  Contextual VQ-Diffusion and Vocoding",
        "authors": [
            "",
            "Authors:",
            "",
            "Chenpeng Du",
            ",",
            "Yiwei Guo",
            ",",
            "Feiyu Shen",
            ",",
            "Zhijun Liu",
            ",",
            "Zheng Liang",
            ",",
            "Xie Chen",
            ",",
            "Shuai Wang",
            ",",
            "Hui Zhang",
            ",",
            "Kai Yu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploiting Uncertainty for Querying Inconsistent Description Logics  Knowledge Bases",
        "authors": [
            "",
            "Authors:",
            "",
            "Riccardo Zese",
            ",",
            "Evelina Lamma",
            ",",
            "Fabrizio Riguzzi",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:CMMLU: Measuring massive multitask language understanding in Chinese",
        "authors": [
            "",
            "Authors:",
            "",
            "Haonan Li",
            ",",
            "Yixuan Zhang",
            ",",
            "Fajri Koto",
            ",",
            "Yifei Yang",
            ",",
            "Hai Zhao",
            ",",
            "Yeyun Gong",
            ",",
            "Nan Duan",
            ",",
            "Timothy Baldwin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Text-driven Talking Face Synthesis by Reprogramming Audio-driven Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jeongsoo Choi",
            ",",
            "Minsu Kim",
            ",",
            "Se Jin Park",
            ",",
            "Yong Man Ro",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:CQLite: Communication-Efficient Multi-Robot Exploration Using  Coverage-biased Distributed Q-Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Ehsan Latif",
            ",",
            "Ramviyas Parasuraman",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Trust in Software Supply Chains: Blockchain-Enabled SBOM and the AIBOM  Future",
        "authors": [
            "",
            "Authors:",
            "",
            "Boming Xia",
            ",",
            "Dawen Zhang",
            ",",
            "Yue Liu",
            ",",
            "Qinghua Lu",
            ",",
            "Zhenchang Xing",
            ",",
            "Liming Zhu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards Open Federated Learning Platforms: Survey and Vision from  Technical and Legal Perspectives",
        "authors": [
            "",
            "Authors:",
            "",
            "Moming Duan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Evidence of social learning across symbolic cultural barriers in sperm  whales",
        "authors": [
            "",
            "Authors:",
            "",
            "Ant\u00f3nio Leit\u00e3o",
            ",",
            "Maxime Lucas",
            ",",
            "Simone Poetto",
            ",",
            "Taylor A. Hersh",
            ",",
            "Shane Gero",
            ",",
            "David Gruber",
            ",",
            "Michael Bronstein",
            ",",
            "Giovanni Petri",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Point to the Hidden: Exposing Speech Audio Splicing via Signal Pointer  Nets",
        "authors": [
            "",
            "Authors:",
            "",
            "Denise Moussa",
            ",",
            "Germans Hirsch",
            ",",
            "Sebastian Wankerl",
            ",",
            "Christian Riess",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Quantity-Aware Coarse-to-Fine Correspondence for Image-to-Point Cloud  Registration",
        "authors": [
            "",
            "Authors:",
            "",
            "Gongxin Yao",
            ",",
            "Yixin Xuan",
            ",",
            "Yiwei Chen",
            ",",
            "Yu Pan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Knapsack: Connectedness, Path, and Shortest-Path",
        "authors": [
            "",
            "Authors:",
            "",
            "Palash Dey",
            ",",
            "Sudeshna Kolay",
            ",",
            "Sipra Singh",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA  Composition",
        "authors": [
            "",
            "Authors:",
            "",
            "Chengsong Huang",
            ",",
            "Qian Liu",
            ",",
            "Bill Yuchen Lin",
            ",",
            "Tianyu Pang",
            ",",
            "Chao Du",
            ",",
            "Min Lin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:CTAGE: Curvature-Based Topology-Aware Graph Embedding for Learning  Molecular Representations",
        "authors": [
            "",
            "Authors:",
            "",
            "Yili Chen",
            ",",
            "Zhengyu Li",
            ",",
            "Zheng Wan",
            ",",
            "Hui Yu",
            ",",
            "Xian Wei",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Sequence-Selection-Based Constellation Shaping for Nonlinear Channels",
        "authors": [
            "",
            "Authors:",
            "",
            "Stella Civelli",
            ",",
            "Enrico Forestieri",
            ",",
            "Marco Secondini",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Bounding the Interleaving Distance for Mapper Graphs with a Loss  Function",
        "authors": [
            "",
            "Authors:",
            "",
            "Erin W. Chambers",
            ",",
            "Elizabeth Munch",
            ",",
            "Sarah Percival",
            ",",
            "Bei Wang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:VulMatch: Binary-level Vulnerability Detection Through Signature",
        "authors": [
            "",
            "Authors:",
            "",
            "Zian Liu",
            ",",
            "Lei Pan",
            ",",
            "Chao Chen",
            ",",
            "Ejaz Ahmed",
            ",",
            "Shigang Liu",
            ",",
            "Jun Zhang",
            ",",
            "Dongxi Liu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Uncovering local aggregated air quality index with smartphone captured  images leveraging efficient deep convolutional neural network",
        "authors": [
            "",
            "Authors:",
            "",
            "Joyanta Jyoti Mondal",
            ",",
            "Md. Farhadul Islam",
            ",",
            "Raima Islam",
            ",",
            "Nowsin Kabir Rhidi",
            ",",
            "Sarfaraz Newaz",
            ",",
            "Meem Arafat Manab",
            ",",
            "A. B. M. Alim Al Islam",
            ",",
            "Jannatun Noor",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic  Localization",
        "authors": [
            "",
            "Authors:",
            "",
            "Joe Benton",
            ",",
            "Valentin De Bortoli",
            ",",
            "Arnaud Doucet",
            ",",
            "George Deligiannidis",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On Error Propagation of Diffusion Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Yangming Li",
            ",",
            "Mihaela van der Schaar",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Separate the Wheat from the Chaff: Model Deficiency Unlearning via  Parameter-Efficient Module Operation",
        "authors": [
            "",
            "Authors:",
            "",
            "Xinshuo Hu",
            ",",
            "Dongfang Li",
            ",",
            "Baotian Hu",
            ",",
            "Zihao Zheng",
            ",",
            "Zhenyu Liu",
            ",",
            "Min Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series  Forecasters",
        "authors": [
            "",
            "Authors:",
            "",
            "Ching Chang",
            ",",
            "Wei-Yao Wang",
            ",",
            "Wen-Chih Peng",
            ",",
            "Tien-Fu Chen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation  with Large Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Martin Weyssow",
            ",",
            "Xin Zhou",
            ",",
            "Kisub Kim",
            ",",
            "David Lo",
            ",",
            "Houari Sahraoui",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On the impossibility of discovering a formula for primes using AI",
        "authors": [
            "",
            "Authors:",
            "",
            "Alexander Kolpakov",
            ",",
            "Aidan Rocke",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Decoupled Contrastive Multi-View Clustering with High-Order Random Walks",
        "authors": [
            "",
            "Authors:",
            "",
            "Yiding Lu",
            ",",
            "Yijie Lin",
            ",",
            "Mouxing Yang",
            ",",
            "Dezhong Peng",
            ",",
            "Peng Hu",
            ",",
            "Xi Peng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet  Underwater Object Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Jingchun Zhou",
            ",",
            "Zongxin He",
            ",",
            "Kin-Man Lam",
            ",",
            "Yudong Wang",
            ",",
            "Weishi Zhang",
            ",",
            "ChunLe Guo",
            ",",
            "Chongyi Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Synergistic Multiscale Detail Refinement via Intrinsic Supervision for  Underwater Image Enhancement",
        "authors": [
            "",
            "Authors:",
            "",
            "Dehuan Zhang",
            ",",
            "Jingchun Zhou",
            ",",
            "ChunLe Guo",
            ",",
            "Weishi Zhang",
            ",",
            "Chongyi Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:BridgeData V2: A Dataset for Robot Learning at Scale",
        "authors": [
            "",
            "Authors:",
            "",
            "Homer Walke",
            ",",
            "Kevin Black",
            ",",
            "Abraham Lee",
            ",",
            "Moo Jin Kim",
            ",",
            "Max Du",
            ",",
            "Chongyi Zheng",
            ",",
            "Tony Zhao",
            ",",
            "Philippe Hansen-Estruch",
            ",",
            "Quan Vuong",
            ",",
            "Andre He",
            ",",
            "Vivek Myers",
            ",",
            "Kuan Fang",
            ",",
            "Chelsea Finn",
            ",",
            "Sergey Levine",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Prompt to Transfer: Sim-to-Real Transfer for Traffic Signal Control with  Prompt Learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Longchao Da",
            ",",
            "Minchiuan Gao",
            ",",
            "Hao Mei",
            ",",
            "Hua Wei",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Generative AI for Semantic Communication: Architecture, Challenges, and  Outlook",
        "authors": [
            "",
            "Authors:",
            "",
            "Le Xia",
            ",",
            "Yao Sun",
            ",",
            "Chengsi Liang",
            ",",
            "Lei Zhang",
            ",",
            "Muhammad Ali Imran",
            ",",
            "Dusit Niyato",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Dual-Decoder Consistency via Pseudo-Labels Guided Data Augmentation for  Semi-Supervised Medical Image Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Yuanbin Chen",
            ",",
            "Tao Wang",
            ",",
            "Hui Tang",
            ",",
            "Longxuan Zhao",
            ",",
            "Ruige Zong",
            ",",
            "Shun Chen",
            ",",
            "Tao Tan",
            ",",
            "Xinlin Zhang",
            ",",
            "Tong Tong",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Hierarchical Masked 3D Diffusion Model for Video Outpainting",
        "authors": [
            "",
            "Authors:",
            "",
            "Fanda Fan",
            ",",
            "Chaoxu Guo",
            ",",
            "Litong Gong",
            ",",
            "Biao Wang",
            ",",
            "Tiezheng Ge",
            ",",
            "Yuning Jiang",
            ",",
            "Chunjie Luo",
            ",",
            "Jianfeng Zhan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Chat Failures and Troubles: Reasons and Solutions",
        "authors": [
            "",
            "Authors:",
            "",
            "Manal Helal",
            ",",
            "Patrick Holthaus",
            ",",
            "Gabriella Lakatos",
            ",",
            "Farshid Amirabdollahian",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Latent Degradation Representation Constraint for Single Image Deraining",
        "authors": [
            "",
            "Authors:",
            "",
            "Yuhong He",
            ",",
            "Long Peng",
            ",",
            "Lu Wang",
            ",",
            "Jun Cheng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Truthful Interval Covering",
        "authors": [
            "",
            "Authors:",
            "",
            "Argyrios Deligkas",
            ",",
            "Aris Filos-Ratsikas",
            ",",
            "Alexandros A. Voudouris",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Panoptic Vision-Language Feature Fields",
        "authors": [
            "",
            "Authors:",
            "",
            "Haoran Chen",
            ",",
            "Kenneth Blomqvist",
            ",",
            "Francesco Milano",
            ",",
            "Roland Siegwart",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Less is More for Long Document Summary Evaluation by LLMs",
        "authors": [
            "",
            "Authors:",
            "",
            "Yunshu Wu",
            ",",
            "Hayate Iso",
            ",",
            "Pouya Pezeshkpour",
            ",",
            "Nikita Bhutani",
            ",",
            "Estevam Hruschka",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Virchow: A Million-Slide Digital Pathology Foundation Model",
        "authors": [
            "",
            "Authors:",
            "",
            "Eugene Vorontsov",
            ",",
            "Alican Bozkurt",
            ",",
            "Adam Casson",
            ",",
            "George Shaikovski",
            ",",
            "Michal Zelechowski",
            ",",
            "Siqi Liu",
            ",",
            "Kristen Severson",
            ",",
            "Eric Zimmermann",
            ",",
            "James Hall",
            ",",
            "Neil Tenenholtz",
            ",",
            "Nicolo Fusi",
            ",",
            "Philippe Mathieu",
            ",",
            "Alexander van Eck",
            ",",
            "Donghun Lee",
            ",",
            "Julian Viret",
            ",",
            "Eric Robert",
            ",",
            "Yi Kan Wang",
            ",",
            "Jeremy D. Kunz",
            ",",
            "Matthew C. H. Lee",
            ",",
            "Jan Bernhard",
            ",",
            "Ran A. Godrich",
            ",",
            "Gerard Oakley",
            ",",
            "Ewan Millar",
            ",",
            "Matthew Hanna",
            ",",
            "Juan Retamero",
            ",",
            "William A. Moye",
            ",",
            "Razik Yousfi",
            ",",
            "Christopher Kanan",
            ",",
            "David Klimstra",
            ",",
            "Brandon Rothrock",
            ",",
            "Thomas J. Fuchs",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Zero- and Few-shot Sound Event Localization and Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Kazuki Shimada",
            ",",
            "Kengo Uchida",
            ",",
            "Yuichiro Koyama",
            ",",
            "Takashi Shibuya",
            ",",
            "Shusuke Takahashi",
            ",",
            "Yuki Mitsufuji",
            ",",
            "Tatsuya Kawahara",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Projection-based Prediction-Correction Method for Distributed Consensus  Optimization",
        "authors": [
            "",
            "Authors:",
            "",
            "Han Long",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Higher-order Graph Convolutional Network with Flower-Petals Laplacians  on Simplicial Complexes",
        "authors": [
            "",
            "Authors:",
            "",
            "Yiming Huang",
            ",",
            "Yujie Zeng",
            ",",
            "Qiang Wu",
            ",",
            "Linyuan L\u00fc",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion  Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Yangming Li",
            ",",
            "Boris van Breugel",
            ",",
            "Mihaela van der Schaar",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:ICML 2023 Topological Deep Learning Challenge : Design and Results",
        "authors": [
            "",
            "Authors:",
            "",
            "Mathilde Papillon",
            ",",
            "Mustafa Hajij",
            ",",
            "Helen Jenne",
            ",",
            "Johan Mathe",
            ",",
            "Audun Myers",
            ",",
            "Theodore Papamarkou",
            ",",
            "Tolga Birdal",
            ",",
            "Tamal Dey",
            ",",
            "Tim Doster",
            ",",
            "Tegan Emerson",
            ",",
            "Gurusankar Gopalakrishnan",
            ",",
            "Devendra Govil",
            ",",
            "Aldo Guzm\u00e1n-S\u00e1enz",
            ",",
            "Henry Kvinge",
            ",",
            "Neal Livesay",
            ",",
            "Soham Mukherjee",
            ",",
            "Shreyas N. Samaga",
            ",",
            "Karthikeyan Natesan Ramamurthy",
            ",",
            "Maneel Reddy Karri",
            ",",
            "Paul Rosen",
            ",",
            "Sophia Sanborn",
            ",",
            "Robin Walters",
            ",",
            "Jens Agerberg",
            ",",
            "Sadrodin Barikbin",
            ",",
            "Claudio Battiloro",
            ",",
            "Gleb Bazhenov",
            ",",
            "Guillermo Bernardez",
            ",",
            "Aiden Brent",
            ",",
            "Sergio Escalera",
            ",",
            "Simone Fiorellino",
            ",",
            "Dmitrii Gavrilev",
            ",",
            "Mohammed Hassanin",
            ",",
            "Paul H\u00e4usner",
            ",",
            "Odin Hoff Gardaa",
            ",",
            "Abdelwahed Khamis",
            ",",
            "Manuel Lecha",
            ",",
            "German Magai",
            ",",
            "Tatiana Malygina",
            ",",
            "Rub\u00e9n Ballester",
            ",",
            "Kalyan Nadimpalli",
            ",",
            "Alexander Nikitin",
            ",",
            "Abraham Rabinowitz",
            ",",
            "Alessandro Salatiello",
            ",",
            "Simone Scardapane",
            ",",
            "Luca Scofano",
            ",",
            "Suraj Singh",
            ",  et al. (10 additional authors not shown)"
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:DualVC 2: Dynamic Masked Convolution for Unified Streaming and  Non-Streaming Voice Conversion",
        "authors": [
            "",
            "Authors:",
            "",
            "Ziqian Ning",
            ",",
            "Yuepeng Jiang",
            ",",
            "Pengcheng Zhu",
            ",",
            "Shuai Wang",
            ",",
            "Jixun Yao",
            ",",
            "Lei Xie",
            ",",
            "Mengxiao Bi",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Astroconformer: The Prospects of Analyzing Stellar Light Curves with  Transformer-Based Deep Learning Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jia-Shu Pan",
            ",",
            "Yuan-Sen Ting",
            ",",
            "Jie Yu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Compositional Program Generation for Few-Shot Systematic Generalization",
        "authors": [
            "",
            "Authors:",
            "",
            "Tim Klinger",
            ",",
            "Luke Liu",
            ",",
            "Soham Dan",
            ",",
            "Maxwell Crouse",
            ",",
            "Parikshit Ram",
            ",",
            "Alexander Gray",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:RTFS-Net: Recurrent time-frequency modelling for efficient audio-visual  speech separation",
        "authors": [
            "",
            "Authors:",
            "",
            "Samuel Pegg",
            ",",
            "Kai Li",
            ",",
            "Xiaolin Hu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:3D-Mol: A Novel Contrastive Learning Framework for Molecular Property  Prediction with 3D Information",
        "authors": [
            "",
            "Authors:",
            "",
            "Taojie Kuang",
            ",",
            "Yiming Ren",
            ",",
            "Zhixiang Ren",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Case Study: Securing MMU-less Linux Using CHERI",
        "authors": [
            "",
            "Authors:",
            "",
            "Hesham Almatary",
            ",",
            "Alfredo Mazzinghi",
            ",",
            "Robert N. M. Watson",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:MetaTool Benchmark for Large Language Models: Deciding Whether to Use  Tools and Which to Use",
        "authors": [
            "",
            "Authors:",
            "",
            "Yue Huang",
            ",",
            "Jiawen Shi",
            ",",
            "Yuan Li",
            ",",
            "Chenrui Fan",
            ",",
            "Siyuan Wu",
            ",",
            "Qihui Zhang",
            ",",
            "Yixin Liu",
            ",",
            "Pan Zhou",
            ",",
            "Yao Wan",
            ",",
            "Neil Zhenqiang Gong",
            ",",
            "Lichao Sun",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Risk-informed Resilience Planning of Transmission Systems Against Ice  Storms",
        "authors": [
            "",
            "Authors:",
            "",
            "Chenxi Hu",
            ",",
            "Yujia Li",
            ",",
            "Yunhe Hou",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Understanding the Humans Behind Online Misinformation: An Observational  Study Through the Lens of the COVID-19 Pandemic",
        "authors": [
            "",
            "Authors:",
            "",
            "Mohit Chandra",
            ",",
            "Anush Mattapalli",
            ",",
            "Munmun De Choudhury",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Pseudo-Generalized Dynamic View Synthesis from a Video",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiaoming Zhao",
            ",",
            "Alex Colburn",
            ",",
            "Fangchang Ma",
            ",",
            "Miguel Angel Bautista",
            ",",
            "Joshua M. Susskind",
            ",",
            "Alexander G. Schwing",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Circuit Component Reuse Across Tasks in Transformer Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jack Merullo",
            ",",
            "Carsten Eickhoff",
            ",",
            "Ellie Pavlick",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:GPT-Prompt Controlled Diffusion for Weakly-Supervised Semantic  Segmentation",
        "authors": [
            "",
            "Authors:",
            "",
            "Wangyu Wu",
            ",",
            "Tianhong Dai",
            ",",
            "Xiaowei Huang",
            ",",
            "Fei Ma",
            ",",
            "Jimin Xiao",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Real-time Photorealistic Dynamic Scene Representation and Rendering with  4D Gaussian Splatting",
        "authors": [
            "",
            "Authors:",
            "",
            "Zeyu Yang",
            ",",
            "Hongye Yang",
            ",",
            "Zijie Pan",
            ",",
            "Xiatian Zhu",
            ",",
            "Li Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Functional Invariants to Watermark Large Transformers",
        "authors": [
            "",
            "Authors:",
            "",
            "Pierre Fernandez",
            ",",
            "Guillaume Couairon",
            ",",
            "Teddy Furon",
            ",",
            "Matthijs Douze",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:FactCHD: Benchmarking Fact-Conflicting Hallucination Detection",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiang Chen",
            ",",
            "Duanzheng Song",
            ",",
            "Honghao Gui",
            ",",
            "Chenxi Wang",
            ",",
            "Ningyu Zhang",
            ",",
            "Jiang Yong",
            ",",
            "Fei Huang",
            ",",
            "Chengfei Lv",
            ",",
            "Dan Zhang",
            ",",
            "Huajun Chen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Enhancing High-Resolution 3D Generation through Pixel-wise Gradient  Clipping",
        "authors": [
            "",
            "Authors:",
            "",
            "Zijie Pan",
            ",",
            "Jiachen Lu",
            ",",
            "Xiatian Zhu",
            ",",
            "Li Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and  Uni-Modal Adapter",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhiyuan Liu",
            ",",
            "Sihang Li",
            ",",
            "Yanchen Luo",
            ",",
            "Hao Fei",
            ",",
            "Yixin Cao",
            ",",
            "Kenji Kawaguchi",
            ",",
            "Xiang Wang",
            ",",
            "Tat-Seng Chua",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Masked Hard-Attention Transformers and Boolean RASP Recognize Exactly  the Star-Free Languages",
        "authors": [
            "",
            "Authors:",
            "",
            "Dana Angluin",
            ",",
            "David Chiang",
            ",",
            "Andy Yang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:SpecTr: Fast Speculative Decoding via Optimal Transport",
        "authors": [
            "",
            "Authors:",
            "",
            "Ziteng Sun",
            ",",
            "Ananda Theertha Suresh",
            ",",
            "Jae Hun Ro",
            ",",
            "Ahmad Beirami",
            ",",
            "Himanshu Jain",
            ",",
            "Felix Yu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Mean Teacher DETR with Masked Feature Alignment: A Robust Domain  Adaptive Detection Transformer Framework",
        "authors": [
            "",
            "Authors:",
            "",
            "Weixi Weng",
            ",",
            "Chun Yuan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:An entropy stable discontinuous Galerkin method for the spherical  thermal shallow water equations",
        "authors": [
            "",
            "Authors:",
            "",
            "Kieran Ricardo",
            ",",
            "Kenneth Duru",
            ",",
            "David Lee",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Affective Video Content Analysis: Decade Review and New Perspectives",
        "authors": [
            "",
            "Authors:",
            "",
            "Junxiao Xue",
            ",",
            "Jie Wang",
            ",",
            "Xuecheng Wu",
            ",",
            "Qian Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Debiasing Algorithm through Model Adaptation",
        "authors": [
            "",
            "Authors:",
            "",
            "Tomasz Limisiewicz",
            ",",
            "David Mare\u010dek",
            ",",
            "Tom\u00e1\u0161 Musil",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Learn to Categorize or Categorize to Learn? Self-Coding for Generalized  Category Discovery",
        "authors": [
            "",
            "Authors:",
            "",
            "Sarah Rastegar",
            ",",
            "Hazel Doughty",
            ",",
            "Cees G. M. Snoek",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:BasisFormer: Attention-based Time Series Forecasting with Learnable and  Interpretable Basis",
        "authors": [
            "",
            "Authors:",
            "",
            "Zelin Ni",
            ",",
            "Hang Yu",
            ",",
            "Shizhan Liu",
            ",",
            "Jianguo Li",
            ",",
            "Weiyao Lin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Unexpected Improvements to Expected Improvement for Bayesian  Optimization",
        "authors": [
            "",
            "Authors:",
            "",
            "Sebastian Ament",
            ",",
            "Samuel Daulton",
            ",",
            "David Eriksson",
            ",",
            "Maximilian Balandat",
            ",",
            "Eytan Bakshy",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for  Fintech Applications",
        "authors": [
            "",
            "Authors:",
            "",
            "Chengyao Wen",
            ",",
            "Yin Lou",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Upper and lower bounds for the Lipschitz constant of random neural  networks",
        "authors": [
            "",
            "Authors:",
            "",
            "Paul Geuchen",
            ",",
            "Thomas Heindl",
            ",",
            "Dominik St\u00f6ger",
            ",",
            "Felix Voigtlaender",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
        "authors": [
            "",
            "Authors:",
            "",
            "Prasad Gabbur",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Generalized test utilities for long-tail performance in extreme  multi-label classification",
        "authors": [
            "",
            "Authors:",
            "",
            "Erik Schultheis",
            ",",
            "Marek Wydmuch",
            ",",
            "Wojciech Kot\u0142owski",
            ",",
            "Rohit Babbar",
            ",",
            "Krzysztof Dembczy\u0144ski",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model  Predictive Control",
        "authors": [
            "",
            "Authors:",
            "",
            "Zihao Wang",
            ",",
            "Zhe Wu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Disentangling the Potential Impacts of Papers into Diffusion,  Conformity, and Contribution Values",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhikai Xue",
            ",",
            "Guoxiu He",
            ",",
            "Zhuoren Jiang",
            ",",
            "Sichen Gu",
            ",",
            "Yangyang Kang",
            ",",
            "Star Zhao",
            ",",
            "Wei Lu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:PELS: A Lightweight and Flexible Peripheral Event Linking System for  Ultra-Low Power IoT Processors",
        "authors": [
            "",
            "Authors:",
            "",
            "Alessandro Ottaviano",
            ",",
            "Robert Balas",
            ",",
            "Philippe Sauter",
            ",",
            "Manuel Eggimann",
            ",",
            "Luca Benini",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:INTERVENOR: Prompt the Coding Ability of Large Language Models with the  Interactive Chain of Repairing",
        "authors": [
            "",
            "Authors:",
            "",
            "Hanbin Wang",
            ",",
            "Zhenghao Liu",
            ",",
            "Shuo Wang",
            ",",
            "Ganqu Cui",
            ",",
            "Ning Ding",
            ",",
            "Zhiyuan Liu",
            ",",
            "Ge Yu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel  Identification",
        "authors": [
            "",
            "Authors:",
            "",
            "Wenqing Wu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for  AI Accountability",
        "authors": [
            "",
            "Authors:",
            "",
            "Boming Xia",
            ",",
            "Qinghua Lu",
            ",",
            "Liming Zhu",
            ",",
            "Sung Une Lee",
            ",",
            "Yue Liu",
            ",",
            "Zhenchang Xing",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Large Language Model-Enhanced Algorithm Selection: Towards Comprehensive  Algorithm Representation",
        "authors": [
            "",
            "Authors:",
            "",
            "Xingyu Wu",
            ",",
            "Yan Zhong",
            ",",
            "Jibin Wu",
            ",",
            "Bingbing Jiang",
            ",",
            "Kay Chen Tan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Labeling Neural Representations with Inverse Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Kirill Bykov",
            ",",
            "Laura Kopf",
            ",",
            "Shinichi Nakajima",
            ",",
            "Marius Kloft",
            ",",
            "Marina M.-C. H\u00f6hne",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:UAE: Universal Anatomical Embedding on Multi-modality Medical Images",
        "authors": [
            "",
            "Authors:",
            "",
            "Xiaoyu Bai",
            ",",
            "Fan Bai",
            ",",
            "Xiaofei Huo",
            ",",
            "Jia Ge",
            ",",
            "Jingjing Lu",
            ",",
            "Xianghua Ye",
            ",",
            "Ke Yan",
            ",",
            "Yong Xia",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:DKiS: Decay weight invertible image steganography with private key",
        "authors": [
            "",
            "Authors:",
            "",
            "Hang Yang",
            ",",
            "Yitian Xu",
            ",",
            "Xuhua Liu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:GIVT: Generative Infinite-Vocabulary Transformers",
        "authors": [
            "",
            "Authors:",
            "",
            "Michael Tschannen",
            ",",
            "Cian Eastwood",
            ",",
            "Fabian Mentzer",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Comprehensive Study on Modelling and Control of Autonomous Underwater  Vehicle",
        "authors": [
            "",
            "Authors:",
            "",
            "Rajini Makam",
            ",",
            "Pruthviraj Mane",
            ",",
            "Suresh Sundaram",
            ",",
            "P. B. Sujit",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Assertion Enhanced Few-Shot Learning: Instructive Technique for Large  Language Models to Generate Educational Explanations",
        "authors": [
            "",
            "Authors:",
            "",
            "Tasmia Shahriar",
            ",",
            "Noboru Matsuda",
            ",",
            "Kelly Ramos",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Invariant Random Forest: Tree-Based Model Solution for OOD  Generalization",
        "authors": [
            "",
            "Authors:",
            "",
            "Yufan Liao",
            ",",
            "Qi Wu",
            ",",
            "Xing Yan",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:On the convergence of restarted Anderson acceleration for symmetric  linear systems",
        "authors": [
            "",
            "Authors:",
            "",
            "Hans De Sterck",
            ",",
            "Oliver A. Krzysik",
            ",",
            "Adam Smith",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Multi-Agent Reinforcement Learning via Distributed MPC as a Function  Approximator",
        "authors": [
            "",
            "Authors:",
            "",
            "Samuel Mallick",
            ",",
            "Filippo Airaldi",
            ",",
            "Azita Dabiri",
            ",",
            "Bart De Schutter",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Meta-Level Learning Algorithm for Sequential Hyper-Parameter Space  Reduction in AutoML",
        "authors": [
            "",
            "Authors:",
            "",
            "Giorgos Borboudakis",
            ",",
            "Paulos Charonyktakis",
            ",",
            "Konstantinos Paraschakis",
            ",",
            "Ioannis Tsamardinos",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Quantifying Divergence for Human-AI Collaboration and Cognitive Trust",
        "authors": [
            "",
            "Authors:",
            "",
            "M\u00fcge Kural",
            ",",
            "Ali Gebe\u015f\u00e7e",
            ",",
            "Tilek Chubakov",
            ",",
            "G\u00f6zde G\u00fcl \u015eahin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Single and Multi-Objective Optimization Benchmark Problems Focusing on  Human-Powered Aircraft Design",
        "authors": [
            "",
            "Authors:",
            "",
            "Nobuo Namura",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Silent Guardian: Protecting Text from Malicious Exploitation by Large  Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiawei Zhao",
            ",",
            "Kejiang Chen",
            ",",
            "Xiaojian Yuan",
            ",",
            "Yuang Qi",
            ",",
            "Weiming Zhang",
            ",",
            "Nenghai Yu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?",
        "authors": [
            "",
            "Authors:",
            "",
            "Fuheng Zhao",
            ",",
            "Lawrence Lim",
            ",",
            "Ishtiyaque Ahmad",
            ",",
            "Divyakant Agrawal",
            ",",
            "Amr El Abbadi",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Partial Label Learning with a Partner",
        "authors": [
            "",
            "Authors:",
            "",
            "Chongjie Si",
            ",",
            "Zekun Jiang",
            ",",
            "Xuehui Wang",
            ",",
            "Yan Wang",
            ",",
            "Xiaokang Yang",
            ",",
            "Wei Shen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Adaptive Tracking and Perching for Quadrotor in Dynamic Scenarios",
        "authors": [
            "",
            "Authors:",
            "",
            "Yuman Gao",
            ",",
            "Jialin Ji",
            ",",
            "Qianhao Wang",
            ",",
            "Rui Jin",
            ",",
            "Yi Lin",
            ",",
            "Zhimeng Shang",
            ",",
            "Yanjun Cao",
            ",",
            "Shaojie Shen",
            ",",
            "Chao Xu",
            ",",
            "Fei Gao",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Mixture of Cluster-conditional LoRA Experts for Vision-language  Instruction Tuning",
        "authors": [
            "",
            "Authors:",
            "",
            "Yunhao Gou",
            ",",
            "Zhili Liu",
            ",",
            "Kai Chen",
            ",",
            "Lanqing Hong",
            ",",
            "Hang Xu",
            ",",
            "Aoxue Li",
            ",",
            "Dit-Yan Yeung",
            ",",
            "James T. Kwok",
            ",",
            "Yu Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Distilling Autoregressive Models to Obtain High-Performance  Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference  Speed",
        "authors": [
            "",
            "Authors:",
            "",
            "Yubin Xiao",
            ",",
            "Di Wang",
            ",",
            "Boyang Li",
            ",",
            "Mingzhao Wang",
            ",",
            "Xuan Wu",
            ",",
            "Changliang Zhou",
            ",",
            "You Zhou",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image  Segmentation against Heterogeneous Annotation Noise",
        "authors": [
            "",
            "Authors:",
            "",
            "Nannan Wu",
            ",",
            "Zhaobin Sun",
            ",",
            "Zengqiang Yan",
            ",",
            "Li Yu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Divergences induced by dual subtractive and divisive normalizations of  exponential families and their convex deformations",
        "authors": [
            "",
            "Authors:",
            "",
            "Frank Nielsen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Weakly Supervised Semantic Segmentation for Driving Scenes",
        "authors": [
            "",
            "Authors:",
            "",
            "Dongseob Kim",
            ",",
            "Seungho Lee",
            ",",
            "Junsuk Choe",
            ",",
            "Hyunjung Shim",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Logic-Scaffolding: Personalized Aspect-Instructed Recommendation  Explanation Generation using LLMs",
        "authors": [
            "",
            "Authors:",
            "",
            "Behnam Rahdari",
            ",",
            "Hao Ding",
            ",",
            "Ziwei Fan",
            ",",
            "Yifei Ma",
            ",",
            "Zhuotong Chen",
            ",",
            "Anoop Deoras",
            ",",
            "Branislav Kveton",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Spatial-Temporal Decoupling Contrastive Learning for Skeleton-based  Human Action Recognition",
        "authors": [
            "",
            "Authors:",
            "",
            "Shaojie Zhang",
            ",",
            "Jianqin Yin",
            ",",
            "Yonghao Dang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Incorporating Feature Signal Transmission with Block-based Haptic Data  Reduction for Time-delayed Teleoperation",
        "authors": [
            "",
            "Authors:",
            "",
            "Hongjun Wu",
            ",",
            "Xiao Xu",
            ",",
            "Zhi Jin",
            ",",
            "Fanle Meng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Principled Instructions Are All You Need for Questioning LLaMA-1/2,  GPT-3.5/4",
        "authors": [
            "",
            "Authors:",
            "",
            "Sondos Mahmoud Bsharat",
            ",",
            "Aidar Myrzakhan",
            ",",
            "Zhiqiang Shen",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Multi-Contact Whole Body Force Control for Position-Controlled Robots",
        "authors": [
            "",
            "Authors:",
            "",
            "Quentin Rouxel",
            "(LARSEN),",
            "Serena Ivaldi",
            "(LARSEN),",
            "Jean-Baptiste Mouret",
            "(LARSEN)"
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A modified AAA algorithm for learning stable reduced-order models from  data",
        "authors": [
            "",
            "Authors:",
            "",
            "Tommaso Bradde",
            ",",
            "Stefano Grivet-Talocia",
            ",",
            "Quirin Aumann",
            ",",
            "Ion Victor Gosea",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models  through Intervention without Tuning",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhongzhi Chen",
            ",",
            "Xingwu Sun",
            ",",
            "Xianfeng Jiao",
            ",",
            "Fengzong Lian",
            ",",
            "Zhanhui Kang",
            ",",
            "Di Wang",
            ",",
            "Cheng-Zhong Xu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:TopCoW: Benchmarking Topology-Aware Anatomical Segmentation of the  Circle of Willis (CoW) for CTA and MRA",
        "authors": [
            "",
            "Authors:",
            "",
            "Kaiyuan Yang",
            ",",
            "Fabio Musio",
            ",",
            "Yihui Ma",
            ",",
            "Norman Juchler",
            ",",
            "Johannes C. Paetzold",
            ",",
            "Rami Al-Maskari",
            ",",
            "Luciano H\u00f6her",
            ",",
            "Hongwei Bran Li",
            ",",
            "Ibrahim Ethem Hamamci",
            ",",
            "Anjany Sekuboyina",
            ",",
            "Suprosanna Shit",
            ",",
            "Houjing Huang",
            ",",
            "Diana Waldmannstetter",
            ",",
            "Florian Kofler",
            ",",
            "Fernando Navarro",
            ",",
            "Martin Menten",
            ",",
            "Ivan Ezhov",
            ",",
            "Daniel Rueckert",
            ",",
            "Iris Vos",
            ",",
            "Ynte Ruigrok",
            ",",
            "Birgitta Velthuis",
            ",",
            "Hugo Kuijf",
            ",",
            "Julien H\u00e4mmerli",
            ",",
            "Catherine Wurster",
            ",",
            "Philippe Bijlenga",
            ",",
            "Laura Westphal",
            ",",
            "Jeroen Bisschop",
            ",",
            "Elisa Colombo",
            ",",
            "Hakim Baazaoui",
            ",",
            "Andrew Makmur",
            ",",
            "James Hallinan",
            ",",
            "Bene Wiestler",
            ",",
            "Jan S. Kirschke",
            ",",
            "Roland Wiest",
            ",",
            "Emmanuel Montagnon",
            ",",
            "Laurent Letourneau-Guillon",
            ",",
            "Adrian Galdran",
            ",",
            "Francesco Galati",
            ",",
            "Daniele Falcetta",
            ",",
            "Maria A. Zuluaga",
            ",",
            "Chaolong Lin",
            ",",
            "Haoran Zhao",
            ",",
            "Zehan Zhang",
            ",",
            "Sinyoung Ra",
            ",",
            "Jongyun Hwang",
            ",",
            "Hyunjin Park",
            ",",
            "Junqiang Chen",
            ",",
            "Marek Wodzinski",
            ",",
            "Henning M\u00fcller",
            ",  et al. (33 additional authors not shown)"
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A Quick Primer on Machine Learning in Wireless Communications",
        "authors": [
            "",
            "Authors:",
            "",
            "Faris B. Mismar",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Contrastive learning-based agent modeling for deep reinforcement  learning",
        "authors": [
            "",
            "Authors:",
            "",
            "Wenhao Ma",
            ",",
            "Yu-Cheng Chang",
            ",",
            "Jie Yang",
            ",",
            "Yu-Kai Wang",
            ",",
            "Chin-Teng Lin",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Framework for Variable-lag Motif Following Relation Inference In Time  Series using Matrix Profile analysis",
        "authors": [
            "",
            "Authors:",
            "",
            "Naaek Chinpattanakarn",
            ",",
            "Chainarong Amornbunchornvej",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Multidimensional extrapolated global proximal gradient and applications  for image processing",
        "authors": [
            "",
            "Authors:",
            "",
            "Abdeslem Hafid Bentbib",
            ",",
            "Khalide Jbilou",
            ",",
            "Ridwane Tahiri",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:ICMC-ASR: The ICASSP 2024 In-Car Multi-Channel Automatic Speech  Recognition Challenge",
        "authors": [
            "",
            "Authors:",
            "",
            "He Wang",
            ",",
            "Pengcheng Guo",
            ",",
            "Yue Li",
            ",",
            "Ao Zhang",
            ",",
            "Jiayao Sun",
            ",",
            "Lei Xie",
            ",",
            "Wei Chen",
            ",",
            "Pan Zhou",
            ",",
            "Hui Bu",
            ",",
            "Xin Xu",
            ",",
            "Binbin Zhang",
            ",",
            "Zhuo Chen",
            ",",
            "Jian Wu",
            ",",
            "Longbiao Wang",
            ",",
            "Eng Siong Chng",
            ",",
            "Sun Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Hold 'em and Fold 'em: Towards Human-scale, Feedback-Controlled Soft  Origami Robots",
        "authors": [
            "",
            "Authors:",
            "",
            "Immanuel Ampomah Mensah",
            ",",
            "Jessica Healey",
            ",",
            "Celina Wu",
            ",",
            "Andrea Lacunza",
            ",",
            "Nathaniel Hanson",
            ",",
            "Kristen L. Dorsey",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:LPAC: Learnable Perception-Action-Communication Loops with Applications  to Coverage Control",
        "authors": [
            "",
            "Authors:",
            "",
            "Saurav Agarwal",
            ",",
            "Ramya Muthukrishnan",
            ",",
            "Walker Gosrich",
            ",",
            "Vijay Kumar",
            ",",
            "Alejandro Ribeiro",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:MISS: A Generative Pretraining and Finetuning Approach for Med-VQA",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiawei Chen",
            ",",
            "Dingkang Yang",
            ",",
            "Yue Jiang",
            ",",
            "Yuxuan Lei",
            ",",
            "Lihua Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Sleeper Agents: Training Deceptive LLMs that Persist Through Safety  Training",
        "authors": [
            "",
            "Authors:",
            "",
            "Evan Hubinger",
            ",",
            "Carson Denison",
            ",",
            "Jesse Mu",
            ",",
            "Mike Lambert",
            ",",
            "Meg Tong",
            ",",
            "Monte MacDiarmid",
            ",",
            "Tamera Lanham",
            ",",
            "Daniel M. Ziegler",
            ",",
            "Tim Maxwell",
            ",",
            "Newton Cheng",
            ",",
            "Adam Jermyn",
            ",",
            "Amanda Askell",
            ",",
            "Ansh Radhakrishnan",
            ",",
            "Cem Anil",
            ",",
            "David Duvenaud",
            ",",
            "Deep Ganguli",
            ",",
            "Fazl Barez",
            ",",
            "Jack Clark",
            ",",
            "Kamal Ndousse",
            ",",
            "Kshitij Sachan",
            ",",
            "Michael Sellitto",
            ",",
            "Mrinank Sharma",
            ",",
            "Nova DasSarma",
            ",",
            "Roger Grosse",
            ",",
            "Shauna Kravec",
            ",",
            "Yuntao Bai",
            ",",
            "Zachary Witten",
            ",",
            "Marina Favaro",
            ",",
            "Jan Brauner",
            ",",
            "Holden Karnofsky",
            ",",
            "Paul Christiano",
            ",",
            "Samuel R. Bowman",
            ",",
            "Logan Graham",
            ",",
            "Jared Kaplan",
            ",",
            "S\u00f6ren Mindermann",
            ",",
            "Ryan Greenblatt",
            ",",
            "Buck Shlegeris",
            ",",
            "Nicholas Schiefer",
            ",",
            "Ethan Perez",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Cyclic and Negacyclic Codes with Optimal and Best Known Minimum  Distances",
        "authors": [
            "",
            "Authors:",
            "",
            "Hao Chen",
            ",",
            "Yanan Wu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:An ontology alignment method with user intervention using compact  differential evolution with adaptive parameter control",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhaoming Lv",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:UMG-CLIP: A Unified Multi-Granularity Vision Generalist for Open-World  Understanding",
        "authors": [
            "",
            "Authors:",
            "",
            "Bowen Shi",
            ",",
            "Peisen Zhao",
            ",",
            "Zichen Wang",
            ",",
            "Yuhang Zhang",
            ",",
            "Yaoming Wang",
            ",",
            "Jin Li",
            ",",
            "Wenrui Dai",
            ",",
            "Junni Zou",
            ",",
            "Hongkai Xiong",
            ",",
            "Qi Tian",
            ",",
            "Xiaopeng Zhang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Exploring the Reasoning Abilities of Multimodal Large Language Models  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning",
        "authors": [
            "",
            "Authors:",
            "",
            "Yiqi Wang",
            ",",
            "Wentao Chen",
            ",",
            "Xiaotian Han",
            ",",
            "Xudong Lin",
            ",",
            "Haiteng Zhao",
            ",",
            "Yongfei Liu",
            ",",
            "Bohan Zhai",
            ",",
            "Jianbo Yuan",
            ",",
            "Quanzeng You",
            ",",
            "Hongxia Yang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:E^2-LLM: Efficient and Extreme Length Extension of Large Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiaheng Liu",
            ",",
            "Zhiqi Bai",
            ",",
            "Yuanxing Zhang",
            ",",
            "Chenchen Zhang",
            ",",
            "Yu Zhang",
            ",",
            "Ge Zhang",
            ",",
            "Jiakai Wang",
            ",",
            "Haoran Que",
            ",",
            "Yukang Chen",
            ",",
            "Wenbo Su",
            ",",
            "Tiezheng Ge",
            ",",
            "Jie Fu",
            ",",
            "Wenhu Chen",
            ",",
            "Bo Zheng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Use of Prior Knowledge to Discover Causal Additive Models with  Unobserved Variables and its Application to Time Series Data",
        "authors": [
            "",
            "Authors:",
            "",
            "Takashi Nicholas Maeda",
            ",",
            "Shohei Shimizu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Improving Domain Adaptation through Extended-Text Reading Comprehension",
        "authors": [
            "",
            "Authors:",
            "",
            "Ting Jiang",
            ",",
            "Shaohan Huang",
            ",",
            "Shengyue Luo",
            ",",
            "Zihan Zhang",
            ",",
            "Haizhen Huang",
            ",",
            "Furu Wei",
            ",",
            "Weiwei Deng",
            ",",
            "Feng Sun",
            ",",
            "Qi Zhang",
            ",",
            "Deqing Wang",
            ",",
            "Fuzhen Zhuang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Improved Implicity Neural Representation with Fourier Bases  Reparameterized Training",
        "authors": [
            "",
            "Authors:",
            "",
            "Kexuan Shi",
            ",",
            "Xingyu Zhou",
            ",",
            "Shuhang Gu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Hierarchical Fashion Design with Multi-stage Diffusion Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhifeng Xie",
            ",",
            "Hao li",
            ",",
            "Huiming Ding",
            ",",
            "Mengtian Li",
            ",",
            "Ying Cao",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Developing ChatGPT for Biology and Medicine: A Complete Review of  Biomedical Question Answering",
        "authors": [
            "",
            "Authors:",
            "",
            "Qing Li",
            ",",
            "Lei Li",
            ",",
            "Yu Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:TAROT: A Hierarchical Framework with Multitask Co-Pretraining on  Semi-Structured Data towards Effective Person-Job Fit",
        "authors": [
            "",
            "Authors:",
            "",
            "Yihan Cao",
            ",",
            "Xu Chen",
            ",",
            "Lun Du",
            ",",
            "Hao Chen",
            ",",
            "Qiang Fu",
            ",",
            "Shi Han",
            ",",
            "Yushu Du",
            ",",
            "Yanbin Kang",
            ",",
            "Guangming Lu",
            ",",
            "Zi Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Are self-explanations from Large Language Models faithful?",
        "authors": [
            "",
            "Authors:",
            "",
            "Andreas Madsen",
            ",",
            "Sarath Chandar",
            ",",
            "Siva Reddy",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Learning Disentangled Speech Representations with Contrastive Learning  and Time-Invariant Retrieval",
        "authors": [
            "",
            "Authors:",
            "",
            "Yimin Deng",
            ",",
            "Huaizhen Tang",
            ",",
            "Xulong Zhang",
            ",",
            "Ning Cheng",
            ",",
            "Jing Xiao",
            ",",
            "Jianzong Wang",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process",
        "authors": [
            "",
            "Authors:",
            "",
            "Kiyohiro Nakayama",
            ",",
            "Mikaela Angelina Uy",
            ",",
            "Yang You",
            ",",
            "Ke Li",
            ",",
            "Leonidas Guibas",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Transcending the Limit of Local Window: Advanced Super-Resolution  Transformer with Adaptive Token Dictionary",
        "authors": [
            "",
            "Authors:",
            "",
            "Leheng Zhang",
            ",",
            "Yawei Li",
            ",",
            "Xingyu Zhou",
            ",",
            "Xiaorui Zhao",
            ",",
            "Shuhang Gu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Differentially Private Estimation of CATE in Adaptive Experiment",
        "authors": [
            "",
            "Authors:",
            "",
            "Jiachun Li",
            ",",
            "Kaining Shi",
            ",",
            "David Simchi-Levi",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on  Agriculture",
        "authors": [
            "",
            "Authors:",
            "",
            "Angels Balaguer",
            ",",
            "Vinamra Benara",
            ",",
            "Renato Luiz de Freitas Cunha",
            ",",
            "Roberto de M. Estev\u00e3o Filho",
            ",",
            "Todd Hendry",
            ",",
            "Daniel Holstein",
            ",",
            "Jennifer Marsman",
            ",",
            "Nick Mecklenburg",
            ",",
            "Sara Malvar",
            ",",
            "Leonardo O. Nunes",
            ",",
            "Rafael Padilha",
            ",",
            "Morris Sharp",
            ",",
            "Bruno Silva",
            ",",
            "Swati Sharma",
            ",",
            "Vijay Aski",
            ",",
            "Ranveer Chandra",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Contrastive Preference Optimization: Pushing the Boundaries of LLM  Performance in Machine Translation",
        "authors": [
            "",
            "Authors:",
            "",
            "Haoran Xu",
            ",",
            "Amr Sharaf",
            ",",
            "Yunmo Chen",
            ",",
            "Weiting Tan",
            ",",
            "Lingfeng Shen",
            ",",
            "Benjamin Van Durme",
            ",",
            "Kenton Murray",
            ",",
            "Young Jin Kim",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:PlayMyData: a curated dataset of multi-platform video games",
        "authors": [
            "",
            "Authors:",
            "",
            "Andrea D'Angelo",
            ",",
            "Claudio Di Sipio",
            ",",
            "Cristiano Politowski",
            ",",
            "Riccardo Rubei",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:NODI: Out-Of-Distribution Detection with Noise from Diffusion",
        "authors": [
            "",
            "Authors:",
            "",
            "Jingqiu Zhou",
            ",",
            "Aojun Zhou",
            ",",
            "Hongsheng Li",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:MA2GCN: Multi Adjacency relationship Attention Graph Convolutional  Networks for Traffic Prediction using Trajectory data",
        "authors": [
            "",
            "Authors:",
            "",
            "Zhengke Sun",
            ",",
            "Yuliang Ma",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Inviscid Burgers as a degenerate elliptic problem",
        "authors": [
            "",
            "Authors:",
            "",
            "Uditnarayan Kouskiya",
            ",",
            "Amit Acharya",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:B-Cos Aligned Transformers Learn Human-Interpretable Features",
        "authors": [
            "",
            "Authors:",
            "",
            "Manuel Tran",
            ",",
            "Amal Lahiani",
            ",",
            "Yashin Dicente Cid",
            ",",
            "Melanie Boxberg",
            ",",
            "Peter Lienemann",
            ",",
            "Christian Matek",
            ",",
            "Sophia J. Wagner",
            ",",
            "Fabian J. Theis",
            ",",
            "Eldad Klaiman",
            ",",
            "Tingying Peng",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:A hybrid tau-leap for simulating chemical kinetics with applications to  parameter estimation",
        "authors": [
            "",
            "Authors:",
            "",
            "Thomas Trigo Trindade",
            ",",
            "Konstantinos C. Zygalakis",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Stream Query Denoising for Vectorized HD Map Construction",
        "authors": [
            "",
            "Authors:",
            "",
            "Shuo Wang",
            ",",
            "Fan Jia",
            ",",
            "Yingfei Liu",
            ",",
            "Yucheng Zhao",
            ",",
            "Zehui Chen",
            ",",
            "Tiancai Wang",
            ",",
            "Chi Zhang",
            ",",
            "Xiangyu Zhang",
            ",",
            "Feng Zhao",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Unsupervised Multiple Domain Translation through Controlled  Disentanglement in Variational Autoencoder",
        "authors": [
            "",
            "Authors:",
            "",
            "Antonio Almud\u00e9var",
            ",",
            "Th\u00e9o Mariotte",
            ",",
            "Alfonso Ortega",
            ",",
            "Marie Tahon",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Preparing Lessons for Progressive Training on Language Models",
        "authors": [
            "",
            "Authors:",
            "",
            "Yu Pan",
            ",",
            "Ye Yuan",
            ",",
            "Yichun Yin",
            ",",
            "Jiaxin Shi",
            ",",
            "Zenglin Xu",
            ",",
            "Ming Zhang",
            ",",
            "Lifeng Shang",
            ",",
            "Xin Jiang",
            ",",
            "Qun Liu",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    },
    {
        "title": "Title:Offloading platooning applications from 5.9 GHz V2X to Radar  Communications: effects on safety and efficiency",
        "authors": [
            "",
            "Authors:",
            "",
            "Elena Haller",
            ",",
            "Galina Sidorenko",
            ",",
            "Oscar Amador",
            ",",
            "Emil Nilsson",
            ""
        ],
        "abstract": "Not Found",
        "date": "Not Found"
    }
]